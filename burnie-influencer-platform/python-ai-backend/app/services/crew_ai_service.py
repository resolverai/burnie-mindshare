import asyncio
import json
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Type, Union
import logging
from concurrent.futures import ThreadPoolExecutor
import re
from pydantic import BaseModel, Field
import traceback
import uuid
import os
from enum import Enum

# Schemas for Image Generation Tools
class ImageToolSchema(BaseModel):
    prompt: str = Field(..., description="Image generation prompt as a simple string")

class FalAIImageToolSchema(ImageToolSchema):
    pass

class OpenAIImageToolSchema(ImageToolSchema):
    pass

class GoogleImageToolSchema(ImageToolSchema):
    pass

from crewai import Agent, Task, Crew, Process
from crewai.tools import BaseTool
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI

# üîá Suppress OpenTelemetry/telemetry exceptions and warnings
import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning, module="opentelemetry.*")
warnings.filterwarnings("ignore", message=".*telemetry.*")
warnings.filterwarnings("ignore", message=".*crewai.*telemetry.*")
warnings.filterwarnings("ignore", message=".*opentelemetry.*")

from app.config.settings import settings
from app.models.content_generation import (
    MiningSession, AgentType, AgentStatus, MiningStatus,
    ContentGenerationResponse, AgentOutput, QualityMetrics,
    PerformancePrediction, GenerationResult
)
from app.database.repositories.user_repository import UserRepository
from app.database.repositories.campaign_repository import CampaignRepository
from app.database.repositories.agent_config_repository import AgentConfigRepository
from app.database.repositories.twitter_learning_repository import TwitterLearningRepository
from app.utils.quality_scorer import QualityScorer
from app.utils.mindshare_predictor import MindsharePredictor
from app.services.llm_content_generators import unified_generator, UnifiedContentGenerator

logger = logging.getLogger(__name__)

# üîá Custom logging filter to suppress telemetry errors
class TelemetryFilter(logging.Filter):
    def filter(self, record):
        # Filter out telemetry-related log messages
        message = record.getMessage().lower()
        return not any(keyword in message for keyword in [
            'telemetry.crewai.com',
            'opentelemetry',
            'otel',
            'connecttimeout',
            'connection to telemetry',
            'traces',
            'maxretryerror'
        ])

# Apply filter to all loggers
for logger_name in ['', 'opentelemetry', 'requests', 'urllib3']:
    logging.getLogger(logger_name).addFilter(TelemetryFilter())

class CrewAIService:
    """
    CrewAI Multi-Agentic Content Generation Service
    
    Orchestrates 5 specialized AI agents to generate Twitter-ready content
    optimized for maximum mindshare and engagement using user's preferred models.
    """
    
    def __init__(self, session_id: str, progress_tracker, websocket_manager, websocket_session_id: str = None):
        """
        Initialize CrewAI service with dual session ID support
        
        Args:
            session_id: Internal session ID for state isolation 
            websocket_session_id: Session ID for WebSocket communication (defaults to session_id)
            progress_tracker: Progress tracking instance
            websocket_manager: WebSocket manager instance
        """
        self.session_id = session_id  # Internal session ID for isolation
        self.websocket_session_id = websocket_session_id or session_id  # WebSocket session ID for frontend
        self.progress_tracker = progress_tracker
        self.websocket_manager = websocket_manager
        
        # Initialize repositories
        self.user_repo = UserRepository()
        self.campaign_repo = CampaignRepository()
        self.agent_config_repo = AgentConfigRepository()
        self.twitter_learning_repo = TwitterLearningRepository()
        
        # Initialize utility services
        self.quality_scorer = QualityScorer()
        self.mindshare_predictor = MindsharePredictor()
        
        # Store agent instances
        self.agents: Dict[AgentType, Agent] = {}
        self.tasks: Dict[AgentType, Task] = {}
        self.crew: Optional[Crew] = None
        
        # Initialize Twitter context storage
        self.project_twitter_context = ""
        self.mining_session = None  # Will be set externally
        
        # Session data
        self.user_data = None
        self.campaign_data = None
        self.agent_configs = {}
        self.twitter_insights = None

        # User preferences and API keys
        self.user_agent_config = None
        self.user_api_keys = {}
        self.model_preferences = {}
        
        # S3 organization parameters
        self.wallet_address = None
        self.agent_id = None

    async def generate_content(self, mining_session: MiningSession, user_api_keys: Dict[str, str] = None, agent_id: int = None, wallet_address: str = None) -> ContentGenerationResponse:
        """Main entry point for multi-agentic content generation"""
        try:
            logger.info(f"üöÄ Starting CrewAI generation for user {mining_session.user_id}, campaign {mining_session.campaign_id}")
            
            # Debug: Log the received wallet_address
            logger.info(f"üîç DEBUG: CrewAI.generate_content received wallet_address: {wallet_address}")
            
            # Store mining session for access throughout the service
            self.mining_session = mining_session
            
            # Store campaign context for access throughout the service
            self.campaign_context = mining_session.campaign_context or {}
            
            # Store user API keys, agent ID, and wallet address for S3 organization
            self.user_api_keys = user_api_keys or {}
            self.agent_id = str(agent_id) if agent_id else "default-agent"
            self.wallet_address = wallet_address or "unknown-wallet"
            
            # Debug: Log what was stored
            logger.info(f"üîç DEBUG: CrewAI stored wallet_address: {self.wallet_address}")
            logger.info(f"üîç DEBUG: CrewAI stored agent_id: {self.agent_id}")
            
            # Debug: Log available API keys (without exposing actual keys)
            available_keys = list(self.user_api_keys.keys()) if self.user_api_keys else []
            logger.info(f"üîë Available API keys: {available_keys}")
            

            
            # Validate critical API keys for text generation (mandatory)
            if not self.user_api_keys:
                logger.error("‚ùå No API keys provided in user_api_keys")
                raise ValueError("No API keys provided. Please configure API keys in Neural Keys.")
            
            # Check for text generation keys (at least one required)
            text_providers = ['openai', 'anthropic', 'google']
            missing_keys = []
            available_text_keys = [k for k in text_providers if self.user_api_keys.get(k) and self.user_api_keys.get(k).strip()]
            
            if not available_text_keys:
                missing_keys.extend(['openai OR anthropic OR google'])
                
            if missing_keys:
                error_msg = f"Missing API keys: {', '.join(missing_keys)}. Please configure them in Neural Keys."
                logger.error(f"‚ùå {error_msg}")
                logger.error(f"üí° Provided keys: {available_keys}")
                raise ValueError(error_msg)
            
            # Phase 1: Initialize and load data (including agent configuration)
            await self._update_progress(10, "Loading user data and agent configuration...")
            await self._initialize_session_data(mining_session, agent_id)
            
            # Phase 1.5 & 2: Fetch complete campaign context from database and validate API keys
            await self._update_progress(12, "Fetching campaign context from database and validating API keys...")
            

            
            # Run context fetching and API validation in parallel (non-blocking)
            import asyncio
            context_task = asyncio.create_task(self._fetch_complete_campaign_context(mining_session.campaign_id))
            api_validation_task = asyncio.create_task(self._validate_api_keys())
            

            # Wait for both tasks to complete
            missing_keys, _ = await asyncio.gather(api_validation_task, context_task)

            
            await self._update_progress(15, "Twitter context and API validation completed...")
            if missing_keys:
                error_msg = f"Missing API keys: {', '.join(missing_keys)}. Please configure them in Neural Keys."
                await self._update_progress(0, error_msg, error=error_msg)
                raise ValueError(error_msg)
            
            # Phase 3: Set up agents with user's personalized configurations and models (AFTER database context is loaded)
            await self._update_progress(20, "Configuring personalized AI agents with your preferred models...")
            self._setup_agents(mining_session)
            
            # Phase 4: Run multi-agentic content generation
            await self._update_progress(30, "Starting multi-agentic content generation...")
            generation_result = await self._run_crew_generation(mining_session)
            
            # Phase 5: Post-process and optimize
            await self._update_progress(90, "Optimizing final content...")
            final_content = await self._post_process_content(generation_result, mining_session)
            
            # Phase 6: Sync content to marketplace (MVP workflow)
            await self._update_progress(95, "Syncing content to marketplace...")
            marketplace_success = await self._sync_to_marketplace(final_content, mining_session)
            
            await self._update_progress(100, "Content generated and added to marketplace!")
            logger.info(f"‚úÖ Content generation completed for session: {self.session_id}")
            
            return final_content
            
        except Exception as e:
            logger.error(f"‚ùå Error in content generation: {e}")
            await self._update_progress(0, f"Error: {str(e)}", error=str(e))
            raise

    async def _initialize_session_data(self, mining_session: MiningSession, agent_id: int = None):
        """Load user, campaign and agent data"""
        try:
            logger.info(f"üîÑ Initializing session data for user {mining_session.user_id}")
            
            # Store agent_id for use in tools
            self.agent_id = agent_id
            
            # Get user data
            self.user_data = self.user_repo.get_user_by_id(mining_session.user_id)
            if not self.user_data:
                raise ValueError(f"User not found: {mining_session.user_id}")
            
            # Get campaign data
            self.campaign_data = self.campaign_repo.get_campaign_by_id(mining_session.campaign_id)
            if not self.campaign_data:
                raise ValueError(f"Campaign not found: {mining_session.campaign_id}")
            
            # Get agent configuration if agent_id provided
            if agent_id:
                self.user_agent_config = self.agent_config_repo.get_agent_by_id(agent_id)
                if self.user_agent_config:
                    logger.info(f"‚úÖ Loaded agent configuration for agent: {agent_id}")
                    # Extract model preferences from agent config
                    config_data = self.user_agent_config.get('configuration', {})
                    if isinstance(config_data, str):
                        try:
                            config_data = json.loads(config_data)
                        except:
                            config_data = {}
                    
                    # Try both camelCase and snake_case for model preferences
                    model_prefs = (config_data.get('modelPreferences') or 
                                  config_data.get('model_preferences') or 
                                  self._get_default_model_preferences())
                    
                    self.model_preferences = model_prefs
                    
                    # Debug: Log the extracted model preferences
                    logger.info(f"üîß Extracted model preferences: {json.dumps(self.model_preferences, indent=2)}")
                    
                    # Specifically log image model preferences
                    image_config = self.model_preferences.get('image', {})
                    logger.info(f"üé® Image model config - Provider: {image_config.get('provider')}, Model: {image_config.get('model')}")
                    logger.info(f"üîç CRITICAL DEBUG - Model preferences object: {type(self.model_preferences)}")
                    logger.info(f"üîç CRITICAL DEBUG - Image preferences: {image_config}")
                    logger.info(f"üîç CRITICAL DEBUG - Full config data keys: {list(config_data.keys()) if isinstance(config_data, dict) else 'Not a dict'}")
                    
                else:
                    logger.warning(f"‚ö†Ô∏è No configuration found for agent {agent_id}")
                    self.model_preferences = self._get_default_model_preferences()
            else:
                self.user_agent_config = None
                self.model_preferences = self._get_default_model_preferences()
            
            # Get Twitter insights for this agent
            self.twitter_insights = {}
            try:
                if self.agent_id:
                    # Get agent-specific Twitter learning data
                    twitter_data = self.twitter_learning_repo.get_agent_twitter_data(
                        self.user_data.get('id'), 
                        self.agent_id
                    )
                else:
                    # Fallback to general user Twitter data
                    twitter_data = self.twitter_learning_repo.get_user_twitter_data(self.user_data.get('id'))
                
                if twitter_data and twitter_data.get('learningData'):
                    self.twitter_insights = twitter_data['learningData']
                    logger.info(f"‚úÖ Loaded Twitter insights for agent {self.agent_id}: {self.twitter_insights.get('total_tweets', 0)} tweets")
                else:
                    logger.info(f"‚ö†Ô∏è No Twitter insights found for agent {self.agent_id}")
            except Exception as e:
                logger.warning(f"Failed to load Twitter insights: {e}")
                
            logger.info("‚úÖ Session data initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize session data: {e}")
            raise

    def _get_project_logo_url(self) -> str:
        """Get project logo URL from database campaign context"""
        try:
            # Use database campaign context instead of mining session context
            campaign_context = getattr(self, 'campaign_data', {})
            
            if not campaign_context:
                logger.warning("‚ö†Ô∏è No campaign data available from database for logo URL")
                return ""
            
            # Check all possible logo fields
            logo_url = campaign_context.get('projectLogo', '')
            logo_url_alt = campaign_context.get('projectLogoUrl', '')
            
            # Use whichever is available
            final_logo_url = logo_url or logo_url_alt
            
            if final_logo_url:
                logger.info(f"üè∑Ô∏è Found project logo URL from database: {final_logo_url}")
                return final_logo_url
            else:
                logger.warning("‚ö†Ô∏è No project logo URL found in database campaign context")
                return ""
        except Exception as e:
            logger.error(f"‚ùå Error getting project logo URL: {e}")
            return ""



    def _get_default_model_preferences(self):
        """Get default model preferences if user hasn't configured any"""
        return {
            'text': {'provider': 'openai', 'model': 'gpt-4o'},
            'image': {'provider': 'openai', 'model': 'dall-e-3'},
            'video': {'provider': 'google', 'model': 'veo-3'},
            'audio': {'provider': 'openai', 'model': 'tts-1-hd'}
        }

    async def _validate_api_keys(self) -> List[str]:
        """Validate that text generation API key is available (required) and log optional content types"""
        missing_keys = []
        
        # TEXT CONTENT IS MANDATORY - Check if text generation API key is available
        text_provider = self.model_preferences.get('text', {}).get('provider', 'openai')
        text_key_name = self._get_provider_key_name(text_provider)
        text_key_available = self.user_api_keys.get(text_key_name) and self.user_api_keys.get(text_key_name).strip()
        
        if not text_key_available:
            missing_keys.append(f"{text_provider.upper()} API key (required for text content)")
            logger.warning(f"‚ö†Ô∏è Missing required {text_provider.upper()} API key for text generation")
        else:
            logger.info(f"‚úÖ Text generation available using {text_provider.upper()}")
        
        # Check other available API keys for optional content
        available_optional_keys = []
        skipped_optional_modalities = []
        
        # Check visual content providers (optional)
        for content_type in ['image', 'video']:
            preference = self.model_preferences.get(content_type, {})
            provider = preference.get('provider')
            if provider:
                key_name = self._get_provider_key_name(provider)
                if key_name and self.user_api_keys.get(key_name) and self.user_api_keys.get(key_name).strip():
                    available_optional_keys.append(f"{content_type.upper()} ({provider.upper()})")
                else:
                    skipped_optional_modalities.append(f"{content_type.upper()} ({provider.upper()})")
        
        # Check strategic analysis (optional)
        if self.user_api_keys.get('anthropic') and self.user_api_keys.get('anthropic').strip():
            available_optional_keys.append("Strategic Analysis (ANTHROPIC)")
        else:
            skipped_optional_modalities.append("Strategic Analysis (ANTHROPIC)")
        
        # Log optional content status
        if available_optional_keys:
            logger.info(f"‚úÖ Optional content types available: {', '.join(available_optional_keys)}")
        
        if skipped_optional_modalities:
            logger.info(f"‚ö†Ô∏è Optional content types that will be skipped: {', '.join(skipped_optional_modalities)}")
        
        # Return missing keys (only fails if text generation is not possible)
        if missing_keys:
            logger.error(f"‚ùå Text generation API key missing - cannot proceed without text content capability")
        
        return missing_keys
    
    def _get_provider_key_name(self, provider: str) -> str:
        """Map provider names to API key names"""
        provider_key_mapping = {
            'openai': 'openai',
            'anthropic': 'anthropic', 
            'google': 'google',
            'replicate': 'replicate',
            'elevenlabs': 'elevenlabs',
            'stability': 'stability'
        }
        return provider_key_mapping.get(provider.lower(), '')

    def _setup_agents(self, mining_session: MiningSession):
        """Set up the 5 specialized AI agents with personalized configurations"""
        try:
            # Create agents with LLM
            llm = self._get_llm_instance()
            
            self.agents[AgentType.DATA_ANALYST] = self._create_data_analyst_agent(llm)
            self.agents[AgentType.CONTENT_STRATEGIST] = self._create_content_strategist_agent(llm)
            self.agents[AgentType.TEXT_CONTENT] = self._create_text_content_agent(llm)
            self.agents[AgentType.VISUAL_CREATOR] = self._create_visual_creator_agent(llm)
            self.agents[AgentType.ORCHESTRATOR] = self._create_orchestrator_agent()
            
            # Create tasks for each agent
            self.tasks[AgentType.DATA_ANALYST] = self._create_data_analysis_task()
            self.tasks[AgentType.CONTENT_STRATEGIST] = self._create_strategy_task()
            self.tasks[AgentType.TEXT_CONTENT] = self._create_content_creation_task()
            self.tasks[AgentType.VISUAL_CREATOR] = self._create_visual_task()
            self.tasks[AgentType.ORCHESTRATOR] = self._create_orchestration_task()
            
            # Create crew with proper task dependencies
            self.crew = Crew(
                agents=list(self.agents.values()),
                tasks=list(self.tasks.values()),
                process=Process.sequential,  # Sequential execution for better control
                verbose=True,
                max_execution_time=600,  # 10 minutes global timeout
                memory=False  # Disable memory to prevent context conflicts
            )
            
            logger.info("ü§ñ All agents and tasks configured successfully")
            
        except Exception as e:
            logger.error(f"‚ùå Error setting up agents: {e}")
            raise

    def _create_data_analyst_agent(self, llm) -> Agent:
        """Create the Data Analyst Agent with real mindshare prediction capabilities"""
        agent_config = self.agent_configs.get(AgentType.DATA_ANALYST, {})
        twitter_context = self._get_twitter_context()
        
        # Initialize mindshare predictor and tools
        predictor = MindsharePredictor()
        campaign_context = {
            'platform_source': self.campaign_data.get('platformSource', 'default') if self.campaign_data else 'default',
            'campaign_type': self.campaign_data.get('campaignType', 'social') if self.campaign_data else 'social',
            'reward_pool': self.campaign_data.get('rewardPool', 0) if self.campaign_data else 0
        }
        
        mindshare_tool = MindshareAnalysisTool(predictor, campaign_context, self.twitter_learning_repo, self.user_data.get('id'), self.agent_id)
        engagement_tool = EngagementPredictionTool(predictor)
        
        return Agent(
            role="Data Analyst & Mindshare Specialist",
            goal="Analyze campaign requirements, user behavior patterns, and platform-specific mindshare trends using ML models trained on historical performance data to provide data-driven insights for content optimization",
            backstory=f"""You are an expert Data Analyst specializing in crypto/Web3 mindshare prediction.
            
            Your task is to analyze the campaign requirements, user behavior patterns, and predict optimal content strategies using:
            
            REAL DATA SOURCES:
            - Twitter Learning Data: {twitter_context}
            - Campaign Details: 
              - Platform: {self.campaign_data.get('platformSource', 'Unknown') if self.campaign_data else 'Unknown'}
              - Type: {self.campaign_data.get('campaignType', 'social') if self.campaign_data else 'social'}
              - Campaign: {self.campaign_data.get('title', 'No campaign data') if self.campaign_data else 'No campaign data'}
              - Reward Pool: {campaign_context['reward_pool']}
            - Mindshare ML Models: Available for {list(predictor.platform_models.keys()) if hasattr(predictor, 'platform_models') else 'Loading...'}
            
            ANALYSIS REQUIREMENTS:
            1. **TWITTER LEARNING DATA INTEGRATION**: Use actual Twitter learning patterns from the database
            2. **MINDSHARE ML MODELS**: Apply trained models for platform-specific predictions  
            3. **Content Strategy**: Recommend optimal content type (text, image, video, meme)
            4. **Engagement Prediction**: Use historical data to predict performance metrics
            5. **Platform Optimization**: Tailor recommendations for the specific platform
            
            Always provide data-driven insights backed by real analytics, not generic advice.
            """,
            verbose=True,
            allow_delegation=False,
            llm=llm,
            tools=[mindshare_tool, engagement_tool],
            max_iter=2,  # Maximum 2 iterations to prevent loops
            max_execution_time=180  # 3 minutes max
        )

    def _get_campaign_context(self) -> str:
        """Get formatted campaign context for agents using database data"""
        try:
            # Use database campaign context instead of frontend data
            campaign_context = getattr(self, 'campaign_data', {})
            
            # üîç DEBUG: Log what we have in campaign_data
            logger.info(f"üîç === CAMPAIGN CONTEXT DEBUG ===")
            logger.info(f"üîç campaign_data exists: {hasattr(self, 'campaign_data')}")
            logger.info(f"üîç campaign_data content: {campaign_context}")
            logger.info(f"üîç campaign_data keys: {list(campaign_context.keys()) if campaign_context else 'None'}")
            
            if not campaign_context:
                logger.warning("‚ö†Ô∏è No campaign data available from database")
                return "Campaign context unavailable"
            
            # Extract key information from database
            title = campaign_context.get('title', 'Campaign')
            description = campaign_context.get('description', '')
            platform_source = campaign_context.get('platform_source', 'twitter')
            project_name = campaign_context.get('projectName', 'N/A')
            token_ticker = campaign_context.get('tokenTicker', 'N/A')
            project_logo = campaign_context.get('projectLogo', '')
            
            # üîç DEBUG: Log extracted values
            logger.info(f"üîç Extracted project_name: '{project_name}'")
            logger.info(f"üîç Extracted token_ticker: '{token_ticker}'")
            logger.info(f"üîç Extracted project_logo: '{project_logo}'")
            logger.info(f"üîç === END CAMPAIGN CONTEXT DEBUG ===")
            
            # Build context string with token ticker
            context_parts = [
                f"Campaign: {title}",
                f"Platform: {platform_source}",
                f"Token/Project: {project_name} ({token_ticker})" if token_ticker != 'N/A' else f"Token/Project: {project_name}"
            ]
            
            if description:
                context_parts.append(f"Description: {description[:200]}...")
            
            if project_logo:
                context_parts.append(f"Project Logo Available: {project_logo}")
                
            # Add Twitter context if available
            if hasattr(self, 'project_twitter_context') and self.project_twitter_context and self.project_twitter_context.strip():
                # Count tweets from twitter context string
                tweet_count = len([line for line in self.project_twitter_context.split('\n') if line.startswith('[202')])
                context_parts.append(f"Recent Twitter Activity: {tweet_count} tweets available")
            
            return "\n".join(context_parts)
        except Exception as e:
            logger.error(f"‚ùå Error getting campaign context: {e}")
            return "Campaign context unavailable"

    async def _fetch_complete_campaign_context(self, campaign_id: int):
        """Fetch complete campaign context from database instead of relying on frontend data"""

        try:
            logger.info(f"üîç Fetching complete campaign context from database for campaign {campaign_id}")
            

            # Fetch campaign data from database
            campaign_data = self.campaign_repo.get_campaign_by_id(campaign_id)

            
            if not campaign_data:

                logger.error(f"‚ùå Campaign {campaign_id} not found in database")
                return
            

            
            logger.info(f"‚úÖ Campaign data fetched: {campaign_data.get('title', 'Unknown')}")
            
            # Extract all campaign information
            campaign_context = {
                'id': campaign_data.get('id'),
                'title': campaign_data.get('title', ''),
                'description': campaign_data.get('description', ''),
                'category': campaign_data.get('category', ''),
                'campaign_type': campaign_data.get('campaignType', ''),
                'topic': campaign_data.get('category', ''),
                'guidelines': campaign_data.get('brandGuidelines', ''),
                'winner_reward': campaign_data.get('rewardPool', ''),
                'platform_source': campaign_data.get('platformSource', 'twitter'),
                
                # Project information from campaigns table
                'projectId': campaign_data.get('projectId'),
                'projectName': campaign_data.get('projectName', ''),
                'projectLogo': campaign_data.get('projectLogo', ''),
                'tokenTicker': campaign_data.get('tokenTicker', ''),
                'projectTwitterHandle': campaign_data.get('projectTwitterHandle', ''),
            }
            

            print(f"  - projectId: {campaign_context.get('projectId')}")
            print(f"  - projectName: {campaign_context.get('projectName')}")
            print(f"  - projectTwitterHandle from campaigns table: {campaign_context.get('projectTwitterHandle')}")
            
            # If no Twitter handle in campaigns table, fetch it from project_twitter_data table
            project_id = campaign_context.get('projectId')
            if project_id and not campaign_context.get('projectTwitterHandle'):

                try:
                    # Fetch Twitter handle from project_twitter_data table
                    from app.services.project_twitter_integration import project_twitter_integration
                    twitter_handle = await project_twitter_integration.get_project_twitter_handle(int(project_id))

                    
                    if twitter_handle:
                        campaign_context['projectTwitterHandle'] = twitter_handle
                except Exception as e:
                    logger.error(f"‚ùå Error fetching Twitter handle for project {project_id}: {e}")
            



            
            # Store in mining session
            if hasattr(self, 'mining_session') and self.mining_session:
                self.mining_session.campaign_context = campaign_context
                logger.info(f"‚úÖ Updated mining session with database campaign context")
            
            # Store for easy access
            self.campaign_data = campaign_context
            
            # Fetch fresh Twitter data if project ID is available (with daily limit protection)
            project_id = campaign_context.get('projectId')

            if project_id:
                # STRATEGY: Use existing Twitter data immediately, fetch new data in background
                logger.info(f"üê¶ Loading existing Twitter context for project {project_id}")
                
                from app.services.project_twitter_integration import project_twitter_integration
                
                # 1. Get existing Twitter context immediately (non-blocking)
                twitter_context_string = await project_twitter_integration.get_project_twitter_context(int(project_id))
                
                if twitter_context_string and twitter_context_string.strip():
                    self.project_twitter_context = twitter_context_string
                    logger.info(f"‚úÖ Using existing Twitter context: {len(twitter_context_string)} characters")
                else:
                    self.project_twitter_context = ""
                    logger.info("üì≠ No existing Twitter context available")
                
                # 2. Trigger background fetch for future content generation (fire-and-forget)
                try:
                    # Get project Twitter handle for background fetch
                    twitter_handle = campaign_context.get('projectTwitterHandle')
                    project_name = campaign_context.get('projectName') or 'Unknown Project'
                    
                    if twitter_handle and twitter_handle.strip():
                        # Start background task - don't wait for it
                        import asyncio
                        asyncio.create_task(self._background_twitter_fetch(
                            project_id=int(project_id),
                            project_name=str(project_name),
                            twitter_handle=str(twitter_handle)
                        ))
                        logger.info(f"üîÑ Started background Twitter fetch for project {project_id}")
                    else:
                        logger.info("üì≠ No Twitter handle available for background fetch")
                        
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Failed to start background Twitter fetch: {e}")
                    # Don't fail content generation if background fetch fails to start

            else:
                logger.warning("‚ö†Ô∏è No project ID found for Twitter context")
                self.project_twitter_context = ""
            
            logger.info(f"‚úÖ Complete campaign context fetched for campaign {campaign_id}")
            
        except Exception as e:

            logger.error(f"‚ùå Failed to fetch complete campaign context: {e}")
            import traceback

            logger.error(traceback.format_exc())

    async def _background_twitter_fetch(self, project_id: int, project_name: str, twitter_handle: str):
        """
        Background Twitter data fetching that doesn't block content generation.
        This runs asynchronously to prepare data for future content generation.
        """
        try:
            logger.info(f"üîÑ Background: Starting Twitter fetch for project {project_id} (@{twitter_handle})")
            
            from app.services.project_twitter_integration import project_twitter_integration
            
            # Use content generation fetch which respects daily limits and has retry logic
            fetch_result = await project_twitter_integration.handle_content_generation_fetch(
                project_id=project_id,
                project_name=project_name,
                twitter_handle=twitter_handle
            )
            
            if fetch_result.get('success'):
                if fetch_result.get('skipped'):
                    logger.info(f"üîÑ Background: Twitter data already current for project {project_id}")
                elif fetch_result.get('posts_fetched', 0) > 0:
                    logger.info(f"üîÑ Background: Fetched {fetch_result['posts_fetched']} new Twitter posts for project {project_id}")
                else:
                    logger.info(f"üîÑ Background: No new Twitter posts found for project {project_id}")
            else:
                logger.warning(f"üîÑ Background: Twitter fetch failed for project {project_id}: {fetch_result.get('error', 'Unknown error')}")
                
        except Exception as e:
            # Background fetch failures should not impact the main flow
            logger.warning(f"üîÑ Background: Twitter fetch exception for project {project_id}: {e}")
            # Don't re-raise - this is fire-and-forget

    def _ensure_project_handle_tagged(self, main_tweet: str) -> str:
        """
        Sanity check: Ensure the project Twitter handle is tagged in the main_tweet.
        If not present, add it at the end of the tweet.
        """
        try:
            if not main_tweet or not main_tweet.strip():
                logger.warning("‚ö†Ô∏è Empty main_tweet provided to sanity check")
                return main_tweet
            
            # Get project Twitter handle from campaign data
            project_twitter_handle = None
            if hasattr(self, 'campaign_data') and self.campaign_data:
                project_twitter_handle = self.campaign_data.get('projectTwitterHandle')
            
            # If no project handle available, return original tweet
            if not project_twitter_handle or not project_twitter_handle.strip():
                logger.info("üì≠ No project Twitter handle available for tagging")
                return main_tweet
            
            # Clean the handle - ensure it starts with @
            if not project_twitter_handle.startswith('@'):
                project_twitter_handle = f"@{project_twitter_handle}"
            
            # Check if the handle is already in the tweet (case-insensitive)
            if project_twitter_handle.lower() in main_tweet.lower():
                logger.info(f"‚úÖ Project handle {project_twitter_handle} already tagged in main_tweet")
                return main_tweet
            
            # Handle is not present - add it at the end
            # Ensure there's a space before the handle
            if main_tweet.endswith(' '):
                tagged_tweet = f"{main_tweet}{project_twitter_handle}"
            else:
                tagged_tweet = f"{main_tweet} {project_twitter_handle}"
            
            logger.info(f"üè∑Ô∏è SANITY CHECK: Added project handle {project_twitter_handle} to main_tweet")
            logger.info(f"üè∑Ô∏è Original: {main_tweet[:50]}...")
            logger.info(f"üè∑Ô∏è Tagged: {tagged_tweet[:50]}...")
            
            return tagged_tweet
            
        except Exception as e:
            logger.error(f"‚ùå Error in project handle sanity check: {e}")
            # Return original tweet if sanity check fails
            return main_tweet

    def _create_content_strategist_agent(self, llm) -> Agent:
        """Create the Content Strategist Agent with strategic analysis capabilities"""
        agent_config = self.agent_configs.get(AgentType.CONTENT_STRATEGIST, {})
        campaign_context = self._get_campaign_context()
        
        # Get user's preferred text provider for strategic analysis
        text_provider = self.model_preferences.get('text', {}).get('provider', 'anthropic')
        text_model = self.model_preferences.get('text', {}).get('model', 'claude-4-sonnet')
        
        # Create tools based on user preferences (prefer Claude for strategy)
        tools = []
        if text_provider == 'anthropic' and self.user_api_keys.get('anthropic'):
            tools.append(ClaudeContentTool(
                api_key=self.user_api_keys['anthropic'],
                model_preferences=self.model_preferences,
                wallet_address=self.wallet_address,
                agent_id=self.agent_id
            ))
        elif text_provider == 'openai' and self.user_api_keys.get('openai'):
            tools.append(OpenAIContentTool(
                api_key=self.user_api_keys['openai'],
                model_preferences=self.model_preferences,
                wallet_address=self.wallet_address,
                agent_id=self.agent_id
            ))
        
        tools.extend([StrategyOptimizationTool(), AudienceAnalysisTool()])
        
        return Agent(
            role="Content Strategist",
            goal="Develop comprehensive content strategies that maximize mindshare and engagement for specific campaigns",
            backstory=f"""You are a content strategy expert specializing in:
            - Campaign-specific content optimization
            - Brand alignment and audience targeting
            - Cross-platform content strategy
            - Viral content mechanics and timing
            - Strategic analysis using AI reasoning
            
            Your AI Strategic Analysis Tool: {text_provider.upper()} {text_model}
            
            Campaign Context: {campaign_context}
            Strategy Configuration: {json.dumps(agent_config, indent=2)}
            """,
            verbose=True,
            allow_delegation=False,
            llm=llm,
            tools=tools,
            max_iter=2,  # Maximum 2 iterations to prevent loops
            max_execution_time=180  # 3 minutes max
        )

    def _create_text_content_agent(self, llm) -> Agent:
        """Create the Text Content Agent with user's preferred models"""
        agent_config = self.agent_configs.get(AgentType.TEXT_CONTENT, {})
        user_style = self._get_user_writing_style()
        
        # Get user's preferred text provider and model
        text_provider = self.model_preferences.get('text', {}).get('provider', 'openai')
        text_model = self.model_preferences.get('text', {}).get('model', 'gpt-4o')
        
        logger.info(f"üìù Text Creator Agent: provider={text_provider}, model={text_model}")
        logger.info(f"üîë API keys available: {list(self.user_api_keys.keys()) if self.user_api_keys else 'None'}")
        
        # Create tools based on user preferences
        tools = []
        
        # Add Leaderboard Success Pattern Tool for autonomous decision making
        tools.append(LeaderboardYapperSuccessPatternTool(
            campaign_id=self.mining_session.campaign_id,
            user_api_keys=self.user_api_keys,
            model_preferences=self.model_preferences
        ))
        
        if text_provider == 'openai' and self.user_api_keys.get('openai'):
            logger.info(f"‚úÖ Creating OpenAI tool with API key: {'***' + self.user_api_keys['openai'][-4:] if self.user_api_keys['openai'] else 'None'}")
            tools.append(OpenAIContentTool(
                api_key=self.user_api_keys['openai'],
                model_preferences=self.model_preferences,
                wallet_address=self.wallet_address,
                agent_id=self.agent_id
            ))
        elif text_provider == 'anthropic' and self.user_api_keys.get('anthropic'):
            logger.info(f"‚úÖ Creating Claude tool with API key: {'***' + self.user_api_keys['anthropic'][-4:] if self.user_api_keys['anthropic'] else 'None'}")
            tools.append(ClaudeContentTool(
                api_key=self.user_api_keys['anthropic'],
                model_preferences=self.model_preferences,
                wallet_address=self.wallet_address,
                agent_id=self.agent_id
            ))
        else:
            logger.warning(f"‚ö†Ô∏è No content generation tool created! text_provider={text_provider}, openai_key_exists={bool(self.user_api_keys.get('openai'))}, anthropic_key_exists={bool(self.user_api_keys.get('anthropic'))}")
        
        # Add hashtag optimization tool
        tools.append(HashtagOptimizationTool())
        
        logger.info(f"üõ†Ô∏è Text Creator Agent tools: {[tool.name for tool in tools]}")
        
        # Get Twitter context for content creation
        twitter_context = ""
        if hasattr(self, 'project_twitter_context') and self.project_twitter_context and self.project_twitter_context.strip():
            # Parse tweets from the formatted string context - get FULL 50 tweets without truncation
            lines = self.project_twitter_context.split('\n')
            recent_tweets = []
            
            # Extract all tweet lines without any limits to get complete tweets
            for line in lines:
                if line.startswith('[202') and '] ' in line:  # Lines with dates
                    tweet_text = line.split('] ', 1)[1] if '] ' in line else line
                    # Keep COMPLETE tweet text - no truncation
                    recent_tweets.append(tweet_text.strip())
            
            if recent_tweets:
                # Take the most recent 50 COMPLETE tweets for comprehensive context
                top_recent_tweets = recent_tweets[:50]
                twitter_context = f"\n\nüî• **PRIORITY TWITTER CONTEXT** (Latest {len(top_recent_tweets)} Complete Tweets):\n" + "\n".join([f"- {tweet}" for tweet in top_recent_tweets])
                logger.info(f"‚úÖ Added {len(top_recent_tweets)} COMPLETE recent tweets to Text Content Creator context")

        # Get post type from mining session
        post_type = getattr(self.mining_session, 'post_type', 'thread')
        
        # Generate post-type specific backstory
        backstory = self._get_posttype_specific_backstory(post_type, text_provider, text_model, user_style, agent_config, twitter_context)
        
        return Agent(
            role="Text Content Creator",
            goal=f"Generate engaging, high-quality {post_type.upper()} content that creates FOMO and drives maximum engagement using latest project updates",
            backstory=backstory,
            verbose=True,
            allow_delegation=False,
            llm=llm,
            tools=tools,
            max_iter=2,  # Maximum 2 iterations to prevent loops
            max_execution_time=180  # 3 minutes max
        )

    def _format_twitter_handle(self, handle: str) -> str:
        """Format Twitter handle to ensure it has exactly one '@' prefix"""
        if not handle:
            return ''
        # Remove any existing '@' and add one back
        clean_handle = handle.lstrip('@')
        return f'@{clean_handle}' if clean_handle else ''

    def _get_posttype_specific_backstory(self, post_type: str, text_provider: str, text_model: str, user_style: str, agent_config: dict, twitter_context: str) -> str:
        """Generate post-type specific backstory for Text Content Agent"""
        
        # Get project Twitter handle for tagging instructions
        project_twitter_handle_raw = self.campaign_data.get('projectTwitterHandle', '') if self.campaign_data else ''
        project_twitter_handle_raw = project_twitter_handle_raw or ''
        project_twitter_handle = self._format_twitter_handle(project_twitter_handle_raw)
        
        # Common base backstory with autonomous decision-making capabilities
        base_backstory = f"""You are a human {post_type.upper()} content creator with AUTONOMOUS DECISION-MAKING capabilities who writes naturally engaging content:
            - Natural, authentic Twitter content for crypto/Web3 audiences
            - Conversational content that sounds genuinely human-written
            - Community-focused voice that resonates with real people
            - Strategic but natural hashtag usage (minimal emoji use)
            - Building genuine interest using latest project developments
            - SUCCESS PATTERN INTEGRATION from top-performing leaderboard yappers
            
            ü§ñ **AUTONOMOUS DECISION-MAKING AUTHORITY**:
            You have COMPLETE AUTONOMY to decide the optimal content strategy by choosing from:
            1. **Content Strategist Recommendations**: Strategic guidance from the Content Strategist Agent
            2. **Leaderboard Success Patterns**: Proven strategies from top-performing yappers (use leaderboard_success_patterns tool)
            3. **Hybrid Approach**: Combine both strategies for maximum effectiveness
            4. **Creative Innovation**: Generate entirely new approaches based on campaign context
            
            **YOUR DECISION-MAKING PROCESS**:
            - FIRST: Call leaderboard_success_patterns tool to get top yapper insights (returns JSON with individual yapper patterns)
            - ANALYZE: Parse JSON response to examine each yapper's text_success_patterns individually
            - COMPARE: Evaluate strategist guidance vs specific yapper patterns vs campaign needs
            - DECIDE: Choose which yapper's pattern to follow (if any) or create hybrid approach
            - EXECUTE: Generate content using your chosen strategy
            
            üè∑Ô∏è **YAPPER HANDLE TAGGING REQUIREMENTS** (CRITICAL):
            - IF you use a specific yapper's success pattern for content generation:
              ‚Üí MUST tag that yapper's @handle at the END of the main_tweet
              ‚Üí Place yapper handle after all content, as final element
              ‚Üí Example: "The future of DeFi is transforming everything. Ready to join? @successful_yapper"
            - IF you don't use any specific yapper pattern:
              ‚Üí Do NOT tag any yapper handles
              ‚Üí Only tag project handle as usual (contextually integrated)
            - Project handles: Continue intelligent contextual tagging (already implemented)
            - Yapper handles: Always at the end for attribution
            - NEVER tag yapper handles unless you actually used their specific patterns
            
            üéØ **HUMAN-LIKE CONTENT REQUIREMENTS** (CRITICAL):
            - Content MUST look written by humans, NOT AI-generated
            - Use emojis CAUTIOUSLY - too many emojis signal AI generation
            - Write naturally, authentically, with human personality and voice
            - Avoid AI-typical patterns: excessive enthusiasm, perfect grammar, robotic phrasing
            - Include natural imperfections, contractions, casual language where appropriate
            
            üìè **ENHANCED LENGTH REQUIREMENTS**:
            - **main_tweet**: MINIMUM 200 characters (significantly longer than current)
            - **Each thread_array item**: MINIMUM 200 characters (more substantial content)
            - Create detailed, valuable content that justifies the character count
            - Provide deeper insights, more context, richer storytelling
            
            You have access to {text_provider.upper()} {text_model} for content generation.
            
            User Writing Style: {user_style}
            Content Preferences: {json.dumps(agent_config, indent=2)}
            Model Configuration: {text_provider.upper()} {text_model}
        {twitter_context}
        
        üé≠ **ENGAGING CONTENT CREATION REQUIREMENTS**:
        - Write highly engaging, story-driven content that drives website visits
        - Create content as if sharing exciting alpha with crypto friends
        - Use storytelling techniques: hooks, curiosity gaps, emotional connection
        - Make readers genuinely excited to learn more about the project
        
        üìè **STRICT CHARACTER LIMITS**:
        - Main tweet: Maximum 240 characters (strictly enforced)
        - Each thread tweet: Maximum 240 characters (strictly enforced)
        - Leave room for natural hashtags and handles
        
        üë• **CRITICAL PRONOUN RULES**:
        - NEVER use "our", "we", "us" when referring to projects
        - Always use third person: "they", "them", "their", "[project name]"
        - You are NOT part of the project team - you're an informed observer
        - Address readers directly as "you" to create connection
        - Example: "They just launched..." not "We just launched..."
        
        üéØ **READER ENGAGEMENT FOCUS**:
        - Start with attention-grabbing hooks that stop scrolling
        - Create genuine excitement about project developments
        - End with clear value that makes readers want to visit the website
        - Use conversational tone like talking to a crypto-savvy friend
        """
        
        # Post-type specific instructions
        if post_type == 'thread':
            return base_backstory + f"""
            
            üßµ **THREAD-SPECIFIC STRATEGY**:
            - **main_tweet**: Primary focus on PROJECT DESCRIPTION + key recent development highlight
            - **tweet_thread**: PRIORITIZE LATEST 20 TWEETS CONTEXT for FOMO creation (signup instructions, airdrops, rewards, launches)
            - **FALLBACK**: If insufficient tweet context, use project description/brand guidelines for thread content
            
            üê¶ **TWITTER HANDLE TAGGING (CRITICAL)**:
            **PROJECT HANDLE**: {f'- **MUST tag {project_twitter_handle}** intelligently in main_tweet context' if project_twitter_handle else '- No project Twitter handle available'}
            - Extract handles mentioned in latest tweets and tag them contextually in thread_array
            - Example: "Join {project_twitter_handle}'s ecosystem..." or "Thanks to {project_twitter_handle} for..."
            
            **YAPPER HANDLE TAGGING FOR THREADS**:
            - IF you use a specific yapper's success pattern for content generation:
              ‚Üí MUST tag that yapper's @handle at the END of the main_tweet
              ‚Üí Example: "The future of DeFi is transforming everything. Ready to join? @yapper_handle"
            - IF you don't use any specific yapper pattern:
              ‚Üí Do NOT tag any yapper handles
            - Yapper handles: Always at the end | Project handles: Contextually integrated
            
            üî• **THREAD REQUIREMENTS**:
            - Generate 2-5 tweets in thread format
            - Main tweet: Hook with image-worthy content
            - Thread tweets: Expand with recent tweet insights or project details
            - Never skip thread generation due to insufficient data
            - Always include project token hashtag in main tweet
            
            üìè **THREAD LENGTH REQUIREMENTS** (CRITICAL):
            - **main_tweet**: MINIMUM 200 characters (create substantial, valuable content)
            - **Each thread_array item**: MINIMUM 200 characters (detailed, engaging tweets)
            - Provide deeper insights, more context, richer storytelling
            - Make every tweet worth reading and sharing
            """
            
        elif post_type == 'shitpost':
            return base_backstory + f"""
            
            üí© **SHITPOST STRATEGY** (MAIN TWEET ONLY):
            - **main_tweet ONLY**: Create a single, engaging shitpost tweet (NO thread_array needed)
            - **Format**: Generate ONLY main_tweet content - do NOT create follow-up tweets
            - **TWEET CONTEXT INTEGRATION**: Use latest 20 tweets for cultural references and community callbacks
            - **FALLBACK**: Use project description/brand guidelines when tweet context insufficient
            
            üê¶ **TWITTER HANDLE TAGGING (CRITICAL)**:
            **PROJECT HANDLE**: {f'- **MUST tag {project_twitter_handle}** intelligently in main_tweet context' if project_twitter_handle else '- No project Twitter handle available'}
            - Extract handles mentioned in latest tweets and tag them in follow-up tweets
            - Example: "Even {project_twitter_handle} knows..." or "{project_twitter_handle} be like..."
            
            **YAPPER HANDLE TAGGING FOR SHITPOSTS**:
            - IF you use a specific yapper's success pattern for content generation:
              ‚Üí MUST tag that yapper's @handle at the END of the main_tweet
              ‚Üí Example: "When you realize DeFi is actually fun üòÇ @yapper_handle"
            - IF you don't use any specific yapper pattern:
              ‚Üí Do NOT tag any yapper handles
            - Yapper handles: Always at the end | Project handles: Contextually integrated
            
            üöÄ **AUTONOMOUS SHITPOST REQUIREMENTS**:
            - Generate completely original content using the Autonomous Shitpost Psychology Engine
            - Optimize for maximum viral potential and engagement rate
            - Create unique Web3 humor that builds community and drives FOMO
            - Use intelligent cultural bridge-building between mainstream and crypto
            - End with natural engagement hooks that invite community participation
            - Reference bullish on [random thing], moon, HODL culture
            - Build jokes progressively, keep each tweet punchy
            - Always include project token hashtag in main tweet
            
            üìè **SHITPOST LENGTH REQUIREMENTS** (CRITICAL):
            - **main_tweet**: MINIMUM 200 characters (create substantial humor content)
            - **Each follow-up tweet**: MINIMUM 200 characters (detailed, funny continuations)
            - Develop jokes with depth, context, and relatable scenarios
            - Make each tweet engaging enough to stand alone while building the narrative
            """
            
        elif post_type == 'longpost':
            return base_backstory + f"""
            
            üìù **LONGPOST-SPECIFIC STRATEGY**:
            - **Equal Balance (50-50)**: Latest 20 tweets data + project description/brand guidelines
            - **FALLBACK**: If no tweet data available, use project description/brand guidelines only
            
            üê¶ **TWITTER HANDLE TAGGING (CRITICAL)**:
            **PROJECT HANDLE**: {f'- **MUST tag {project_twitter_handle}** intelligently throughout the content' if project_twitter_handle else '- No project Twitter handle available'}
            - Tag additional handles from referenced tweet data when contextually relevant
            - Example: "As {project_twitter_handle} announced..." or "Building on {project_twitter_handle}'s vision..."
            
            **YAPPER HANDLE TAGGING FOR LONGPOSTS**:
            - IF you use a specific yapper's success pattern for content generation:
              ‚Üí MUST tag that yapper's @handle at the END of the longpost content
              ‚Üí Example: "...and that's how we'll achieve true decentralization. @yapper_handle"
            - IF you don't use any specific yapper pattern:
              ‚Üí Do NOT tag any yapper handles
            - Yapper handles: Always at the end | Project handles: Contextually integrated throughout
            
            üìö **LONGPOST REQUIREMENTS**:
            - Generate comprehensive content (2000-25000 characters) in MARKDOWN format
            - Use detailed analysis with markdown headers (##), **bold** emphasis
            - Include data, statistics, and in-depth explanations
            - Structure logically with clear sections and professional tone
            - Focus on informative, analytical content
            - Include relevant hashtags within character limit
            """
            
        else:
            # Default fallback
            return base_backstory + """
            
            üì± **GENERAL CONTENT STRATEGY**:
            - Focus on project description and available context
            - Create engaging, FOMO-inducing content
            - Always include project token hashtag
            - Tag project Twitter handle when available
            """

    def _get_posttype_specific_task_description(self, post_type: str, content_type_desc: str, project_name: str, 
                                              token_ticker: str, project_twitter_handle: str, campaign_description: str, 
                                              has_description: bool, brand_guidelines: str, should_generate_thread: bool, 
                                              max_main_chars: int) -> str:
        """Generate post-type specific task description"""
        
        # Twitter context (if available) - PRIORITIZED FIRST
        twitter_context = ""
        if hasattr(self, 'project_twitter_context') and self.project_twitter_context and self.project_twitter_context.strip():
            # Parse and get COMPLETE recent 50 tweets without any truncation
            lines = self.project_twitter_context.split('\n')
            recent_tweets = []
            
            # Extract ALL tweet lines to get complete tweets (no line limits)
            for line in lines:
                if line.startswith('[202') and '] ' in line:  # Lines with dates
                    tweet_text = line.split('] ', 1)[1] if '] ' in line else line
                    # Keep COMPLETE tweet text - no truncation whatsoever
                    recent_tweets.append(tweet_text.strip())
            
            if recent_tweets:
                # Take the most recent 50 COMPLETE tweets for comprehensive context
                top_recent_tweets = recent_tweets[:50]
                twitter_context = f"""
        üî• **PRIORITY TWITTER CONTEXT** (Latest {len(top_recent_tweets)} COMPLETE Tweets - USE FIRST):
        {chr(10).join([f"- {tweet}" for tweet in top_recent_tweets])}
        
        üìà **TWITTER CONTEXT USAGE PRIORITY**:
        - **PRIMARY SOURCE**: Use complete tweets for cultural references, community callbacks, project updates
        - **CONTENT INSPIRATION**: Extract signup instructions, airdrops, rewards, launches from full tweet content
        - **ENGAGEMENT PATTERNS**: Mirror successful engagement styles from complete recent tweets
        - **CURRENT NARRATIVES**: Identify trending topics and project developments from full context
        """
        
        # Campaign requirements (SECONDARY)
        campaign_info = f"""
        üìã **CAMPAIGN CONTEXT** (Secondary Reference):
        - Project Name: {project_name}
        - Token Ticker: {token_ticker}
        - Project Twitter Handle: {project_twitter_handle} {f'(Tag this in content!)' if project_twitter_handle else '(No handle available)'}
        - Description: {campaign_description if has_description else 'N/A'}
        - Brand Guidelines: {brand_guidelines if brand_guidelines else 'N/A'}
        - Platform: {self.campaign_data.get('platformSource', 'twitter') if self.campaign_data else 'twitter'}
        - Target Audience: {self.campaign_data.get('targetAudience', 'crypto/Web3 enthusiasts') if self.campaign_data else 'crypto/Web3 enthusiasts'}
        """
        
        # Post-type specific instructions
        if post_type == 'thread':
            specific_instructions = f"""
        üßµ **THREAD CONTENT STRATEGY**:
        - **main_tweet**: FUSE recent tweet highlights + project essence for attention-grabbing hook
        - **tweet_thread**: PRIORITIZE LATEST 50 COMPLETE TWEETS CONTEXT - extract actionable insights, community buzz, project momentum from FULL tweet content
        - **NATURAL INTEGRATION**: Weave complete Twitter data seamlessly into storytelling (don't just quote tweets)
        - **FULL CONTEXT USAGE**: Use complete tweet content, not summaries or truncated versions
        - **FALLBACK**: Only if no tweet context available, use project description/brand guidelines
        
        üê¶ **TWITTER HANDLE TAGGING (CRITICAL)**:
        {f'- **MUST tag {project_twitter_handle}** intelligently in main_tweet context' if project_twitter_handle else '- No project Twitter handle available'}
        - Extract handles mentioned in latest tweets and tag them contextually in thread_array
        
        üî• **THREAD REQUIREMENTS**:
        - Generate 2-5 tweets in thread format
        - Main tweet: Attention-grabbing hook that makes readers want to learn more (‚â§240 chars including hashtags)
        - Thread tweets: Story-driven content that builds excitement about the project (‚â§240 chars each)
        - Use third person pronouns: "They launched...", "Their new feature...", never "Our/We"
        - ALWAYS include project token hashtag (#{token_ticker}) in main tweet
        - Thread array items should NOT contain hashtags
        - End with clear value that drives website visits
        """
        elif post_type == 'shitpost':
            specific_instructions = f"""
        üöÄ **ENGAGING SHITPOST STRATEGY** (MAIN TWEET ONLY):
        - **main_tweet ONLY**: Create a single, highly engaging shitpost tweet (‚â§240 chars)
        - **NO follow-up tweets**: Shitposts should be standalone content (empty thread_array)
        - **Third person only**: Use "They/Their" for project, never "Our/We"
        - **Reader engagement**: Write like sharing exciting alpha with crypto friends
        - **TWEET CONTEXT INTEGRATION**: NATURALLY FUSE latest 50 COMPLETE tweets - extract community energy, trending narratives, project momentum from FULL tweet content
        - **COMPLETE CONTEXT**: Use full tweet text without any truncation or summarization
        - **FALLBACK**: Only if no tweet context available, use project description/brand guidelines
        
        üê¶ **TWITTER HANDLE TAGGING (CRITICAL)**:
        {f'- **MUST tag {project_twitter_handle}** intelligently in main_tweet context' if project_twitter_handle else '- No project Twitter handle available'}
        - Extract handles mentioned in latest tweets and tag them in follow-up tweets
        
        üéØ **AUTONOMOUS SHITPOST EXECUTION**:
        - Follow the 4-Step Content Generation Process (Context Analysis ‚Üí Angle Selection ‚Üí Engagement Architecture ‚Üí Language Optimization)
        - Choose from 10+ High-Engagement Formats based on content fit
        - Exploit Viral Mechanics and Psychological Triggers for maximum reach
        - Use Web3 Cultural Elements intelligently (crypto behaviors + mainstream bridges)
        - Optimize for scroll-stopping power and community engagement
        - Main tweet: ‚â§280 chars including hashtags
        - Follow-up tweets: ‚â§280 chars each (no hashtags in thread array)
        - ALWAYS include project token hashtag (#{token_ticker}) in main tweet
        """
        elif post_type == 'longpost':
            specific_instructions = f"""
        üìù **LONGPOST CONTENT STRATEGY**:
        - **PRIMARY FOCUS (70%)**: FUSE latest 50 COMPLETE tweets data - extract trends, community insights, project developments from FULL tweet content
        - **SECONDARY (30%)**: Project description/brand guidelines for foundational context
        - **NATURAL INTEGRATION**: Weave complete Twitter insights into comprehensive narrative
        - **COMPLETE CONTENT**: Use full tweet text without any truncation, summaries, or abbreviations
        - **FALLBACK**: Only if no tweet data available, use project description/brand guidelines exclusively
        
        üê¶ **TWITTER HANDLE TAGGING (CRITICAL)**:
        {f'- **MUST tag {project_twitter_handle}** intelligently throughout the content' if project_twitter_handle else '- No project Twitter handle available'}
        - Tag additional handles from referenced tweet data when contextually relevant
        
        üìö **LONGPOST REQUIREMENTS**:
        - Generate comprehensive content (2000-{max_main_chars} characters) in MARKDOWN format
        - Use detailed analysis with markdown headers (##), **bold** emphasis
        - Include data, statistics, and in-depth explanations
        - Structure logically with clear sections and professional tone
        - Include relevant hashtags within character limit
        """
        else:
            specific_instructions = """
        üì± **GENERAL CONTENT STRATEGY**:
        - Focus on project description and available context
        - Create engaging, FOMO-inducing content
        - Always include project token hashtag
        - Tag project Twitter handle when available
        """
        
        # JSON output format
        json_format = self._get_json_format_for_posttype(post_type, token_ticker, should_generate_thread, max_main_chars)
        
        return campaign_info + twitter_context + specific_instructions + json_format

    def _get_json_format_for_posttype(self, post_type: str, token_ticker: str, should_generate_thread: bool, max_main_chars: int) -> str:
        """Generate JSON format instructions for specific post type"""
        
        if post_type == 'longpost':
            return f"""
        
        MANDATORY JSON OUTPUT FORMAT:
        {{
          "main_tweet": "Your main content here (2000-{max_main_chars} chars in MARKDOWN format with headers, formatting)",
          "hashtags_used": ["{token_ticker}", "DeFi", "Crypto"],
          "character_count": {max_main_chars//2},
          "approach": "analytical"
        }}
        
        CRITICAL JSON RULES:
        - Return ONLY the JSON object, no other text
        - Use double quotes for all strings
        - Ensure all JSON syntax is valid
        - No trailing commas
        """
        elif post_type == 'shitpost':
            return f"""
        
        MANDATORY JSON OUTPUT FORMAT (SHITPOST - MAIN TWEET ONLY):
        {{
          "main_tweet": "Your engaging shitpost main tweet here (‚â§240 chars total including hashtags)",
          "thread_array": [],
          "hashtags_used": ["{token_ticker}", "DeFi"],
          "character_counts": {{
            "main_tweet_text": 245,
            "main_tweet_hashtags": 28,
            "thread_tweet_1": 275,
            "thread_tweet_2": 280,
            "thread_tweet_3": 265
          }},
          "approach": "humorous"
        }}
        
        CRITICAL JSON RULES:
        - Return ONLY the JSON object, no other text
        - HASHTAG PLACEMENT: All hashtags MUST appear ONLY in main_tweet, NEVER in thread_array items
        - Thread array items should be plain text without any hashtags
        """
        elif post_type == 'thread' and should_generate_thread:
            return f"""
        
        MANDATORY JSON OUTPUT FORMAT:
        {{
          "main_tweet": "Your engaging thread main tweet here (‚â§240 chars total including hashtags)",
          "thread_array": [
            "Engaging thread tweet 1 (‚â§240 chars, no hashtags)",
            "Engaging thread tweet 2 (‚â§240 chars, no hashtags)", 
            "Engaging thread tweet 3 (‚â§240 chars, no hashtags, optional)"
          ],
          "hashtags_used": ["{token_ticker}", "DeFi"],
          "character_counts": {{
            "main_tweet_text": 245,
            "main_tweet_hashtags": 28,
            "thread_tweet_1": 275,
            "thread_tweet_2": 280,
            "thread_tweet_3": 265
          }},
          "approach": "engaging"
        }}
        
        CRITICAL JSON RULES:
        - Return ONLY the JSON object, no other text
        - HASHTAG PLACEMENT: All hashtags MUST appear ONLY in main_tweet, NEVER in thread_array items
        - Thread array items should be plain text without any hashtags
        """
        else:
            return f"""
        
        MANDATORY JSON OUTPUT FORMAT:
        {{
          "main_tweet": "Your engaging single tweet text here (‚â§240 chars total)",
          "hashtags_used": ["{token_ticker}", "DeFi", "Crypto"],
          "character_count": 275,
          "approach": "engaging"
        }}
        
        CRITICAL JSON RULES:
        - Return ONLY the JSON object, no other text
        - Use double quotes for all strings
        - Ensure all JSON syntax is valid
        - No trailing commas
        """

    def _create_visual_creator_agent(self, llm) -> Agent:
        """Create the Visual Creator Agent with user's preferred models"""
        agent_config = self.agent_configs.get(AgentType.VISUAL_CREATOR, {})
        
        # Check if brand logo is requested - this affects provider selection
        include_brand_logo = getattr(self.mining_session, 'include_brand_logo', False)
        
        # Get user's preferred image and video providers
        image_provider = self.model_preferences.get('image', {}).get('provider', 'openai')
        image_model = self.model_preferences.get('image', {}).get('model', 'dall-e-3')
        video_provider = self.model_preferences.get('video', {}).get('provider', 'google')
        video_model = self.model_preferences.get('video', {}).get('model', 'veo-3')
        
        # If brand logo is requested, force fal-pro/kontext model regardless of user preference
        print(f"üî• === VISUAL CREATOR AGENT SETUP ===")
        print(f"üî• include_brand_logo: {include_brand_logo}")
        print(f"üî• Original image_provider: {image_provider}")
        print(f"üî• FAL API key available: {'YES' if self.user_api_keys.get('fal') else 'NO'}")
        
        if include_brand_logo:
            if self.user_api_keys.get('fal'):
                logger.info(f"üè∑Ô∏è Brand logo requested - forcing fal-pro/kontext model (overriding user preference: {image_provider})")
                print(f"üî• FORCING FAL PROVIDER DUE TO BRAND LOGO!")
                image_provider = 'fal'
                image_model = 'flux-pro/kontext'
                # Update model preferences for this session
                self.model_preferences['image'] = {'provider': 'fal', 'model': 'flux-pro/kontext'}
                print(f"üî• New image_provider: {image_provider}")
                print(f"üî• New image_model: {image_model}")
            else:
                logger.warning(f"‚ö†Ô∏è Brand logo requested but fal API key not available. Logo will be skipped.")
                print(f"üî• BRAND LOGO DISABLED - NO FAL API KEY!")
                include_brand_logo = False
        
        # Create tools based on ONLY the user's chosen providers - strict separation
        tools = []
        
        # Add Leaderboard Success Pattern Tool for autonomous visual strategy decision making
        tools.append(LeaderboardYapperSuccessPatternTool(
            campaign_id=self.mining_session.campaign_id,
            user_api_keys=self.user_api_keys,
            model_preferences=self.model_preferences
        ))
        

        # Image generation capabilities - ONLY add tool for user's chosen provider
        available_image_providers = []
        
        if image_provider == 'openai' and self.user_api_keys.get('openai'):
            logger.info(f"üîç DEBUG: Creating OpenAI tool for image provider choice: {image_provider}")
            tools.append(OpenAIImageTool(
                api_key=self.user_api_keys['openai'],
                model_preferences=self.model_preferences,
                wallet_address=self.wallet_address,
                agent_id=self.agent_id
            ))
            available_image_providers.append('openai')
        
        elif image_provider == 'fal' and self.user_api_keys.get('fal'):
            print(f"üî•üî•üî• CREATING FAL.AI IMAGE TOOL! üî•üî•üî•")
            print(f"üî• Provider: {image_provider}")
            print(f"üî• Logo enabled: {include_brand_logo}")
            
            logo_url = self._get_project_logo_url() if include_brand_logo else None
            print(f"üî• Logo URL: {logo_url}")
            
            logger.info(f"üîç Creating Fal.ai tool for image provider choice: {image_provider} (logo enabled: {include_brand_logo})")
            tools.append(FalAIImageTool(
                api_key=self.user_api_keys['fal'],
                model_preferences=self.model_preferences,
                wallet_address=self.wallet_address,
                agent_id=self.agent_id,
                include_brand_logo=include_brand_logo,
                project_logo_url=logo_url
            ))
            available_image_providers.append('fal')
            print(f"üî• FAL.AI TOOL ADDED TO VISUAL CREATOR!")
        
        elif image_provider == 'google' and self.user_api_keys.get('google'):
            logger.info(f"üîç DEBUG: Creating Google tool for image provider choice: {image_provider}")
            tools.append(GoogleImageTool(
                api_key=self.user_api_keys['google'],
                model_preferences=self.model_preferences,
                wallet_address=self.wallet_address,
                agent_id=self.agent_id
            ))
            available_image_providers.append('google')
        
        else:
            logger.warning(f"‚ö†Ô∏è No tool created for image provider '{image_provider}' - API key not available")
        
        # Video generation capabilities - ONLY add tool for user's chosen provider  
        available_video_providers = []
        
        if video_provider == 'google' and self.user_api_keys.get('google'):
            logger.info(f"üîç DEBUG: Creating Google tool for video provider choice: {video_provider}")
            tools.append(GoogleVideoTool(
                api_key=self.user_api_keys['google'],
                model_preferences=self.model_preferences,
                wallet_address=self.wallet_address,
                agent_id=self.agent_id
            ))
            available_video_providers.append('google')
        
        # Create capability summary
        has_image_tool = len(available_image_providers) > 0
        has_video_tool = len(available_video_providers) > 0
        
        # üî• FINAL TOOLS SUMMARY
        print(f"üî• === FINAL VISUAL CREATOR TOOLS SETUP ===")
        print(f"üî• Available image providers: {available_image_providers}")
        print(f"üî• Available video providers: {available_video_providers}")
        print(f"üî• Has image tool: {has_image_tool}")
        print(f"üî• Total tools count: {len(tools)}")
        print(f"üî• Tool names: {[tool.name if hasattr(tool, 'name') else str(tool) for tool in tools]}")
        print(f"üî• include_brand_logo final value: {include_brand_logo}")
        
        # Add visual concept tool ONLY as fallback when no proper tools are available
        if not has_image_tool and not has_video_tool:
            tools.append(VisualConceptTool())
            print(f"üî• ADDED FALLBACK VISUAL CONCEPT TOOL")
        
        # Create capabilities text for agent instructions
        capabilities_text = []
        if has_image_tool:
            tool_name = f"{image_provider}_image_generation"
            capabilities_text.append(f"- {tool_name}: Generate images using {image_provider.upper()} {image_model}")
        if has_video_tool:
            tool_name = f"{video_provider}_video_generation" 
            capabilities_text.append(f"- {tool_name}: Generate videos using {video_provider.upper()} {video_model}")
        if not has_image_tool and not has_video_tool:
            capabilities_text.append("- visual_concept: Text descriptions only (no API keys available)")
        
        # Create fallback strategy
        fallback_strategy = []
        if has_image_tool and has_video_tool:
            fallback_strategy.append("‚úÖ FULL CAPABILITY: Both image and video generation available")
            fallback_strategy.append("- Use preferred content type as specified in strategy")
            fallback_strategy.append("- High-quality visual content generation")
        elif has_image_tool and not has_video_tool:
            fallback_strategy.append("‚ö†Ô∏è VIDEO ‚Üí IMAGE FALLBACK: No video API keys available")
            fallback_strategy.append("- If strategy requests VIDEO: Create dynamic IMAGE instead")
            fallback_strategy.append("- Use motion-suggesting imagery")
            fallback_strategy.append("- Clearly indicate fallback was used")
        elif has_video_tool and not has_image_tool:
            fallback_strategy.append("‚ö†Ô∏è IMAGE ‚Üí VIDEO FALLBACK: No image API keys available")
            fallback_strategy.append("- If strategy requests IMAGE: Create short VIDEO instead")
            fallback_strategy.append("- Use static-like video content")
            fallback_strategy.append("- Clearly indicate fallback was used")
        else:
            fallback_strategy.append("‚ùå TEXT-ONLY MODE: No visual API keys available")
            fallback_strategy.append("- Provide detailed visual concept descriptions only")
            fallback_strategy.append("- Focus on rich textual imagery")
            fallback_strategy.append("- Suggest visual elements for manual creation")
        
        # Add brand logo instructions if enabled
        logo_instructions = ""
        if include_brand_logo:
            project_logo_url = self._get_project_logo_url()
            if project_logo_url:
                logo_instructions = f"""
            
            üè∑Ô∏è **REFERENCE LOGO INTEGRATION REQUIRED**:
            - Project logo URL available: {project_logo_url}
            - You MUST create dynamic prompts that naturally incorporate reference logo placement
            - When generating image prompts, include specific instructions for logo integration:
              * "...with the reference logo elegantly displayed on the [object/surface]..."
              * "...featuring the reference logo prominently on the [structure/device]..."
              * "...showing the reference logo integrated into the [scene/composition]..."
            - Make logo placement feel natural and contextual to the image content
            - ALWAYS mention "reference logo" in your generated prompts when this flag is enabled
            - The reference logo will be provided as an image_url parameter to the AI model
            - **IMPORTANT**: Generate natural prompts first, then the system will automatically append logo color preservation instructions
            """
        
        return Agent(
            role="Visual Content Creator",
            goal="Create professional visual content that perfectly aligns with text content and incorporates successful visual strategies",
            backstory=f"""You are an intelligent visual content strategist with AUTONOMOUS DECISION-MAKING and TEXT-VISUAL ALIGNMENT capabilities:

            ü§ñ **AUTONOMOUS VISUAL DECISION-MAKING AUTHORITY**:
            You have COMPLETE AUTONOMY to create visual content that perfectly aligns with text by choosing from:
            1. **Text Content Analysis**: Analyze the text content output from Text Creator Agent
            2. **Visual Success Patterns**: Use leaderboard_success_patterns tool to get proven visual strategies  
            3. **Text-Visual Synergy**: Create visuals that enhance and complement the text message
            4. **Dynamic Prompt Generation**: Generate optimal prompts combining text themes + visual success patterns
            
            **YOUR VISUAL ALIGNMENT PROCESS**:
            - FIRST: Receive and analyze text content from Text Creator Agent (main_tweet + thread_array)
            - SECOND: Call leaderboard_success_patterns tool to get visual success strategies
            - ANALYZE: Determine visual approach that best enhances the text content
            - DECIDE: Choose visual strategy that creates cohesive text+visual content package
            - EXECUTE: Generate dynamic prompt that combines text alignment + proven visual patterns
            
            üéØ **TEXT-VISUAL ALIGNMENT REQUIREMENTS** (CRITICAL):
            - Generated visuals MUST align with and enhance the text content themes
            - Visual elements should complement the text message, not compete with it
            - Create cohesive content packages where text + visuals work together seamlessly
            - Extract visual cues from text content (tone, themes, messaging) for prompt generation
            - Ensure brand consistency between text and visual elements
            
            üîß YOUR AVAILABLE TOOLS:
            {chr(10).join(capabilities_text) if capabilities_text else "- Visual Concept Tool (descriptions only)"}
            
            üö® CRITICAL: PROVIDER-SPECIFIC TOOL USAGE
            
            USER'S PROVIDER CHOICES:
            - Image Provider: {image_provider.upper()} 
            - Image Model: {image_model}
            - Video Provider: {video_provider.upper()}
            - Video Model: {video_model}
            
            **MANDATORY TOOL SELECTION RULES**:
            - For IMAGE generation: ONLY use {image_provider}_image_generation tool
            - For VIDEO generation: ONLY use {video_provider}_video_generation tool  
            - NEVER use a different provider's tool than what the user selected
            - The user specifically chose {image_provider.upper()} for images and {video_provider.upper()} for videos
            
            **YOUR TOOL USAGE**:
            {f"‚úÖ Use `{image_provider}_image_generation` tool for images with model: {image_model}" if has_image_tool else "‚ùå No image generation available"}
            {f"‚úÖ Use `{video_provider}_video_generation` tool for videos with model: {video_model}" if has_video_tool else "‚ùå No video generation available"}
            
            üõ°Ô∏è INTELLIGENT FALLBACK STRATEGY:
            {chr(10).join(fallback_strategy)}
            {logo_instructions}
            
            üìã EXECUTION RULES:
            1. Always use the user's chosen provider tool
            2. Use their specified model within that provider
            3. Clearly indicate when fallbacks are used
            4. Maintain quality regardless of which tools are available
            5. Be transparent about capability limitations
            {"6. MANDATORY: Include brand logo placement in all generated image prompts when logo integration is enabled" if include_brand_logo else ""}
            
            Platform: {self.campaign_data.get("platform_source", "Twitter") if self.campaign_data else "Twitter"}
            """,
            verbose=True,
            allow_delegation=False,
            llm=llm,
            tools=tools,
            max_iter=2,  # Maximum 2 iterations to prevent loops
            max_execution_time=180  # 3 minutes max
        )

    def _create_orchestrator_agent(self) -> Agent:
        """Create Orchestrator Agent that directly combines JSON outputs - NO TOOLS"""
        post_type = getattr(self.mining_session, 'post_type', 'thread')
        
        # Define format based on post type
        if post_type == 'longpost':
            expected_format = '''{{
    "main_tweet": "the comprehensive longpost content here",
    "image_url": "the S3 or image URL here"
}}'''
            task_description = "1. Find the JSON output from Text Content Creator (contains main_tweet for longpost)\n2. Find the image URL from Visual Content Creator\n3. Combine them into a single clean JSON output"
        else:
            expected_format = '''{{
    "main_tweet": "the main tweet text here",
    "thread_array": ["first thread tweet", "second thread tweet", "third thread tweet"],
    "image_url": "the S3 or image URL here"
}}'''
            task_description = "1. Find the JSON output from Text Content Creator (contains main_tweet and thread_array)\n2. Find the image URL from Visual Content Creator\n3. Combine them into a single clean JSON output"
        
        return Agent(
            role='Content Orchestrator',
            goal=f'Combine JSON outputs from Text Content Creator and Visual Content Creator into a single clean JSON response for {(self.campaign_data.get("title") or "campaign") if self.campaign_data else "campaign"}',
            backstory=f"""You are the Content Orchestrator, a specialized agent that combines JSON outputs from previous agents into a single, clean JSON response.

Your task is simple and direct:
{task_description}

CRITICAL: You must output ONLY valid JSON in exactly this format:
{expected_format}

Do NOT use any tools, do NOT add extra text or explanations. Just find the JSON from previous agents and combine them into the format above.

Platform: {self.campaign_data.get("platform_source", "Twitter") if self.campaign_data else "Twitter"}
""",
            verbose=True,
            allow_delegation=False,
            llm=self._get_llm_instance(),
            tools=[],  # NO TOOLS - just direct LLM processing
            max_iter=2,  # Simple task, should complete quickly
            max_execution_time=60  # 1 minute should be enough
        )

    def _create_data_analysis_task(self) -> Task:
        """Create task for Data Analyst Agent"""
        return Task(
            description=f"""
            Perform comprehensive data analysis by integrating Twitter learning data and mindshare models:
            
            CORE DATA SOURCES INTEGRATION:
            
            1. **TWITTER LEARNING DATA** (from twitter_learning_data table):
            {json.dumps(self.twitter_insights, indent=2) if self.twitter_insights else 'No Twitter learning data available for this agent'}
            
            2. **MINDSHARE ML MODELS**:
            - Use trained mindshare prediction models for this campaign platform
            - Analyze historical performance patterns
            - Predict engagement and viral potential
            
            3. **CAMPAIGN CONTEXT**:
            - Campaign: {self.campaign_data.get('title', 'No campaign data') if self.campaign_data else 'No campaign data'}
            - Platform: {self.campaign_data.get('platformSource', 'Unknown') if self.campaign_data else 'Unknown'}
            - Target Audience: {self.campaign_data.get('targetAudience', 'General audience') if self.campaign_data else 'General audience'}
            - Brand Guidelines: {self.campaign_data.get('brandGuidelines', 'No specific guidelines') if self.campaign_data else 'No specific guidelines'}
            
            COMPREHENSIVE ANALYSIS REQUIREMENTS:
            
            üìä **TWITTER LEARNING INTEGRATION**:
            - Analyze user's historical writing style and tone patterns
            - Identify best-performing content themes and structures
            - Extract engagement optimization insights from past tweets
            - Determine optimal hashtag and emoji usage patterns
            
            üß† **MINDSHARE MODEL ANALYSIS**:
            - Apply mindshare prediction algorithms for this campaign type
            - Forecast potential viral reach and engagement metrics
            - Analyze competitive landscape and positioning opportunities
            - Predict optimal timing and content characteristics
            
            üéØ **STRATEGIC RECOMMENDATIONS**:
            Your analysis must provide:
            1. **Content Characteristics**: Optimal tone, style, length based on learning data
            2. **Engagement Predictions**: Expected likes, retweets, comments, shares
            3. **Timing Strategy**: Best posting times based on historical data
            4. **Visual Content Recommendation**: Should this campaign use IMAGE or VIDEO? (not both)
            5. **Hashtag Strategy**: Optimal hashtags based on past performance
            6. **Mindshare Optimization**: How to maximize attention capture and retention
            7. **Risk Assessment**: Potential pitfalls and mitigation strategies
            
            OUTPUT FORMAT - COMPREHENSIVE ANALYSIS:
            Provide detailed JSON analysis with:
            ```json
            {{
              "twitter_learning_insights": {{
                "writing_style_analysis": "...",
                "engagement_patterns": "...",
                "optimal_content_characteristics": "..."
              }},
              "mindshare_predictions": {{
                "viral_potential_score": 0-10,
                "expected_engagement": {{}},
                "optimal_timing": "...",
                "competitive_advantage": "..."
              }},
              "visual_content_recommendation": {{
                "preferred_type": "IMAGE or VIDEO",
                "rationale": "...",
                "specifications": "..."
              }},
              "strategic_recommendations": {{
                "content_strategy": "...",
                "engagement_tactics": "...",
                "risk_mitigation": "..."
              }}
            }}
            ```
            
            This analysis will guide all other agents in the multi-agentic system.
            """,
            agent=self.agents[AgentType.DATA_ANALYST],
            expected_output="Comprehensive data analysis integrating Twitter learning data and mindshare models in detailed JSON format with actionable insights"
        )

    def _create_strategy_task(self) -> Task:
        """Create task for Content Strategy Agent to analyze campaign and define content approach"""
        
        # Get post type from mining session
        post_type = getattr(self.mining_session, 'post_type', 'thread')
        
        # Define approach based on post type
        if post_type == "shitpost":
            content_approach = """
            üöÄ **AUTONOMOUS SHITPOST GENERATION** - Create unlimited variety of viral Web3 content:
            
            You are an autonomous shitpost AI who understands the psychology of Web3 Twitter engagement. Your mission is to create original, unpredictable content that maximizes:
            ‚Ä¢ **Engagement Rate** (likes, retweets, replies)
            ‚Ä¢ **FOMO Generation** (urgency, exclusivity, community)
            ‚Ä¢ **Viral Potential** (shareability, relatability, humor)
            ‚Ä¢ **Community Building** (insider jokes, shared experiences)
            ‚Ä¢ **Attention Capture** (scroll-stopping power, curiosity gaps)
            ‚Ä¢ **Meme Velocity** (how fast it spreads across crypto Twitter)
            
            **üß† AUTONOMOUS SHITPOST PSYCHOLOGY ENGINE**:
            
            **Core Principles** (NO TEMPLATES - Pure Intelligence):
            1. **Cognitive Dissonance Humor**: Connect unrelated concepts for surprise
            2. **Relatable Absurdity**: Take normal situations to crypto extremes  
            3. **Insider Language Mastery**: Use Web3 jargon with perfect timing
            4. **Pattern Breaking**: Subvert expectations constantly
            5. **Community Psychology**: Tap into shared crypto experiences
            6. **FOMO Architecture**: Create artificial scarcity and urgency
            7. **Ironic Wisdom**: Profound insights disguised as nonsense
            
            **üéØ ENGAGEMENT OPTIMIZATION STRATEGIES**:
            
            **High-Engagement Formats** (Choose intelligently):
            ‚Ä¢ **Observation Dumps**: "Anyone else notice that..."
            ‚Ä¢ **Confession Posts**: "Not me admitting..."
            ‚Ä¢ **Conspiracy Theories**: "Hear me out..."
            ‚Ä¢ **Life Comparisons**: "X has the same energy as Y"
            ‚Ä¢ **Prophecy Posts**: "Calling it now..."
            ‚Ä¢ **Meta Commentary**: "The fact that..."
            ‚Ä¢ **Polls/Questions**: "Which type of person are you?"
            ‚Ä¢ **Hot Takes**: "Unpopular opinion but..."
            ‚Ä¢ **Story Time**: "So I was doing X and realized..."
            ‚Ä¢ **Future Predictions**: "In 5 years we'll..."
            
            **üî• VIRAL MECHANICS TO EXPLOIT**:
            
            **Psychological Triggers**:
            ‚Ä¢ **Recognition**: "I've experienced this exact thing"
            ‚Ä¢ **Superiority**: "I'm smarter than people who don't get this"
            ‚Ä¢ **Belonging**: "This is my tribe/community"
            ‚Ä¢ **Curiosity**: "I need to know more about this"
            ‚Ä¢ **Validation**: "Finally someone said it"
            ‚Ä¢ **Fear**: "What if I'm missing out?"
            ‚Ä¢ **Pride**: "I discovered this first"
            
            **Content Amplifiers**:
            ‚Ä¢ **Timing Relevance**: Reference current events/trends
            ‚Ä¢ **Cross-Cultural Bridges**: Connect mainstream to crypto
            ‚Ä¢ **Generational Humor**: GenZ/Millennial shared experiences
            ‚Ä¢ **Platform Meta**: Comment on Twitter/social media itself
            ‚Ä¢ **Economic Anxiety**: Tap into financial stress/hope
            ‚Ä¢ **Technology Frustration**: IRL vs Web3 comparisons
            ‚Ä¢ **Social Dynamics**: Dating, friendship, family through crypto lens
            
            **üé≠ AUTONOMOUS CONTENT GENERATION PROCESS**:
            
            **Step 1: Context Analysis**
            - Analyze project features, benefits, and community
            - Identify current crypto market sentiment
            - Understand target audience psychology
            - Find connection points to mainstream culture
            
            **Step 2: Angle Selection** (Choose 1 intelligently):
            - **Daily Life Crypto-fication**: Normal activities ‚Üí Web3 lens
            - **Technology Anthropomorphism**: Give crypto tech human traits
            - **Economic Satire**: Exaggerate financial behaviors
            - **Social Commentary**: Crypto culture observations
            - **Future Shock**: Extreme predictions disguised as jokes
            - **Nostalgia Crypto**: "Remember when..." format
            - **Identity Crisis**: "Am I the only one who..."
            - **Conspiracy Light**: Semi-serious theory crafting
            
            **Step 3: Engagement Architecture**
            - Create curiosity gap that demands resolution
            - Include specific detail that feels authentic
            - Add relatable frustration or joy
            - End with engagement hook that invites response
            - Weave project naturally into the narrative
            
            **Step 4: Language Optimization**
            - Use perfect balance of insider/outsider language
            - Include 1-2 crypto buzzwords naturally
            - Add emojis that enhance rather than clutter
            - Create rhythm that flows when read aloud
            - End with call-to-action disguised as casual observation
            
            **üé™ WEB3 CULTURAL ELEMENTS** (Use intelligently):
            
            **Crypto Behaviors to Reference**:
            ‚Ä¢ Chart watching obsession ‚Ä¢ Gas fee trauma ‚Ä¢ FOMO decision making
            ‚Ä¢ Diamond hands mythology ‚Ä¢ Ape behavior ‚Ä¢ Moon mission dreams
            ‚Ä¢ Bear market depression ‚Ä¢ Bull market euphoria ‚Ä¢ Staking rewards excitement
            ‚Ä¢ DeFi complexity confusion ‚Ä¢ NFT profile pic psychology ‚Ä¢ Discord community dynamics
            ‚Ä¢ Telegram alpha hunting ‚Ä¢ Twitter space FOMO
            
            **Mainstream ‚Üí Crypto Bridges**:
            ‚Ä¢ Dating apps ‚Üí DeFi protocols ‚Ä¢ Food delivery ‚Üí Token distribution
            ‚Ä¢ Weather ‚Üí Market conditions ‚Ä¢ Traffic ‚Üí Network congestion  
            ‚Ä¢ Relationships ‚Üí Tokenomics ‚Ä¢ Shopping ‚Üí Portfolio management
            ‚Ä¢ Exercise ‚Üí DCA strategies ‚Ä¢ Sleep ‚Üí Market timing
            ‚Ä¢ Pets ‚Üí Prediction oracles ‚Ä¢ Plants ‚Üí Growth investing
            
            **üöÄ CAMPAIGN INTEGRATION MASTERY**:
            
            **Natural Integration Methods**:
            - Use project name in ironic comparison
            - Reference project features as life solutions
            - Compare project benefits to daily frustrations
            - Position project as cultural shift enabler
            - Make project hashtag feel earned, not forced
            - Create inside jokes around project community
            - Reference project milestones as personal victories
            
            **CRITICAL AUTONOMOUS EXECUTION**:
            - Generate completely original content (NO TEMPLATES)
            - Ensure every shitpost feels spontaneous and authentic
            - Optimize for maximum engagement and viral potential
            - Build project community through shared humor and culture
            - Create content that people WANT to share and discuss
            - Design posts that stop scrolling and demand interaction
            
            Remember: The best shitposts feel like natural thoughts that accidentally became profound. Create content that makes people think "This person gets it" while subtly building project awareness and community.
            """
        elif post_type == "longpost":
            content_approach = """
            LONGPOST APPROACH - Create comprehensive, detailed content:
            - Develop in-depth analysis or educational content
            - Provide detailed explanations, insights, or tutorials
            - Use professional tone with thorough research
            - Include data, statistics, or technical details when relevant
            - Structure content logically with clear sections
            - Maximum 25000 characters for main content (no thread needed)
            - Focus on value-driven, informative content
            - Include relevant hashtags and professional engagement hooks
            """
        else:  # thread (default)
            content_approach = """
            THREAD APPROACH - Create engaging Twitter thread content:
            - Start with a compelling hook in the main tweet
            - Develop the narrative across multiple connected tweets
            - Each tweet should build upon the previous one
            - Use storytelling techniques and progressive disclosure
            - Main tweet maximum 250 characters + 30 hashtag characters
            - Each thread tweet maximum 280 characters
            - Ideally 200-240 characters per thread tweet for optimal engagement
            - Include call-to-action or engagement hook at the end
            """
        
        return Task(
            description=f"""
            Analyze the campaign requirements and develop a content strategy for {post_type.upper()} content.
            
            Campaign: {self.campaign_context.get('title', 'Unknown Campaign')}
            Platform: {self.campaign_context.get('platform_source', 'twitter')}
            Token/Project: {self.campaign_context.get('project', {}).get('name', 'N/A')}
            
            {content_approach}
            
            Your task:
            1. Analyze the campaign context and requirements
            2. Define the content approach based on {post_type} type
            3. Identify key messages and themes
            4. Determine optimal engagement strategy
            5. Specify content structure and character limits
            
            Consider:
            - Target audience and community preferences  
            - Platform-specific best practices for {post_type}
            - Brand voice and messaging guidelines
            - Current trends and community interests
            - Optimal posting strategy for maximum engagement
            
            Output a strategic brief that the Text Content Agent can use to create effective {post_type} content.
            """,
            agent=self.agents[AgentType.CONTENT_STRATEGIST],
            expected_output=f"""
            Strategic brief for {post_type.upper()} content including:
            - Content approach and tone
            - Key messaging themes
            - Target audience insights
            - Platform optimization strategy
            - Engagement tactics
            - Content structure guidelines
            - Character limit specifications
            - Hashtag strategy
            """
        )

    def _create_content_creation_task(self) -> Task:
        """Create task for Text Content Agent to generate tweet threads"""
        
        # Get post type from mining session
        post_type = getattr(self.mining_session, 'post_type', 'thread')
        
        # Check content generation requirements based on post type
        campaign_description = self.campaign_data.get('description', '') if self.campaign_data else ''
        campaign_description = campaign_description or ''  # Ensure it's never None
        has_description = campaign_description and campaign_description.strip()
        
        # Determine content structure based on post type
        if post_type == "longpost":
            should_generate_thread = False
            max_main_chars = 25000
            content_type_desc = "LONGPOST GENERATION"
        elif post_type == "shitpost":
            should_generate_thread = False  # Shitposts only need main_tweet
            max_main_chars = 240  # 240 chars max for main tweet
            content_type_desc = "SHITPOST GENERATION (MAIN TWEET ONLY)"
        else:  # thread (default)
            should_generate_thread = has_description
            max_main_chars = 240  # 240 chars max for main tweet
            content_type_desc = "TWITTER THREAD GENERATION" if has_description else "SINGLE TWEET GENERATION"
        
        # Extract additional campaign details with proper null handling
        brand_guidelines = self.campaign_data.get('brandGuidelines', '') if self.campaign_data else ''
        brand_guidelines = brand_guidelines or ''  # Ensure it's never None
        token_ticker = self.campaign_data.get('tokenTicker', 'TOKEN') if self.campaign_data else 'TOKEN'
        token_ticker = token_ticker or 'TOKEN'  # Ensure it's never None
        project_name = self.campaign_data.get('projectName', 'Project') if self.campaign_data else 'Project'
        project_name = project_name or 'Project'  # Ensure it's never None
        project_twitter_handle_raw = self.campaign_data.get('projectTwitterHandle', '') if self.campaign_data else ''
        project_twitter_handle_raw = project_twitter_handle_raw or ''  # Ensure it's never None
        project_twitter_handle = self._format_twitter_handle(project_twitter_handle_raw)
        
        # Debug logging for token ticker
        logger.info(f"üìä Campaign token ticker: {token_ticker} (from campaign data: {self.campaign_data.get('tokenTicker') if self.campaign_data else 'None'})")
        logger.info(f"üê¶ Project Twitter handle: {project_twitter_handle} (from campaign data: {self.campaign_data.get('projectTwitterHandle') if self.campaign_data else 'None'})")
        
        # Generate post-type specific task description
        task_description = self._get_posttype_specific_task_description(
            post_type, content_type_desc, project_name, token_ticker, 
            project_twitter_handle, campaign_description, has_description,
            brand_guidelines, should_generate_thread, max_main_chars
        )
        
        # Enhanced task description with leaderboard success pattern tool requirement
        enhanced_task_description = f"""
        üèÜ **MANDATORY FIRST STEP - LEADERBOARD SUCCESS PATTERNS**:
        You MUST start by calling the `leaderboard_success_patterns` tool to get JSON data of top 3 yappers' success patterns.
        The tool returns structured JSON with each yapper's individual patterns and their Twitter handles.
        
        **CRITICAL ANALYSIS OF TOOL OUTPUT**:
        1. Parse the JSON response carefully
        2. Examine each yapper's "text_success_patterns" individually  
        3. Compare their strategies with the Content Strategist's recommendations
        4. Make an AUTONOMOUS DECISION on which approach to use
        
        **YAPPER HANDLE TAGGING LOGIC** (CRITICAL):
        - IF you choose to use a specific yapper's text success pattern ‚Üí MUST tag their @handle at the END of main_tweet
        - IF you don't use any specific yapper pattern ‚Üí Do NOT tag any yapper handles
        - Example if using yapper pattern: "The future of DeFi is transforming everything. Ready to join? @top_yapper"
        - Example if not using: Just tag project handle as usual (contextually integrated)
        - Yapper handles: Always at the end | Project handles: Contextually integrated
        
        {task_description}
        
        üéØ **ENHANCED WORKFLOW**:
        1. FIRST: Call leaderboard_success_patterns tool
        2. SECOND: Parse JSON and analyze each yapper's text_success_patterns
        3. THIRD: Compare with Content Strategist recommendations
        4. FOURTH: Make autonomous decision on approach
        5. FIFTH: Generate content with appropriate handle tagging
        6. SIXTH: Return JSON in expected format
        
        Remember: You have COMPLETE AUTONOMY to decide which strategy works best for this campaign!
        """
        
        return Task(
            description=enhanced_task_description,
            agent=self.agents[AgentType.TEXT_CONTENT],
            expected_output=f"Single JSON object with main_tweet, {'hashtags_used, character_counts, and approach fields' if post_type == 'longpost' else 'thread_array, hashtags_used, and character_counts fields'} - no additional text or explanations"
        )

    def _create_visual_task(self) -> Task:
        """Create task for Visual Creator Agent"""
        # Get the same configuration that was used in agent creation
        image_provider = self.model_preferences.get('image', {}).get('provider', 'openai')
        image_model = self.model_preferences.get('image', {}).get('model', 'dall-e-3')
        video_provider = self.model_preferences.get('video', {}).get('provider', 'google')
        video_model = self.model_preferences.get('video', {}).get('model', 'veo-3')
        
        # Check if tools are available
        has_image_tool = image_provider in ['openai', 'fal', 'google'] and self.user_api_keys.get(image_provider if image_provider != 'fal' else 'fal')
        has_video_tool = video_provider == 'google' and self.user_api_keys.get('google')
        
        return Task(
            description=f"""
            üö® **CRITICAL: STRICT PROVIDER-BASED TOOL USAGE**
            
            Your chosen configuration:
            - Image Provider: {image_provider.upper()}
            - Image Model: {image_model}
            - Video Provider: {video_provider.upper()} 
            - Video Model: {video_model}
            
            **MANDATORY TOOL SELECTION - NO EXCEPTIONS**:
            {f"- For IMAGE generation: ONLY use `{image_provider}_image_generation` tool" if has_image_tool else "- No image generation available"}
            {f"- For VIDEO generation: ONLY use `{video_provider}_video_generation` tool" if has_video_tool else "- No video generation available"}
            
            **NEVER DEVIATE FROM USER'S PROVIDER CHOICE**:
            The user specifically selected {image_provider.upper()} for images and {video_provider.upper()} for videos.
            You have access ONLY to tools for their chosen providers.
            
            üèÜ **MANDATORY: USE LEADERBOARD SUCCESS PATTERNS**:
            BEFORE generating any visual content, you MUST call the `leaderboard_success_patterns` tool to get proven visual strategies from top-performing yappers for this campaign.
            The tool returns structured JSON with each yapper's individual patterns and their Twitter handles.
            
            **CRITICAL ANALYSIS OF TOOL OUTPUT**:
            1. Parse the JSON response carefully
            2. Examine each yapper's "visual_success_patterns" individually
            3. FILTER: Only consider yappers who have meaningful visual_success_patterns data
            4. VALIDATE: Check if visual patterns contain actionable insights (viral_mechanics, trending_elements, etc.)
            5. Make an AUTONOMOUS DECISION on which yapper's visual style to adopt (if any)
            
            **INTELLIGENT YAPPER SELECTION LOGIC** (CRITICAL):
            - FIRST: Check which yappers have comprehensive visual_success_patterns available
            - SECOND: From available visual patterns, select the most relevant one for your content
            - IF NO yappers have meaningful visual_success_patterns:
              ‚Üí Ignore all yapper patterns completely
              ‚Üí Generate dynamic prompt based SOLELY on Text Creator Agent output
              ‚Üí Create original visual strategy autonomous from text content themes
            - IF yappers DO have visual patterns:
              ‚Üí Select the yapper with the most relevant visual strategies
              ‚Üí Combine their patterns with text content for optimal visuals
            
            **REQUIRED WORKFLOW**:
            1. FIRST: Call `leaderboard_success_patterns` tool with visual analysis request
            2. SECOND: Parse JSON and identify yappers with meaningful visual_success_patterns
            3. THIRD: IF visual patterns available ‚Üí Select best yapper; IF not ‚Üí ignore all patterns
            4. FOURTH: Analyze the text content output from Text Creator Agent
            5. FIFTH: Create visual strategy (pattern-based OR purely text-based)
            6. SIXTH: Generate visual content using your provider-specific tools
            
            **VISUAL PATTERN DECISION-MAKING**:
            - SMART FILTERING: Only use yappers with actual visual success data
            - INTELLIGENT FALLBACK: If no useful visual patterns, rely on text content analysis
            - AUTONOMOUS CREATIVITY: You have complete freedom to create original visuals when patterns aren't helpful
            - TEXT-VISUAL SYNERGY: Always ensure visuals complement the text content effectively
            
            Generate REAL visual content using your available tools:
            
            üìù **TEXT CONTENT ANALYSIS INSTRUCTIONS**:
            You will receive the Text Content Creator's JSON output as input. Parse and analyze it based on post type:
            
            **FOR THREAD/SHITPOST** - Analyze the complete JSON structure:
            {{
                "main_tweet": "the main tweet text here",
                "thread_array": ["first thread tweet", "second thread tweet", "third thread tweet"],
                "hashtags_used": [...],
                "character_counts": {{...}}
            }}
            ‚Üí Use BOTH main_tweet AND all thread_array content to understand the full narrative and emotional journey
            
            **FOR LONGPOST** - Analyze the main_tweet field containing the full content:
            {{
                "main_tweet": "the comprehensive longpost content here (2000-25000 characters)",
                "hashtags_used": [...],
                "character_counts": {{...}}
            }}
            ‚Üí Use the complete longpost content to extract themes, emotions, and key concepts
            
            Campaign Context:
            - Title: {self.campaign_data.get('title', 'N/A') if self.campaign_data else 'N/A'}
            - Brand Guidelines: {self.campaign_data.get('brandGuidelines', 'Modern, professional, crypto-focused') if self.campaign_data else 'Modern, professional, crypto-focused'}
            - Platform: {self.campaign_data.get('platformSource', 'twitter') if self.campaign_data else 'twitter'}
            - Post Type: {getattr(self.mining_session, 'post_type', 'thread').upper()}
            
            üìã **POST TYPE VISUAL STRATEGY**:
            {f'- LONGPOST: Generate ONE compelling image to accompany the comprehensive text content' if getattr(self.mining_session, 'post_type', 'thread') == 'longpost' else 
             f'- SHITPOST: Generate humorous, meme-style image for MAIN TWEET ONLY (no thread images)' if getattr(self.mining_session, 'post_type', 'thread') == 'shitpost' else 
             '- THREAD: Generate engaging image/video for main tweet based on strategist recommendation'}
            
            üìã **STRATEGY-DRIVEN CONTENT TYPE**:
            {f'- Generate ONE professional image that complements the longpost content theme' if getattr(self.mining_session, 'post_type', 'thread') == 'longpost' else 
             f'- Generate ONE meme-style image for shitpost main tweet only' if getattr(self.mining_session, 'post_type', 'thread') == 'shitpost' else 
             '- Review the Content Strategist recommendation (IMAGE or VIDEO)'}
            {'' if getattr(self.mining_session, 'post_type', 'thread') == 'longpost' else 
             f'- Use ironic, humorous, crypto meme aesthetic' if getattr(self.mining_session, 'post_type', 'thread') == 'shitpost' else 
             '- Follow the strategic decision as your PRIMARY goal'}
            {'' if getattr(self.mining_session, 'post_type', 'thread') == 'longpost' else 
             f'- Focus on absurd, relatable scenarios with crypto elements' if getattr(self.mining_session, 'post_type', 'thread') == 'shitpost' else 
             '- Apply intelligent fallback hierarchy if needed'}
            
            üéØ **EXECUTION HIERARCHY**:
            
            **STEP 1: Try User's Preferred Model**
            - Check if user's preferred model is available for requested content type
            - Use their preferred tool/provider first
            - Only proceed to Step 2 if this fails or API is unavailable
            
            **STEP 2: Try Alternative Providers (Same Content Type)**
            - If preferred model fails, try other available providers
            - Maintain the SAME content type (IMAGE stays IMAGE, VIDEO stays VIDEO)
            - Example: If OpenAI DALL-E fails, try Claude Sonnet for images
            
            **STEP 3: Content Type Fallback (Only if NO APIs for requested type)**
            IF STRATEGY REQUESTED VIDEO but NO video APIs available:
            - Switch to IMAGE generation using any available image provider
            - Create dynamic, motion-suggesting imagery
            - Include visual elements that convey video-like energy
            
            IF STRATEGY REQUESTED IMAGE but NO image APIs available:
            - Switch to VIDEO generation using any available video provider
            - Create brief, static-like video content
            - Focus on single compelling visual frame
            
            **STEP 4: Text-Only Fallback (Last Resort)**
            IF NO visual generation APIs available at all:
            - Provide rich, detailed visual concept description
            - Include specific imagery suggestions
            - Focus on textual visual storytelling
            
            üé® **GENERATION INSTRUCTIONS**:
            
            **STRICT PROVIDER-SPECIFIC TOOL USAGE**:
            You have been configured with specific tools based on your chosen providers.
            
            üö® **CRITICAL: ONLY USE THE TOOLS YOU HAVE ACCESS TO**:
            {f"- For IMAGE generation: Use `{image_provider}_image_generation` tool ONLY" if has_image_tool else "- No image generation tools available"}
            {f"- For VIDEO generation: Use `{video_provider}_video_generation` tool ONLY" if has_video_tool else "- No video generation tools available"}
            
            **PROVIDER-SPECIFIC EXAMPLES**:
            
            **If you have OpenAI image tool** ‚Üí Use `openai_image_generation`:
            - Available models: dall-e-3, dall-e-2, gpt-image-1, gpt-4o
            - Example: openai_image_generation("A modern Web3 office with futuristic elements")
            
            **If you have Fal.ai image tool** ‚Üí Use `fal_image_generation`:
            - Available models: flux-*, stable-diffusion-*, ideogram-*, etc.
            - Example: fal_image_generation("A dynamic crypto trading dashboard with neon elements")
            
            **If you have Google image tool** ‚Üí Use `google_image_generation`:
            - Available models: imagen-*, gemini-*
            - Example: google_image_generation("Professional blockchain technology visualization")
            
            **If you have Google video tool** ‚Üí Use `google_video_generation`:
            - Available models: veo-*, lumiere-*
            - Example: google_video_generation("Short promotional video for crypto platform")
            
            üö´ **FORBIDDEN TOOLS**:
            - Do NOT use `visual_concept` tool if you have provider-specific tools available
            - Do NOT use any tools other than those specifically configured for your providers
            - Each tool will reject requests if you're not authorized to use that provider
            
            üéØ **CONTENT GENERATION SPECIFICATIONS**:
            
            üé® **AUTONOMOUS ARTISTIC STYLE SELECTION** (CRITICAL):
            You are an intelligent visual creator who independently chooses the best artistic style based on the tweet content and emotional tone. Do NOT rely on templates - create original, dynamic prompts that match the content perfectly.
            
            **ARTISTIC STYLE CATEGORIES** (Choose autonomously based on content):
            
            **STYLE OPTIONS** (Select what fits the tweet emotion):
            ‚Ä¢ Comic/Cartoon - for humorous, relatable content
            ‚Ä¢ Meme/Internet Culture - for FOMO, viral content  
            ‚Ä¢ Techno/Cyberpunk - for futuristic, innovation themes
            ‚Ä¢ FOMO/Urgency - for time-sensitive opportunities
            ‚Ä¢ Animated/Dynamic - for action-oriented content
            ‚Ä¢ Community/Social - for inclusive, gathering themes
            ‚Ä¢ Urgency/Pressure - for "last chance" messaging
            ‚Ä¢ Vector Art/Clean - for professional, minimalist content
            ‚Ä¢ Hyper Realistic - for serious, credible messaging
            ‚Ä¢ Photo Realistic - for authentic, trustworthy content
            ‚Ä¢ Pixel Art/Retro - for nostalgic, gaming references
            ‚Ä¢ Studio Lightning - for polished, professional look
            ‚Ä¢ Cinematic - for dramatic, epic storytelling
            ‚Ä¢ Abstract/Conceptual - for complex ideas visualization
            
            **ESSENTIAL QUALITY KEYWORDS** (ALWAYS include these for professional output):
            
            **Resolution & Detail**:
            "8K resolution", "4K resolution", "ultra-detailed", "hyperdetailed", "sharp focus", "crisp lines", "pixel-perfect"
            
            **Photography Terms**:  
            "Photorealistic", "award-winning photography", "studio lighting", "cinematic lighting", "dramatic lighting", "professional photography"
            
            **Art Quality**:
            "Masterpiece", "masterful composition", "award-winning digital art", "ultra-high quality", "best quality", "premium quality"
            
            **Rendering & Effects**:
            "Hyperrealistic CGI", "3D render", "volumetric lighting", "perfect reflections", "dynamic lighting effects"
            
            **Style Descriptors**:
            "Clean vector art", "geometric precision", "vibrant color palette", "rich color depth", "atmospheric lighting"
            
            üìñ **AUTONOMOUS PROMPT GENERATION PROCESS** (CRITICAL):
            You are an AI visual expert who creates original, compelling prompts without relying on templates. Your mission is to analyze tweet content and craft unique, high-impact visual prompts that perfectly complement the message.
            
            üö´ **CRITICAL NO-TEXT REQUIREMENT**:
            You MUST INTELLIGENTLY INTEGRATE "no text", "no words", "no letters", "no writing" directly into every visual prompt you generate. This ensures clean imagery without unwanted text overlays.
            
            **SMART NO-TEXT INTEGRATION EXAMPLES**:
            - "...with photorealistic CGI, 8K ultra-detailed, NO TEXT OR WORDS visible, dramatic technological lighting..."
            - "...masterpiece quality digital art, absolutely no writing or letters, award-winning composition..."
            - "...volumetric lighting effects, strictly no text elements, clean minimalist design..."
            
            **STEP-BY-STEP AUTONOMOUS PROCESS**:
            
            1. **Deep Content Analysis** (Post-Type Specific): 
               - **FOR THREAD/SHITPOST**: Analyze BOTH main_tweet AND complete thread_array from Text Content Creator's JSON output
               - **FOR LONGPOST**: Analyze the comprehensive main_tweet (longpost content) from Text Content Creator's JSON output
               - Read ALL the generated text content thoroughly to understand the complete narrative
               - Identify core emotions: excitement, urgency, community, innovation, FOMO, humor, etc.
               - Extract key concepts: project features, benefits, community aspects, timing, opportunities
               - Determine the primary message goal: inform, excite, create urgency, build community, etc.
               - Consider the full content scope when designing visual concepts
            
            2. **Intelligent Style Selection**:
               - Choose the most appropriate artistic style from the options above
               - Consider your target audience (Web3 GenZ, crypto enthusiasts, tech-savvy users)
               - Match visual complexity to message complexity
               - Decide on realism level: cartoon ‚Üí stylized ‚Üí photorealistic
            
            3. **Original Concept Creation**:
               - Generate a unique visual concept that amplifies the tweet's message
               - Create original scenes, characters, or compositions (do NOT copy templates)
               - Incorporate crypto/Web3 cultural elements naturally when relevant
               - Design for maximum viral potential and engagement
            
            4. **Professional Enhancement**:
               - Always include Essential Quality Keywords for professional output
               - Specify appropriate lighting that enhances the mood
               - Add technical specifications (resolution, rendering quality)
               - Ensure Twitter-optimized dimensions and mobile readability
            
            5. **Prompt Optimization**:
               - Structure: [Main Visual Concept] + [Specific Details] + [Style] + [NO-TEXT Requirement] + [Quality Keywords] + [Technical Specs]
               - MANDATORY: Always include explicit no-text instructions in every prompt
               - Keep prompts clear, specific, and actionable for AI models
               - Include emotional descriptors that match the tweet's tone
               - Ensure visual directly supports and amplifies the tweet message
            
            **AUTONOMOUS CREATIVE EXAMPLES** (Your style of thinking):
            
            Example Analysis Process:
            Tweet: "BOB's hybrid model is revolutionizing Bitcoin DeFi"
            ‚Üí Emotion: Innovation, confidence, breakthrough
            ‚Üí Style: Techno/cyberpunk with professional credibility  
            ‚Üí Original Concept: Bitcoin and Ethereum symbols merging into a new hybrid form with energy flowing between them
            ‚Üí Generated Prompt: "Two golden orbs representing Bitcoin and Ethereum slowly merging into a brilliant hybrid symbol, with energy streams flowing between them in a high-tech laboratory setting, surrounding holographic charts showing upward growth, cyberpunk aesthetic with blue and gold neon lighting, NO TEXT OR WORDS visible anywhere, photorealistic CGI, 8K ultra-detailed, dramatic technological lighting, masterpiece quality, award-winning digital art"
            
            This approach ensures variety, creativity, and perfect message-visual alignment for every unique tweet!
            
            **WORLD-CLASS IMAGE GENERATION REQUIREMENTS**:
            - Use your configured image tool ({f"{image_provider}_image_generation" if has_image_tool else "none available"})
            - **MANDATORY**: Follow the Autonomous Prompt Generation Process above - NO TEMPLATES
            - **CRITICAL NO-TEXT RULE**: EVERY prompt MUST include explicit "no text", "no words", "no letters" instructions
            - **STEP 1**: Deep analysis of ALL Text Content Creator's output (main_tweet + thread_array for threads/shitposts, or full longpost content) for emotional tone and core concepts
            - **STEP 2**: Intelligent selection of artistic style that best fits the content
            - **STEP 3**: Original concept creation that amplifies the tweet's message uniquely
            - **STEP 4**: Professional enhancement with Essential Quality Keywords + NO-TEXT requirements
            - **STEP 5**: Prompt optimization for maximum AI model effectiveness with guaranteed no-text integration
            
            üö® **CRITICAL TOOL INPUT FORMAT**:
            - When calling {f"{image_provider}_image_generation" if has_image_tool else "image generation"} tool, provide ONLY a simple string prompt
            - DO NOT use dictionary format, JSON format, or any complex structure
            - Example: Use "A futuristic digital landscape..." NOT {{"description": "A futuristic...", "image_url": "..."}}
            - The tool expects: prompt = "your generated prompt text here"
            - Keep it simple: just the creative prompt string you generate
            - **CRITICAL**: Create original, dynamic prompts that ensure variety and prevent repetitive imagery
            - Campaign context: "{self.campaign_data.get('title', 'campaign') if self.campaign_data else 'campaign'}"
            - Twitter-optimized dimensions with maximum visual impact
            - Include compelling visual elements that enhance engagement and message clarity
            - High viral potential with Web3 culture and emotional resonance
            - Professional finish suitable for crypto/Web3 audience
            - Ensure visual diversity across different content generations
            
            **VIDEO GENERATION REQUIREMENTS**:
            - Use your configured video tool ({f"{video_provider}_video_generation" if has_video_tool else "none available"})
            - Transform campaign context into a compelling visual story: "{self.campaign_data.get('title', 'campaign') if self.campaign_data else 'campaign'}"
            - Apply story-based prompt structure with temporal elements (beginning, middle, end)
            - Include dynamic transitions and cinematic storytelling
            - 8-second promotional video with narrative arc
            - Twitter specifications (max 2:20, 1920x1080px)
            - Mobile-optimized viewing
            
            üéØ **QUALITY REQUIREMENTS**:
            - Mobile-first design approach
            - High contrast for readability
            - Brand color consistency
            - Platform-specific optimization
            - Accessibility compliance
            
            ‚ö†Ô∏è **CRITICAL EXECUTION RULES**:
            1. **ALWAYS use story-based prompts** - Transform every visual request into a micro-narrative
            2. Follow the hierarchy: Preferred ‚Üí Alternative ‚Üí Fallback ‚Üí Text-only
            3. Actually call your AI generation tools to create real content with story prompts
            4. Do NOT provide generic descriptions unless in text-only mode
            5. Clearly indicate which tier of the hierarchy was used
            6. Explain why fallbacks were necessary (API unavailable, model failed, etc.)
            7. Maintain campaign quality regardless of which tools are used
            
            üìù **AUTONOMOUS CREATIVE WORKFLOW**:
            
            **YOUR INTELLIGENT PROCESS** (No templates - pure creativity):
            1. **Deep Tweet Analysis**: Extract the emotional core and key message concepts from Text Content Creator's output
            2. **Autonomous Style Decision**: Choose the perfect artistic style based on content emotion and target impact
            3. **Original Concept Generation**: Create a unique, never-before-seen visual concept that amplifies the message
            4. **Professional Enhancement**: Add Essential Quality Keywords for maximum AI model performance
            5. **Prompt Optimization**: Structure for clarity, impact, and technical excellence
            
            **CREATIVE THINKING EXAMPLES** (Your autonomous approach):
            
            Tweet: "gm Web3 fam üåÖ Ready to build the future?"
            ‚Üí Analysis: Warm, community-focused, forward-looking, inclusive
            ‚Üí Style Choice: Community/Social with optimistic lighting
            ‚Üí Original Concept: A diverse group of people silhouetted against a rising digital sun, with their devices casting holographic blueprints of tomorrow's tech
            ‚Üí Autonomous Prompt: "Silhouettes of diverse people standing on a hill watching a digital sunrise with holographic blueprints of futuristic technology floating between them, warm golden and blue lighting creating hope and community feeling, photorealistic digital art, 8K ultra-detailed, cinematic composition, masterpiece quality"
            
            Tweet: "Time's running out - don't miss the opportunity üö®"
            ‚Üí Analysis: Urgent, pressure, FOMO, time-sensitive action needed
            ‚Üí Style Choice: FOMO/Urgency with dramatic tension
            ‚Üí Original Concept: An hourglass with opportunities literally falling through while hands reach desperately upward
            ‚Üí Autonomous Prompt: "A giant crystal hourglass with golden opportunity symbols (keys, coins, doors) falling through the narrow center while multiple hands reach upward from below trying to catch them, dramatic red and gold lighting with urgency effects, hyperrealistic 3D render, 8K resolution, dynamic motion capture, award-winning digital art"
            
            Tweet: "Building the next generation of decentralized finance"
            ‚Üí Analysis: Innovation, construction, future-focused, technical advancement
            ‚Üí Style Choice: Techno/Cyberpunk with architectural elements
            ‚Üí Original Concept: Architects of light constructing transparent financial structures in digital space
            ‚Üí Autonomous Prompt: "Ethereal figures made of light constructing complex geometric financial structures floating in digital space, with data streams flowing through transparent architecture, cyberpunk aesthetic with purple and teal energy flows, photorealistic CGI, 8K ultra-detailed, volumetric lighting, masterpiece architectural visualization"
            
            This autonomous approach ensures every image is unique, contextually perfect, and professionally crafted!
            
            CRITICAL OUTPUT FORMAT - MUST FOLLOW EXACTLY:
            You MUST return ONLY a valid JSON object with NO additional text, explanations, or formatting.
            
            USE THIS EXACT JSON STRUCTURE:
            {{
              "content_type": "IMAGE", 
              "image_url": "https://complete-s3-url-with-all-parameters.amazonaws.com/...",
              "video_url": null,
              "visual_concept": null,
              "provider_used": "Fal.ai",
              "model_used": "imagen4-preview", 
              "dimensions": "1024x576px",
              "file_format": "JPEG",
              "execution_tier": "PREFERRED_MODEL",
              "strategy_alignment": "Generated image matches strategic recommendation",
              "alt_text": "Digital avatar with glowing circuit patterns showing crypto earnings"
            }}
            
            FOR VIDEO CONTENT, USE:
            {{
              "content_type": "VIDEO",
              "image_url": null, 
              "video_url": "https://complete-video-url.amazonaws.com/...",
              "visual_concept": null,
              "provider_used": "Google",
              "model_used": "veo-3",
              "dimensions": "1920x1080",
              "file_format": "MP4", 
              "execution_tier": "PREFERRED_MODEL",
              "strategy_alignment": "Generated video matches strategic recommendation",
              "alt_text": "Dynamic video showing crypto trading dashboard"
            }}
            
            FOR TEXT-ONLY FALLBACK, USE:
            {{
              "content_type": "TEXT_ONLY",
              "image_url": null,
              "video_url": null, 
              "visual_concept": "Detailed visual description here",
              "provider_used": "Text-only",
              "model_used": "N/A",
              "dimensions": "N/A",
              "file_format": "N/A",
              "execution_tier": "TEXT_ONLY",
              "strategy_alignment": "Provides visual guidance without generation",
              "alt_text": "Visual concept description"
            }}
            
            CRITICAL JSON RULES:
            - Return ONLY the JSON object, no other text
            - Use double quotes for all strings  
            - Set unused fields to null (not empty strings)
            - Ensure all JSON syntax is valid
            - No trailing commas
            - No comments or explanations outside the JSON
            - Include complete URLs with all query parameters
            
            Remember: Only ONE visual content type per Twitter post for optimal performance!
            """,
            agent=self.agents[AgentType.VISUAL_CREATOR],
            expected_output="Single JSON object with content_type, image_url/video_url, provider_used, and technical specifications - no additional text or explanations"
        )

    def _create_orchestration_task(self) -> Task:
        """Create task for Orchestrator Agent"""
        post_type = getattr(self.mining_session, 'post_type', 'thread')
        
        # Define task instructions based on post type
        if post_type == 'longpost':
            format_example = '''{
    "main_tweet": "copy the comprehensive longpost content here",
    "image_url": "copy the image URL here"
}'''
            instructions = """1. Look for the JSON output from Text Content Creator (has "main_tweet" for longpost)
2. Look for the image URL from Visual Content Creator (S3 URL or other image URL)
3. Combine them into exactly this JSON format:"""
            fallback_rules = """- If no image URL exists, use empty string: ""
- Do NOT include thread_array for longposts"""
        else:
            format_example = '''{
    "main_tweet": "copy the main tweet text here",
    "thread_array": ["copy", "the", "thread", "array", "here"],
    "image_url": "copy the image URL here"
}'''
            instructions = """1. Look for the JSON output from Text Content Creator (has "main_tweet" and "thread_array")
2. Look for the image URL from Visual Content Creator (S3 URL or other image URL)
3. Combine them into exactly this JSON format:"""
            fallback_rules = """- If no thread_array exists, use an empty array: []
- If no image URL exists, use empty string: \"\""""
        
        return Task(
            description=f"""
            COMBINE JSON OUTPUTS INTO SINGLE CLEAN JSON
            
            You must find and combine the outputs from the Text Content Creator and Visual Content Creator.
            
            INSTRUCTIONS:
            {instructions}
            
            {format_example}
            
            CRITICAL REQUIREMENTS:
            - Output ONLY valid JSON in the exact format above
            - Do NOT add explanations, descriptions, or extra text
            - Do NOT use tools
            - Find the actual content from previous agents and combine it
            {fallback_rules}
            
            Campaign: {self.campaign_data.get('title', 'Content Campaign') if self.campaign_data else 'Content Campaign'}
            """,
            agent=self.agents[AgentType.ORCHESTRATOR],
            expected_output="Valid JSON containing main_tweet, thread_array, and image_url from previous agents",
            context=[
                self.tasks[AgentType.DATA_ANALYST],
                self.tasks[AgentType.CONTENT_STRATEGIST], 
                self.tasks[AgentType.TEXT_CONTENT],
                self.tasks[AgentType.VISUAL_CREATOR]
            ]
        )

    async def _run_crew_generation(self, mining_session: MiningSession) -> Dict[str, Any]:
        """Run the CrewAI generation process with progress tracking"""
        try:
            # Update session status
            mining_session.status = MiningStatus.GENERATING
            await self._update_progress(40, "Data Analyst Agent: Analyzing patterns...")
            mining_session.agent_statuses[AgentType.DATA_ANALYST] = AgentStatus.RUNNING
            
            # Execute crew tasks in sequence with progress updates
            result = await asyncio.create_task(self._execute_crew_with_progress())
            
            logger.info("‚úÖ CrewAI generation completed successfully")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Error in crew generation: {e}")
            raise

    async def _execute_crew_with_progress(self) -> Dict[str, Any]:
        """Execute crew with enhanced real-time progress tracking and content previews"""
        # Send initial milestone
        await self._send_generation_milestone("crew_start", {
            "agents_count": 5,
            "estimated_duration": "2-3 minutes",
            "user_models": self.model_preferences
        })
        
        # Execute the actual CrewAI crew with interleaved progress updates
        try:
            logger.info("üöÄ Starting CrewAI crew execution...")
            
            # Phase 1: Data Analysis (start immediately)
            await self._update_agent_status(
                AgentType.DATA_ANALYST, 
                AgentStatus.RUNNING, 
                "Analyzing campaign data and market trends...",
                {"phase": "data_collection", "models_used": ["mindshare_ml", "twitter_learning"]}
            )
            await asyncio.sleep(0.2)
            await self._update_progress(45, "Data Analyst Agent: Processing campaign insights...")
            logger.info("üìä Data Analyst Agent: Started")
            
            # Send milestone for data analysis completion
            await asyncio.sleep(2)
            await self._send_generation_milestone("data_analysis_complete", {
                "insights_gathered": ["audience_analysis", "engagement_patterns", "trending_topics"],
                "confidence": 0.92
            })
        
        # Phase 2: Content Strategy
            await self._update_agent_status(AgentType.DATA_ANALYST, AgentStatus.COMPLETED)
            await asyncio.sleep(0.2)
            await self._update_agent_status(
                AgentType.CONTENT_STRATEGIST, 
                AgentStatus.RUNNING, 
                "Creating content strategy and tone...",
                {"strategy_type": "viral_optimization", "target_platform": "twitter"}
            )
            await asyncio.sleep(0.2)
            await self._update_progress(55, "Content Strategist Agent: Developing strategy...")
            logger.info("üéØ Content Strategist Agent: Started")
            
            await asyncio.sleep(2)
            await self._send_generation_milestone("strategy_complete", {
                "content_approach": "data_driven_viral",
                "visual_recommendation": "image_preferred",
                "tone": "engaging_professional"
            })
        
        # Phase 3: Text Content Generation
            await self._update_agent_status(AgentType.CONTENT_STRATEGIST, AgentStatus.COMPLETED)
            await asyncio.sleep(0.2)
            await self._update_agent_status(
                AgentType.TEXT_CONTENT, 
                AgentStatus.RUNNING, 
                "Writing engaging content with optimal hashtags...",
                {"model": self.model_preferences.get('text', {}).get('model', 'gpt-4o')}
            )
            await asyncio.sleep(0.2)
            await self._update_progress(65, "Text Content Agent: Generating content...")
            logger.info("‚úçÔ∏è Text Content Agent: Started")
            
            # Start the actual CrewAI crew execution in background
            
            # Run crew in thread pool to avoid blocking
            with ThreadPoolExecutor() as executor:
                # Start crew execution in background while we continue progress updates
                crew_future = asyncio.get_event_loop().run_in_executor(executor, self.crew.kickoff)
                
                # Continue progress updates while crew runs
                await asyncio.sleep(2.5)
                
                # Send text content preview milestone
                await self._send_generation_milestone("text_generation_progress", {
                    "status": "in_progress",
                    "estimated_completion": "30 seconds"
                })
        
        # Phase 4: Visual Content
                await self._update_agent_status(AgentType.TEXT_CONTENT, AgentStatus.COMPLETED)
                await asyncio.sleep(0.2)
                await self._update_agent_status(
                    AgentType.VISUAL_CREATOR, 
                    AgentStatus.RUNNING, 
                    "Creating visual concepts and image prompts...",
                    {"visual_type": "image", "model": self.model_preferences.get('image', {}).get('model', 'dall-e-3')}
                )
                await asyncio.sleep(0.2)
                await self._update_progress(75, "Visual Creator Agent: Designing visual concepts...")
                logger.info("üé® Visual Creator Agent: Started")
                
                await asyncio.sleep(2.5)
                
                await self._send_generation_milestone("visual_generation_progress", {
                    "visual_type": "image_generation",
                    "style": "professional_engaging"
                })
        
        # Phase 5: Orchestration
                await self._update_agent_status(AgentType.VISUAL_CREATOR, AgentStatus.COMPLETED)
                await asyncio.sleep(0.2)
                await self._update_agent_status(
                    AgentType.ORCHESTRATOR, 
                    AgentStatus.RUNNING, 
                    "Finalizing Twitter-ready content package...",
                    {"combining": ["text", "visuals", "hashtags"], "final_format": "twitter_ready"}
                )
                await asyncio.sleep(0.2)
                await self._update_progress(85, "Orchestrator Agent: Optimizing final content...")
                logger.info("üé≠ Orchestrator Agent: Started")
                
                # Ensure crew has enough time to complete
                await asyncio.sleep(1)
                
                # Wait for crew to complete
                crew_result = await crew_future
                
                await self._update_agent_status(AgentType.ORCHESTRATOR, AgentStatus.COMPLETED)
                await self._update_progress(88, "Finalizing content package...")
                logger.info("‚úÖ All agents completed")
            
            logger.info("‚úÖ CrewAI crew execution completed")
            
            # Process the crew result into our expected format
            raw_result = str(crew_result) if crew_result else "Generated content from 5-agent constellation"
            
            # Log the raw result for debugging
            logger.info(f"üîç Raw result from orchestrator (first 500 chars): {raw_result[:500]}...")
            logger.info(f"üîç Raw result contains 'main_tweet': {'main_tweet' in raw_result}")
            logger.info(f"üîç Raw result contains 'thread_array': {'thread_array' in raw_result}")
            
            # NEW APPROACH: Orchestrator now outputs clean JSON directly
            # Try to parse the orchestrator output as JSON first
            final_content = ""
            tweet_thread = None
            
            try:
                import json
                
                # Try multiple approaches to extract JSON from orchestrator output
                json_found = False
                
                # Approach 1: Look for complete JSON object with main_tweet
                json_match = re.search(r'\{(?:[^{}]|{[^{}]*}|\[[^\]]*\])*"main_tweet"(?:[^{}]|{[^{}]*}|\[[^\]]*\])*\}', raw_result, re.DOTALL)
                if json_match:
                    try:
                        json_str = json_match.group(0)
                        parsed_json = json.loads(json_str)
                        
                        final_content = parsed_json.get("main_tweet", "")
                        tweet_thread = parsed_json.get("thread_array", [])
                        json_found = True
                        
                        # ‚úÖ SANITY CHECK: Ensure project handle is tagged in main_tweet
                        final_content = self._ensure_project_handle_tagged(final_content)
                        
                        logger.info(f"‚úÖ Successfully parsed orchestrator JSON output (approach 1)")
                        logger.info(f"‚úÖ Extracted main_tweet length: {len(final_content)} chars")
                        logger.info(f"‚úÖ Extracted thread_array: {len(tweet_thread) if tweet_thread else 0} tweets")
                    except json.JSONDecodeError as e:
                        logger.warning(f"‚ö†Ô∏è JSON parsing failed for approach 1: {e}")
                
                # Approach 2: If approach 1 failed, try to find main_tweet content more broadly
                if not json_found:
                    # Look for main_tweet with content that may span multiple lines
                    main_tweet_pattern = r'"main_tweet"\s*:\s*"((?:[^"\\]|\\.|\\n|\\r|\\t)*)"'
                    main_tweet_match = re.search(main_tweet_pattern, raw_result, re.DOTALL)
                    if main_tweet_match:
                        final_content = main_tweet_match.group(1)
                        # Unescape common escape sequences
                        final_content = final_content.replace('\\n', '\n').replace('\\r', '\r').replace('\\t', '\t').replace('\\"', '"').replace('\\\\', '\\')
                        tweet_thread = []  # No thread for longpost anyway
                        json_found = True
                        
                        # ‚úÖ SANITY CHECK: Ensure project handle is tagged in main_tweet
                        final_content = self._ensure_project_handle_tagged(final_content)
                        
                        logger.info(f"‚úÖ Extracted main_tweet using approach 2, length: {len(final_content)} chars")
                        
                if not json_found:
                    logger.warning(f"‚ö†Ô∏è No JSON found in orchestrator output, falling back to extraction")
                    extraction_result = self._extract_twitter_content(raw_result)
                    final_content = extraction_result["content_text"]
                    tweet_thread = extraction_result["tweet_thread"]
                    
                    # ‚úÖ SANITY CHECK: Ensure project handle is tagged in main_tweet
                    final_content = self._ensure_project_handle_tagged(final_content)
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è JSON parsing failed: {e}, falling back to extraction")
                extraction_result = self._extract_twitter_content(raw_result)
                final_content = extraction_result["content_text"]
                tweet_thread = extraction_result["tweet_thread"]
                
                # ‚úÖ SANITY CHECK: Ensure project handle is tagged in main_tweet
                final_content = self._ensure_project_handle_tagged(final_content)
            
            # Debug: Log extraction results
            post_type = getattr(self.mining_session, 'post_type', 'thread')
            logger.info(f"üîç POST TYPE: {post_type}")
            logger.info(f"üîç Extracted content_text length: {len(final_content)} chars")
            logger.info(f"üîç Extracted content_text preview: {final_content[:200]}...")
            if len(final_content) > 200:
                logger.info(f"üîç Extracted content_text ending: ...{final_content[-200:]}")
            logger.info(f"üîç Extracted tweet_thread: {tweet_thread}")
            logger.info(f"üîç Tweet thread type: {type(tweet_thread)}")
            logger.info(f"üîç Tweet thread length: {len(tweet_thread) if tweet_thread else 0}")
            
            # Debug: Log the raw orchestrator output and extracted content
            logger.info(f"üé≠ Orchestrator raw output length: {len(raw_result)} chars")
            logger.info(f"üé≠ Orchestrator raw output preview: {raw_result[:500]}...")
            if post_type == 'longpost':
                logger.info(f"üîç LONGPOST - Full orchestrator output for debugging: {raw_result}")  # Full output for debugging longpost issues
            
            # Debug: Check if orchestrator produced incomplete response
            if "I now can give a great answer" in raw_result or len(raw_result) < 100:
                logger.warning(f"‚ö†Ô∏è Orchestrator produced incomplete response: {raw_result}")
                logger.warning(f"‚ö†Ô∏è This suggests orchestrator context processing issues")
                
                # FALLBACK: Manually extract content from crew context
                logger.info(f"üîß Activating orchestrator fallback mechanism...")
                extraction_result = self._extract_twitter_content(raw_result)
                final_content = extraction_result["content_text"]
                tweet_thread = extraction_result["tweet_thread"]
                
                # ‚úÖ SANITY CHECK: Ensure project handle is tagged in main_tweet
                final_content = self._ensure_project_handle_tagged(final_content)
            
            # Debug: Check for Visual Creator URLs in orchestrator output
            import re
            urls_found = re.findall(r'https?://[^\s\]<>"\'`\n\r\[\)]+', raw_result)
            logger.info(f"üîç URLs found in orchestrator output: {len(urls_found)} URLs")
            for i, url in enumerate(urls_found):
                logger.info(f"   URL {i+1}: {url[:80]}...")
            
            logger.info(f"üìù Extracted final content length: {len(final_content)} chars")
            
            # Send content preview before final processing
            await self._send_content_preview("final_content", {
                "text_preview": final_content[:100] + "..." if len(final_content) > 100 else final_content,
                "has_image": "üì∏ Image URL:" in final_content,
                "char_count": len(final_content.split('\n')[0]) if final_content else 0
            })
            
            # Calculate quality metrics using our scoring system
            quality_scores = self.quality_scorer.score_content(final_content, self.campaign_data)
            overall_quality = quality_scores.get('overall_quality', 0.0)
            
            # Get performance predictions (returns a dictionary)
            performance_predictions = await self.mindshare_predictor.predict_performance(final_content, self.campaign_data)
            
            # Extract mindshare score with fallback handling
            if isinstance(performance_predictions, dict):
                mindshare_score = performance_predictions.get('mindshare_score', 75.0)
            else:
                # Fallback if predict_performance returns a single value
                mindshare_score = float(performance_predictions) if performance_predictions else 75.0
            
            # Send final completion milestone
            await self._send_generation_milestone("generation_complete", {
                "quality_score": overall_quality,
                "mindshare_score": mindshare_score,
                "content_length": len(final_content),
                "twitter_ready": True
            })
            
            return {
                "final_content": final_content,
                "tweet_thread": tweet_thread,  # Include extracted tweet thread
                "raw_orchestrator_output": raw_result,  # Add raw output for image extraction
                "quality_metrics": {
                    "overall_quality": overall_quality,
                    "detailed_scores": quality_scores
                },
                "performance_prediction": {
                    "mindshare_score": float(mindshare_score),
                    "predicted_engagement": float(overall_quality * 1.2),
                    "viral_potential": 85.0 if overall_quality > 80 else 65.0,  # Convert to float
                    "confidence_level": 90.0
                },
                "generation_metadata": {
                    "agents_used": ["Data Analyst", "Content Strategist", "Text Creator", "Visual Creator", "Orchestrator"],
                    "generation_time": datetime.utcnow().isoformat(),
                    "optimization_factors": ["mindshare", "engagement", "brand_alignment"]
                },
                "agent_contributions": {
                    AgentType.DATA_ANALYST: {
                        "role": "Campaign analysis and trend insights",
                        "contribution": "Analyzed campaign data and market trends",
                        "confidence": 90.0
                    },
                    AgentType.CONTENT_STRATEGIST: {
                        "role": "Strategic content approach",
                        "contribution": "Developed content strategy and tone",
                        "confidence": 88.0
                    },
                    AgentType.TEXT_CONTENT: {
                        "role": "Primary content generation",
                        "contribution": "Generated engaging text content",
                        "confidence": 92.0
                    },
                    AgentType.VISUAL_CREATOR: {
                        "role": "Visual concept recommendations",
                        "contribution": "Created visual content concepts",
                        "confidence": 85.0
                    },
                    AgentType.ORCHESTRATOR: {
                        "role": "Final optimization and quality assurance",
                        "contribution": "Optimized and finalized content package",
                        "confidence": 95.0
                    }
                }
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error in CrewAI execution: {e}")
            
            # Send error milestone
            await self._send_generation_milestone("generation_error", {
                "error_type": type(e).__name__,
                "error_message": str(e),
                "recovery_suggestion": "Please check API keys and try again"
            })
            
            # Don't fallback to mock - require proper configuration
            raise RuntimeError(f"CrewAI execution failed: {e}. Please ensure AI provider API keys are configured in settings.")

    # All mock data removed - system now requires real AI provider configuration

    async def _post_process_content(self, generation_result: Dict[str, Any], mining_session: MiningSession) -> ContentGenerationResponse:
        """Post-process the generated content and create final response"""
        try:
            # Extract the final content
            final_content = generation_result["final_content"]
            
            # Extract image URLs from the raw orchestrator output (not processed final_content)
            raw_output = generation_result.get("raw_orchestrator_output", final_content)
            logger.info(f"üîç Post-processing: Raw orchestrator output preview: {raw_output[:300]}...")
            image_urls = self._extract_image_urls_from_content(raw_output)
            logger.info(f"üñºÔ∏è Post-processing: Extracted {len(image_urls) if image_urls else 0} image URLs: {image_urls}")
            
            # Calculate final scores
            quality_metrics = generation_result["quality_metrics"]
            performance_prediction = generation_result["performance_prediction"]
            
            # Extract tweet thread if available
            tweet_thread = generation_result.get("tweet_thread")
            
            # Create the response with properly extracted images and thread
            response = ContentGenerationResponse(
                content_text=final_content,
                tweet_thread=tweet_thread,  # Include tweet thread
                content_images=image_urls if image_urls else None,  # Populate content_images field
                predicted_mindshare=performance_prediction["mindshare_score"],
                quality_score=quality_metrics["overall_quality"],
                generation_metadata=generation_result["generation_metadata"],
                agent_contributions=generation_result["agent_contributions"],
                optimization_factors=generation_result["generation_metadata"]["optimization_factors"],
                performance_predictions=performance_prediction
            )
            
            logger.info(f"üìù Generated content: {final_content[:50]}...")
            logger.info(f"üñºÔ∏è  Extracted {len(image_urls) if image_urls else 0} image(s): {image_urls}")
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Error in post-processing: {e}")
            raise

    def _extract_image_urls_from_content(self, raw_result: str) -> List[str]:
        """Extract image URLs from orchestrator output and return as list"""
        try:
            import re
            lines = raw_result.split('\n')
            image_urls = []
            
            # Comprehensive URL patterns for all AI providers
            url_patterns = [
                # LLM Content Extraction Tool format (highest priority)
                r'Image URL:\s*([^\s\n\r]+)',  # "Image URL: https://..."
                r'üì∏\s*Image URL:\s*([^\s\n\r]+)',  # "üì∏ Image URL: https://..."
                
                # S3 Burnie URLs (all variations)
                r'https://burnie-mindshare-content-staging\.s3\.amazonaws\.com/[^\s\]<>"\'`\n\r\[\)]+',
                r'https://burnie-mindshare-content\.s3\.amazonaws\.com/[^\s\]<>"\'`\n\r\[\)]+',
                r'https://[^.\s]*burnie[^.\s]*\.s3\.amazonaws\.com/[^\s\]<>"\'`\n\r\[\)]+',
                
                # OpenAI URLs
                r'https://oaidalleapiprodscus\.blob\.core\.windows\.net/[^\s\]<>"\'`\n\r\[\)]+',
                r'https://cdn\.openai\.com/[^\s\]<>"\'`\n\r\[\)]+',
                
                # Google URLs
                r'https://storage\.googleapis\.com/[^\s\]<>"\'`\n\r\[\)]+',
                r'https://firebasestorage\.googleapis\.com/[^\s\]<>"\'`\n\r\[\)]+',
                
                # Other AI providers
                r'https://replicate\.delivery/[^\s\]<>"\'`\n\r\[\)]+',
                r'https://[^.\s]*stability\.ai[^.\s]*/[^\s\]<>"\'`\n\r\[\)]+',
                
                # Generic image URLs by file extension
                r'https://[^\s\]<>"\'`\n\r\[\)]+\.(?:png|jpg|jpeg|gif|webp)(?:\?[^\s\]<>"\'`\n\r\[\)]*)?',
                
                # AI-generated path pattern
                r'https://[^\s\]<>"\'`\n\r\[\)]*ai-generated[^\s\]<>"\'`\n\r\[\)]*',
                
                # Structured extraction patterns
                r'Image URL:\s*\[?([^\s\]<>"\'`\n\r\[\)]+)\]?',
                r'üì∏\s*Image URL:\s*([^\s\]<>"\'`\n\r\[\)]+)',
                
                # Markdown link patterns: [text](URL)
                r'Image URL:\s*\[[^\]]+\]\(([^)]+)\)',
                r'üì∏\s*Image URL:\s*\[[^\]]+\]\(([^)]+)\)',
                r'\[[^\]]*Image[^\]]*\]\(([^)]+)\)',  # Any text with "Image" in brackets
                
                # Fallback: Any HTTPS URL
                r'https://[^\s\]<>"\'`\n\r\[\)]+'
            ]
            
            # Pattern 1: Handle JSON output from orchestrator (NEW - for structured output)
            try:
                import json
                # Find lines that look like JSON
                for line in lines:
                    line_clean = line.strip()
                    if line_clean.startswith('{') and 'image_url' in line_clean:
                        # Try to parse as JSON
                        json_data = json.loads(line_clean)
                        if 'image_url' in json_data and json_data['image_url']:
                            image_urls.append(json_data['image_url'])
                            logger.info(f"üîç Image extraction: Found URL in JSON format")
                            break
            except (json.JSONDecodeError, ValueError) as e:
                logger.debug(f"üîç JSON parsing failed for image extraction: {e}")
            
            # Pattern 2: Look for structured format with comprehensive patterns
            if not image_urls:
                for i, line in enumerate(lines):
                    if ("üé® VISUAL CONTENT:" in line or "üì∏ Image URL:" in line or 
                        "üé® IMAGE:" in line or "Image URL:" in line):
                        for j in range(i, min(i + 5, len(lines))):
                            if "http" in lines[j]:
                                # Try all URL patterns
                                for pattern in url_patterns:
                                    matches = re.finditer(pattern, lines[j])
                                    for match in matches:
                                        # If pattern has capture groups, use the first group, otherwise use full match
                                        url_match = match.group(1) if match.groups() else match.group(0)
                                        # Clean URL by removing brackets and quotes
                                        clean_url = re.sub(r'[\[\]"\'`]', '', url_match).strip()
                                        if clean_url and clean_url not in image_urls:
                                            image_urls.append(clean_url)
                                            logger.info(f"‚úÖ Found image URL (structured): {clean_url[:100]}...")
                            if image_urls:  # Break if we found URLs
                                break
                    if image_urls:  # Break outer loop if found
                        break
            
            # Pattern 2: Scan entire content for any image URLs
            if not image_urls:
                full_text = ' '.join(lines)
                for pattern in url_patterns:
                    matches = re.finditer(pattern, full_text)
                    for match in matches:
                        # If pattern has capture groups, use the first group, otherwise use full match
                        url_match = match.group(1) if match.groups() else match.group(0)
                        # Clean URL by removing brackets and quotes
                        clean_url = re.sub(r'[\[\]"\'`]', '', url_match).strip()
                        if clean_url and clean_url not in image_urls:
                            image_urls.append(clean_url)
                            logger.info(f"‚úÖ Found image URL (scan): {clean_url[:100]}...")
            
            # Pattern 3: Look for any line containing specific domain patterns
            if not image_urls:
                domain_indicators = [
                    'burnie-mindshare-content',
                    'oaidalleapiprodscus.blob.core.windows.net',
                    'cdn.openai.com',
                    'storage.googleapis.com',
                    'firebasestorage.googleapis.com', 
                    'replicate.delivery',
                    'stability.ai',
                    'ai-generated'
                ]
                
                for line in lines:
                    for indicator in domain_indicators:
                        if indicator in line and 'http' in line:
                            # Extract any HTTPS URL from this line
                            general_url_pattern = r'https://[^\s\]<>"\'`\n\r\[\)]+'
                            url_matches = re.findall(general_url_pattern, line)
                            for url_match in url_matches:
                                clean_url = re.sub(r'[\[\]"\'`]', '', url_match).strip()
                                if clean_url and clean_url not in image_urls:
                                    image_urls.append(clean_url)
                                    logger.info(f"‚úÖ Found image URL (domain): {clean_url[:100]}...")
                            break
                    if image_urls:
                        break
            
            logger.info(f"üîç Total image URLs extracted: {len(image_urls)}")
            return image_urls
            
        except Exception as e:
            logger.error(f"‚ùå Error extracting image URLs: {e}")
            return []

    def _fallback_content_extraction(self, orchestrator_output: str, generation_result: Dict[str, Any]) -> str:
        """Fallback mechanism to manually extract and combine content when orchestrator fails"""
        try:
            logger.info(f"üîß Starting fallback content extraction...")
            
            # Try to extract from crew result metadata or context
            extracted_text = ""
            extracted_image_url = ""
            
            # Look for text content in generation result or orchestrator context
            if hasattr(self, '_last_text_content'):
                extracted_text = self._last_text_content
                logger.info(f"‚úÖ Found cached text content: {extracted_text[:100]}...")
            else:
                # Fallback: Look for any tweet-like content in orchestrator output
                lines = orchestrator_output.split('\n')
                for line in lines:
                    if (len(line.strip()) > 50 and len(line.strip()) < 280 and 
                        ('#' in line or 'üî•' in line or 'üí∞' in line or 'üöÄ' in line)):
                        extracted_text = line.strip()
                        logger.info(f"‚úÖ Extracted text from fallback: {extracted_text[:100]}...")
                        break
            
            # Look for image URLs in orchestrator output or generation metadata
            import re
            
            # Try multiple URL extraction patterns
            url_patterns = [
                # S3 Burnie URLs (all variations)
                r'https://burnie-mindshare-content-staging\.s3\.amazonaws\.com/[^\s\]<>"\'`\n\r\[\)]+',
                r'https://burnie-mindshare-content\.s3\.amazonaws\.com/[^\s\]<>"\'`\n\r\[\)]+',
                r'https://[^.\s]*burnie[^.\s]*\.s3\.amazonaws\.com/[^\s\]<>"\'`\n\r\[\)]+',
                
                # OpenAI URLs
                r'https://oaidalleapiprodscus\.blob\.core\.windows\.net/[^\s\]<>"\'`\n\r\[\)]+',
                r'https://cdn\.openai\.com/[^\s\]<>"\'`\n\r\[\)]+',
                
                # Google URLs
                r'https://storage\.googleapis\.com/[^\s\]<>"\'`\n\r\[\)]+',
                r'https://firebasestorage\.googleapis\.com/[^\s\]<>"\'`\n\r\[\)]+',
                
                # Other AI providers
                r'https://replicate\.delivery/[^\s\]<>"\'`\n\r\[\)]+',
                r'https://[^.\s]*stability\.ai[^.\s]*/[^\s\]<>"\'`\n\r\[\)]+',
                
                # Generic image URLs by file extension
                r'https://[^\s\]<>"\'`\n\r\[\)]+\.(?:png|jpg|jpeg|gif|webp)(?:\?[^\s\]<>"\'`\n\r\[\)]*)?',
                
                # AI-generated path pattern
                r'https://[^\s\]<>"\'`\n\r\[\)]*ai-generated[^\s\]<>"\'`\n\r\[\)]*',
                
                # Structured extraction patterns
                r'Image URL:\s*\[?([^\s\]<>"\'`\n\r\[\)]+)\]?',
                r'üì∏\s*Image URL:\s*([^\s\]<>"\'`\n\r\[\)]+)',
                
                # Markdown link patterns: [text](URL)
                r'Image URL:\s*\[[^\]]+\]\(([^)]+)\)',
                r'üì∏\s*Image URL:\s*\[[^\]]+\]\(([^)]+)\)',
                r'\[[^\]]*Image[^\]]*\]\(([^)]+)\)',  # Any text with "Image" in brackets
                
                # Fallback: Any HTTPS URL
                r'https://[^\s\]<>"\'`\n\r\[\)]+'
            ]
            
            search_text = orchestrator_output + str(generation_result)
            
            for pattern in url_patterns:
                matches = re.findall(pattern, search_text)
                if matches:
                    extracted_image_url = matches[0].strip('[]"\'')
                    logger.info(f"‚úÖ Extracted image URL from fallback: {extracted_image_url[:80]}...")
                    break
            
            # Construct fallback final content
            if not extracted_text:
                extracted_text = "Generated crypto content ready for Twitter! üöÄ #CryptoWisdom"
                
            fallback_content = f"""üì± FINAL TWITTER POST:

üê¶ TEXT:
{extracted_text}

üé® IMAGE:
{extracted_image_url if extracted_image_url else "No image generated"}

‚úÖ STATUS: Ready for publication (Fallback extraction)

üìä Content Stats:
‚Ä¢ Characters: {len(extracted_text)}/280
‚Ä¢ Visual: {'Image included' if extracted_image_url else 'Text-only post'}
‚Ä¢ Source: Fallback mechanism

üí° To Post on Twitter:
1. Copy the text above
2. {'Download and attach the image from the URL' if extracted_image_url else 'Post directly to Twitter'}
3. Post to Twitter!"""

            logger.info(f"üîß Fallback extraction completed successfully")
            return fallback_content
            
        except Exception as e:
            logger.error(f"‚ùå Fallback extraction failed: {e}")
            return """üì± FINAL TWITTER POST:

üê¶ TEXT:
Generated crypto content ready for Twitter! üöÄ #CryptoWisdom

üé® IMAGE:
No image generated

‚úÖ STATUS: Ready for publication (Emergency fallback)"""

    async def _update_progress(self, progress: int, step: str, error: str = None, campaign_id: int = None):
        """Enhanced progress update with campaign-specific messaging"""
        try:
            session = self.progress_tracker.get_session(self.session_id)
            if session:
                session.progress = progress
                session.current_step = step
                if error:
                    session.error = error
                    session.status = MiningStatus.ERROR
                
                # Enhanced WebSocket message with more context
                message = {
                    "type": "progress_update",
                    "session_id": self.websocket_session_id,  # Use WebSocket session ID for frontend
                    "progress": progress,
                    "current_step": step,
                    "agent_statuses": session.agent_statuses,
                    "timestamp": datetime.utcnow().isoformat(),
                    "error": error
                }
                
                # Add campaign-specific context if provided
                if campaign_id:
                    message["campaign_id"] = campaign_id
                    message["campaign_context"] = {
                        "id": campaign_id,
                        "title": getattr(self, 'campaign_data', {}).get('title', 'Unknown'),
                        "platform": getattr(self, 'campaign_data', {}).get('platform_source', 'Unknown')
                    }
                
                # Send WebSocket update with retry logic
                try:
                    await self.websocket_manager.send_progress_update(self.websocket_session_id, message)
                    logger.info(f"üì° Progress WebSocket: {progress}% - {step}")
                except Exception as ws_error:
                    logger.warning(f"‚ö†Ô∏è WebSocket send failed: {ws_error}")
                
                # Adaptive delay based on progress stage
                delay = 0.2 if progress < 50 else 0.1
                await asyncio.sleep(delay)
                
        except Exception as e:
            logger.error(f"‚ùå Error updating progress: {e}")

    async def _update_agent_status(self, agent_type: AgentType, status: AgentStatus, task: str = "", metadata: Dict[str, Any] = None):
        """Enhanced agent status update with metadata and detailed tracking"""
        try:
            session = self.progress_tracker.get_session(self.session_id)
            if session:
                session.agent_statuses[agent_type] = status
                
                # Enhanced agent update message
                message = {
                    "type": "agent_update",
                    "session_id": self.websocket_session_id,  # Use WebSocket session ID for frontend
                    "agent_type": agent_type.value if hasattr(agent_type, 'value') else str(agent_type),
                    "status": status.value if hasattr(status, 'value') else str(status),
                    "task": task,
                    "agent_statuses": {k.value if hasattr(k, 'value') else str(k): v.value if hasattr(v, 'value') else str(v) 
                                     for k, v in session.agent_statuses.items()},
                    "timestamp": datetime.utcnow().isoformat(),
                    "metadata": metadata or {}
                }
                
                # Add agent-specific context
                agent_info = self._get_agent_info(agent_type)
                if agent_info:
                    message["agent_info"] = agent_info
                
                # Send WebSocket update with retry logic
                try:
                    await self.websocket_manager.send_progress_update(self.websocket_session_id, message)
                    logger.info(f"ü§ñ Agent WebSocket: {agent_type} -> {status} ({task})")
                except Exception as ws_error:
                    logger.warning(f"‚ö†Ô∏è Agent WebSocket send failed: {ws_error}")
                
                # Ensure message ordering
                await asyncio.sleep(0.1)
                
        except Exception as e:
            logger.error(f"‚ùå Error updating agent status: {e}")
    
    async def _send_generation_milestone(self, milestone: str, data: Dict[str, Any], campaign_id: int = None):
        """Send major generation milestones for enhanced frontend tracking"""
        try:
            message = {
                "type": "generation_milestone",
                "session_id": self.websocket_session_id,  # Use WebSocket session ID for frontend
                "milestone": milestone,
                "data": data,
                "timestamp": datetime.utcnow().isoformat()
            }
            
            if campaign_id:
                message["campaign_id"] = campaign_id
            
            await self.websocket_manager.send_progress_update(self.websocket_session_id, message)
            logger.info(f"üéØ Milestone WebSocket: {milestone}")
            
        except Exception as e:
            logger.error(f"‚ùå Error sending milestone: {e}")
    
    async def _send_content_preview(self, content_type: str, preview_data: Dict[str, Any], campaign_id: int = None):
        """Send real-time content previews as they're generated"""
        try:
            message = {
                "type": "content_preview",
                "session_id": self.websocket_session_id,  # Use WebSocket session ID for frontend
                "content_type": content_type,
                "preview": preview_data,
                "timestamp": datetime.utcnow().isoformat()
            }
            
            if campaign_id:
                message["campaign_id"] = campaign_id
            
            await self.websocket_manager.send_progress_update(self.websocket_session_id, message)
            logger.info(f"üëÄ Content Preview: {content_type}")
            
        except Exception as e:
            logger.error(f"‚ùå Error sending content preview: {e}")
    
    def _get_agent_info(self, agent_type: AgentType) -> Dict[str, Any]:
        """Get descriptive information about each agent type"""
        agent_descriptions = {
            AgentType.DATA_ANALYST: {
                "name": "Data Analyst",
                "role": "Campaign Intelligence",
                "description": "Analyzes campaign data and market trends",
                "emoji": "üìä"
            },
            AgentType.CONTENT_STRATEGIST: {
                "name": "Content Strategist", 
                "role": "Strategic Planning",
                "description": "Develops content strategy and approach",
                "emoji": "üéØ"
            },
            AgentType.TEXT_CONTENT: {
                "name": "Text Creator",
                "role": "Content Generation", 
                "description": "Generates engaging text content",
                "emoji": "‚úçÔ∏è"
            },
            AgentType.VISUAL_CREATOR: {
                "name": "Visual Creator",
                "role": "Visual Design",
                "description": "Creates visual content concepts",
                "emoji": "üé®"
            },
            AgentType.ORCHESTRATOR: {
                "name": "Orchestrator",
                "role": "Final Assembly",
                "description": "Optimizes and finalizes content",
                "emoji": "üé≠"
            }
        }
        
        return agent_descriptions.get(agent_type, {
            "name": str(agent_type),
            "role": "AI Agent",
            "description": "Specialized AI processing",
            "emoji": "ü§ñ"
        })

    def _get_llm_instance(self):
        """Get LLM instance based on configuration"""
        provider = "openai"  # Default, could be made configurable per user
        
        if provider == "openai":
            return ChatOpenAI(
                openai_api_key=settings.openai_api_key,
                model_name=settings.crewai_model,
                temperature=settings.crewai_temperature,
                max_tokens=settings.crewai_max_tokens
            )
        elif provider == "anthropic":
            return ChatAnthropic(
                anthropic_api_key=settings.anthropic_api_key,
                model="claude-3-sonnet-20240229",
                temperature=settings.crewai_temperature
            )
        elif provider == "google":
            return ChatGoogleGenerativeAI(
                google_api_key=settings.google_api_key,
                model="gemini-pro",
                temperature=settings.crewai_temperature
            )
        else:
            # Fallback to OpenAI with GPT-4o (faster and more cost-effective than GPT-3.5-turbo)
            return ChatOpenAI(
                openai_api_key=settings.openai_api_key,
                model_name="gpt-4o",
                temperature=settings.crewai_temperature,
                max_tokens=settings.crewai_max_tokens
            )

    def _get_twitter_context(self) -> str:
        """Get Twitter context for agents"""
        if self.twitter_insights:
            return f"""
            User's Twitter insights:
            - Average engagement rate: {self.twitter_insights.get('avg_engagement_rate', 'N/A')}%
            - Optimal posting times: {self.twitter_insights.get('optimal_times', 'N/A')}
            - Top hashtags: {self.twitter_insights.get('top_hashtags', 'N/A')}
            - Writing style: {self.twitter_insights.get('writing_style', 'N/A')}
            """
        return "No Twitter data available - using general best practices"

    def _get_campaign_context(self) -> str:
        """Get campaign context for agents"""
        if self.campaign_data:
            return f"""
            Campaign: {self.campaign_data.get('title', 'N/A')}
            Platform: {self.campaign_data.get('platformSource', 'twitter')}
            Description: {self.campaign_data.get('description', 'N/A')}
            Target Audience: {self.campaign_data.get('targetAudience', 'N/A')}
            Brand Guidelines: {self.campaign_data.get('brandGuidelines', 'N/A')}
            Reward Token: {self.campaign_data.get('rewardToken', 'N/A')}
            """
        return "Campaign data not available"

    def _get_user_writing_style(self) -> str:
        """Get user's writing style from Twitter analysis"""
        if self.twitter_insights and 'writing_style' in self.twitter_insights:
            style = self.twitter_insights['writing_style']
            return f"""
            Average post length: {style.get('avg_length', 150)} characters
            Hashtag usage: {style.get('hashtag_usage', 2)} per post
            Emoji usage: {style.get('emoji_usage', 'moderate')}
            Tone: {style.get('tone', 'professional')}
            """
        return "No specific writing style data - using platform best practices"

    async def _sync_to_marketplace(self, content: ContentGenerationResponse, mining_session: MiningSession) -> bool:
        """Sync generated content to TypeScript backend marketplace"""
        try:
            import httpx
            from app.config.settings import settings
            
            # Prepare content data for marketplace
            content_data = {
                "content_text": content.content_text,
                "tweet_thread": getattr(content, 'tweet_thread', None),  # Include tweet thread if available
                "content_images": content.content_images,  # Include images in sync payload
                "predicted_mindshare": content.predicted_mindshare,
                "quality_score": content.quality_score,
                "generation_metadata": content.generation_metadata,
                "post_type": getattr(mining_session, 'post_type', 'thread')  # Include post type from mining session
            }
            
            # Calculate asking price based on quality score
            base_price = 15  # Base price in ROAST tokens
            quality_multiplier = content.quality_score / 100
            asking_price = max(base_price * quality_multiplier, 10)  # Minimum 10 ROAST
            
            # Use configured TypeScript backend URL
            typescript_backend_url = settings.typescript_backend_url
            
            sync_payload = {
                "content_data": content_data,
                "creator_id": mining_session.user_id,
                "asking_price": asking_price
            }
            
            logger.info(f"üîÑ Syncing content to marketplace with {len(content.content_images) if content.content_images else 0} image(s)")
            
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{typescript_backend_url}/api/campaigns/{mining_session.campaign_id}/sync-content",
                    json=sync_payload,
                    timeout=10.0
                )
                
                if response.status_code == 201:
                    sync_result = response.json()
                    logger.info(f"‚úÖ Content synced to marketplace: ID {sync_result['data']['id']}")
                    return True
                else:
                    logger.warning(f"‚ö†Ô∏è Marketplace sync failed: {response.status_code} - {response.text}")
                    return False
                    
        except Exception as e:
            logger.error(f"‚ùå Error syncing content to marketplace: {e}")
            return False

    def _extract_twitter_content(self, raw_result: str) -> Dict[str, Any]:
        """Extract Twitter content directly from agent JSON - SIMPLE VERSION"""
        import json
        import re
        
        logger.info(f"üîç Direct JSON extraction from agent outputs...")
        
        final_text = ""
        tweet_thread = None
        image_url = ""
        
        # STEP 1: Extract from Text Content Creator JSON
        try:
            # Look for main_tweet and thread_array in JSON
            # Use a more robust regex that handles escaped quotes and quoted content
            main_tweet_match = re.search(r'"main_tweet"\s*:\s*"((?:[^"\\]|\\.|\\n|\\r|\\t)*)"', raw_result, re.DOTALL)
            if main_tweet_match:
                final_text = main_tweet_match.group(1)
                # Unescape any escaped quotes and other escape sequences in the content
                final_text = final_text.replace('\\n', '\n').replace('\\r', '\r').replace('\\t', '\t').replace('\\"', '"').replace('\\\\', '\\')
                logger.info(f"‚úÖ Found main_tweet in _extract_twitter_content: {len(final_text)} chars")
            
            # Look for thread_array
            thread_match = re.search(r'"thread_array"\s*:\s*(\[[^\]]*\])', raw_result)
            if thread_match:
                try:
                    tweet_thread = json.loads(thread_match.group(1))
                    logger.info(f"‚úÖ Found thread_array: {len(tweet_thread)} tweets")
                except:
                    pass
        except Exception as e:
            logger.warning(f"‚ùå JSON extraction failed: {e}")
        
        # STEP 2: Fallback to extraction tool format
        if not final_text:
            tweet_match = re.search(r'Tweet Text:\s*(.+)', raw_result)
            if tweet_match:
                final_text = tweet_match.group(1).strip().strip('"')
        
        if not tweet_thread:
            # First try to find JSON array format
            thread_match = re.search(r'Tweet Thread:\s*(\[.+?\])', raw_result, re.DOTALL)
            if thread_match:
                try:
                    tweet_thread = json.loads(thread_match.group(1))
                    logger.info(f"‚úÖ Found thread_array in JSON format: {len(tweet_thread)} tweets")
                except:
                    pass
            
            # If no JSON array found, look for multi-line format (1/6, 2/6, etc.)
            if not tweet_thread:
                thread_lines = []
                lines = raw_result.split('\n')
                in_thread_section = False
                
                for line in lines:
                    line_stripped = line.strip()
                    if line_stripped.startswith('Tweet Thread:'):
                        in_thread_section = True
                        continue
                    elif in_thread_section:
                        # Check if line looks like a thread item (starts with number/)
                        if re.match(r'^\d+/\d+', line_stripped) or (line_stripped and not line_stripped.startswith('Image URL:')):
                            if line_stripped:  # Don't add empty lines
                                thread_lines.append(line_stripped)
                        elif line_stripped.startswith('Image URL:') or not line_stripped:
                            # End of thread section
                            break
                
                if thread_lines:
                    tweet_thread = thread_lines
                    logger.info(f"‚úÖ Found thread in multi-line format: {len(tweet_thread)} tweets")
        
        # STEP 3: Extract image URL
        image_match = re.search(r'"image_url"\s*:\s*"([^"]*)"', raw_result)
        if image_match:
            image_url = image_match.group(1)
        elif 'Image URL:' in raw_result:
            url_match = re.search(r'Image URL:\s*([^\s]+)', raw_result)
            if url_match:
                image_url = url_match.group(1)
        
        logger.info(f"üéØ Extraction results: text={bool(final_text)}, thread={len(tweet_thread) if tweet_thread else 0}, image={bool(image_url)}")
        
        return {
            "content_text": final_text,
            "tweet_thread": tweet_thread,
            "image_url": image_url
        }
    
    def _format_for_twitter(self, text: str, post_type: str = "thread") -> str:
        """Clean and format text for Twitter posting"""
        text = text.strip()
        text = re.sub(r'^[üê¶üì±üé®üéØüìä‚úÖ‚öôÔ∏è‚è∞üí°]+\s*', '', text)
        text = re.sub(r'\s+', ' ', text)
        text = text.strip('"').strip("'")
        
        # Only apply Twitter character limit for threads and shitposts, NOT for longposts
        if post_type != "longpost" and len(text) > 280:
            text = text[:276] + "..."
        
        return text

    def _get_fallback_models(self):
        """Get fallback models for each content type"""
        return {
            'text': [
                {'provider': 'openai', 'model': 'gpt-4o'},
                {'provider': 'openai', 'model': 'gpt-4o-mini'},
                {'provider': 'anthropic', 'model': 'claude-4-sonnet'}
            ],
            'image': [
                {'provider': 'openai', 'model': 'dall-e-3'},
                {'provider': 'openai', 'model': 'dall-e-2'}
            ],
            'video': [
                {'provider': 'google', 'model': 'veo-3'}
            ],
            'audio': [
                {'provider': 'openai', 'model': 'tts-1-hd'},
                {'provider': 'openai', 'model': 'tts-1'}
            ]
        }


# Simplified schema for the tool arguments  
class LeaderboardYapperToolInput(BaseModel):
    query: str = Field(default="", description="Analysis request for success patterns")

# Leaderboard Yapper Success Pattern Analysis Tool
class LeaderboardYapperSuccessPatternTool(BaseTool):
    name: str = "leaderboard_success_patterns"
    description: str = "Extract and analyze success patterns from 3 randomly selected leaderboard yappers for the current campaign. Call this tool with any string input to get insights."
    campaign_id: int = None
    user_api_keys: Dict[str, str] = {}
    model_preferences: Dict[str, Any] = {}
    
    def __init__(self, campaign_id: int, user_api_keys: Dict[str, str] = None, model_preferences: Dict[str, Any] = None):
        super().__init__()
        self.campaign_id = campaign_id
        self.user_api_keys = user_api_keys or {}
        self.model_preferences = model_preferences or {}
    
    def _run(self, **kwargs) -> str:
        """
        Extract success patterns from top 3 leaderboard yappers for the current campaign
        
        Args:
            **kwargs: Flexible arguments - handles various CrewAI input formats
            
        Returns:
            JSON string with structured yapper success patterns
        """
        try:
            # Handle flexible input - CrewAI might pass various argument formats
            query_text = ""
            if 'query' in kwargs:
                query_text = str(kwargs['query'])
            elif 'analysis_request' in kwargs:
                query_text = str(kwargs['analysis_request'])
            elif 'description' in kwargs:
                query_text = str(kwargs['description'])
            elif len(kwargs) == 1:
                # If there's only one argument, use its value regardless of key
                query_text = str(list(kwargs.values())[0])
            
            logger.info(f"üèÜ Extracting success patterns for campaign {self.campaign_id}: {query_text}")
            logger.info(f"üîß Tool received kwargs: {kwargs}")
            
            # Get top yappers' success patterns from database
            success_patterns = asyncio.run(self._extract_yapper_success_patterns())
            
            if not success_patterns:
                return "No leaderboard yapper success patterns available for this campaign."
            
            # Summarize patterns using LLM
            insights = asyncio.run(self._summarize_success_patterns(success_patterns))
            
            return insights
            
        except Exception as e:
            logger.error(f"‚ùå Error extracting success patterns: {str(e)}")
            return f"Error extracting success patterns: {str(e)}"
    
    async def _extract_yapper_success_patterns(self) -> List[Dict[str, Any]]:
        """Extract and aggregate success patterns from database"""
        try:
            import asyncpg
            from app.config.settings import settings
            
            conn = await asyncpg.connect(
                host=settings.database_host,
                port=settings.database_port,
                user=settings.database_user,
                password=settings.database_password,
                database=settings.database_name
            )
            
            try:
                logger.info(f"üîç Starting success pattern extraction for campaign {self.campaign_id}")
                
                # First, let's check what data exists for this campaign
                check_query = """
                SELECT 
                    "twitterHandle",
                    "leaderboardPosition",
                    LENGTH("anthropic_analysis"::text) as anthropic_len,
                    LENGTH("openai_analysis"::text) as openai_len,
                    LEFT("anthropic_analysis"::text, 100) as anthropic_preview,
                    LEFT("openai_analysis"::text, 100) as openai_preview
                FROM leaderboard_yapper_data 
                WHERE "campaignId" = $1 
                AND "leaderboardPosition" IS NOT NULL
                ORDER BY "leaderboardPosition" ASC
                LIMIT 5;
                """
                
                check_rows = await conn.fetch(check_query, self.campaign_id)
                logger.info(f"üìä Found {len(check_rows)} records for campaign {self.campaign_id}")
                
                for i, row in enumerate(check_rows):
                    logger.info(f"  Row {i+1}: {row['twitterHandle']} (pos: {row['leaderboardPosition']}) - "
                              f"anthropic: {row['anthropic_len']}chars, openai: {row['openai_len']}chars")
                    if row['anthropic_preview']:
                        logger.info(f"    anthropic_preview: {row['anthropic_preview']}")
                    if row['openai_preview']:
                        logger.info(f"    openai_preview: {row['openai_preview']}")
                
                # SQL Query: Get 3 random yappers (not just top performers) for variability
                query = """
                WITH yapper_best_positions AS (
                    SELECT 
                        "twitterHandle",
                        MIN("leaderboardPosition") as best_position,
                        ARRAY_AGG(
                            CASE 
                                WHEN "anthropic_analysis" IS NOT NULL 
                                AND "anthropic_analysis"::text != '' 
                                AND "anthropic_analysis"::text != 'null'
                                AND LENGTH(TRIM("anthropic_analysis"::text)) > 2
                                AND LEFT(TRIM("anthropic_analysis"::text), 1) = '{'
                                THEN "anthropic_analysis" 
                            END
                        ) FILTER (WHERE "anthropic_analysis" IS NOT NULL 
                                   AND "anthropic_analysis"::text != '' 
                                   AND "anthropic_analysis"::text != 'null'
                                   AND LENGTH(TRIM("anthropic_analysis"::text)) > 2
                                   AND LEFT(TRIM("anthropic_analysis"::text), 1) = '{') as anthropic_analyses,
                        ARRAY_AGG(
                            CASE 
                                WHEN "openai_analysis" IS NOT NULL 
                                AND "openai_analysis"::text != '' 
                                AND "openai_analysis"::text != 'null'
                                AND LENGTH(TRIM("openai_analysis"::text)) > 2
                                AND LEFT(TRIM("openai_analysis"::text), 1) = '{'
                                THEN "openai_analysis" 
                            END
                        ) FILTER (WHERE "openai_analysis" IS NOT NULL 
                                   AND "openai_analysis"::text != '' 
                                   AND "openai_analysis"::text != 'null'
                                   AND LENGTH(TRIM("openai_analysis"::text)) > 2
                                   AND LEFT(TRIM("openai_analysis"::text), 1) = '{') as openai_analyses
                    FROM leaderboard_yapper_data 
                    WHERE "campaignId" = $1 
                        AND "twitterFetchStatus" = 'completed'
                        AND "leaderboardPosition" IS NOT NULL
                    GROUP BY "twitterHandle"
                )
                SELECT 
                    "twitterHandle",
                    best_position,
                    anthropic_analyses,
                    openai_analyses
                FROM yapper_best_positions
                WHERE (anthropic_analyses IS NOT NULL OR openai_analyses IS NOT NULL)
                ORDER BY RANDOM()  -- Random selection instead of best position
                LIMIT 3
                """
                
                logger.info("üîç Executing main query to get 3 random yappers for variability...")
                records = await conn.fetch(query, self.campaign_id)
                logger.info(f"üìä Got {len(records)} random yappers from main query")
                
                if not records:
                    logger.warning(f"‚ö†Ô∏è No leaderboard yappers found for campaign {self.campaign_id}")
                    return []
                
                success_patterns = []
                for i, record in enumerate(records):
                    twitter_handle = record['twitterHandle']
                    best_position = record['best_position']
                    
                    logger.info(f"  Processing yapper {i+1}: @{twitter_handle} (best position: {best_position})")
                    
                    # Combine and deduplicate analyses
                    combined_analyses = []
                    
                    # Add anthropic analyses
                    if record['anthropic_analyses']:
                        logger.info(f"    Found {len(record['anthropic_analyses'])} anthropic analyses")
                        for j, analysis in enumerate(record['anthropic_analyses']):
                            if analysis:
                                logger.info(f"      Anthropic analysis {j+1} type: {type(analysis)}")
                                combined_analyses.append(analysis)
                    
                    # Add openai analyses
                    if record['openai_analyses']:
                        logger.info(f"    Found {len(record['openai_analyses'])} openai analyses")
                        for j, analysis in enumerate(record['openai_analyses']):
                            if analysis:
                                logger.info(f"      OpenAI analysis {j+1} type: {type(analysis)}")
                                combined_analyses.append(analysis)
                    
                    logger.info(f"    Total analyses before dedup: {len(combined_analyses)}")
                    
                    # Deduplicate similar JSONs (basic deduplication by content similarity)
                    deduplicated = self._deduplicate_analyses(combined_analyses)
                    logger.info(f"    Total analyses after dedup: {len(deduplicated)}")
                    
                    if deduplicated:
                        success_patterns.append({
                            'twitter_handle': twitter_handle,
                            'best_position': best_position,
                            'analyses': deduplicated
                        })
                        
                        logger.info(f"üèÜ Extracted {len(deduplicated)} analyses for @{twitter_handle} (position #{best_position})")
                
                logger.info(f"‚úÖ Final result: Found success patterns from {len(success_patterns)} top yappers")
                return success_patterns
                
            finally:
                await conn.close()
                
        except Exception as e:
            logger.error(f"‚ùå Database error extracting success patterns: {str(e)}")
            logger.error(f"‚ùå Full traceback: {traceback.format_exc()}")
            return []
    
    def _deduplicate_analyses(self, analyses: List[Dict]) -> List[Dict]:
        """Remove duplicate analyses based on content similarity"""
        if not analyses:
            return []
        
        deduplicated = []
        seen_signatures = set()
        
        for analysis in analyses:
            if not analysis:
                continue
                
            try:
                # Handle both dict and string (JSON) inputs
                if isinstance(analysis, str):
                    analysis_dict = json.loads(analysis)
                elif isinstance(analysis, dict):
                    analysis_dict = analysis
                else:
                    logger.warning(f"‚ö†Ô∏è Unexpected analysis type: {type(analysis)}")
                    continue
                    
                # Remove ml_features as requested
                filtered_analysis = {k: v for k, v in analysis_dict.items() if k != 'ml_features'}
                
                # Create a simple signature for deduplication
                signature = str(sorted(filtered_analysis.items()))
                
                if signature not in seen_signatures:
                    seen_signatures.add(signature)
                    deduplicated.append(filtered_analysis)
                    
            except json.JSONDecodeError as e:
                logger.warning(f"‚ö†Ô∏è Failed to parse analysis JSON: {e}")
                continue
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error processing analysis: {e}")
                continue
        
        return deduplicated
    
    async def _summarize_success_patterns(self, success_patterns: List[Dict[str, Any]]) -> str:
        """Summarize success patterns using LLM"""
        try:
            # Determine which LLM to use based on user preferences
            text_provider = self.model_preferences.get('text', {}).get('provider', 'openai')
            text_model = self.model_preferences.get('text', {}).get('model', 'gpt-4o')
            
            # Create comprehensive prompt for LLM analysis
            prompt = self._create_summarization_prompt(success_patterns)
            
            # Get LLM response
            if text_provider == 'openai' and self.user_api_keys.get('openai'):
                response = await self._call_openai_for_summary(prompt, text_model)
            elif text_provider == 'anthropic' and self.user_api_keys.get('anthropic'):
                response = await self._call_anthropic_for_summary(prompt, text_model)
            else:
                # Fallback to any available provider
                if self.user_api_keys.get('openai'):
                    response = await self._call_openai_for_summary(prompt, 'gpt-4o')
                elif self.user_api_keys.get('anthropic'):
                    response = await self._call_anthropic_for_summary(prompt, 'claude-3-5-sonnet-20241022')
                else:
                    return "No LLM provider available for success pattern analysis."
            
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Error summarizing success patterns: {str(e)}")
            return f"Error summarizing success patterns: {str(e)}"
    
    def _create_summarization_prompt(self, success_patterns: List[Dict[str, Any]]) -> str:
        """Create comprehensive prompt for LLM analysis"""
        patterns_text = ""
        
        for i, pattern in enumerate(success_patterns, 1):
            patterns_text += f"\n--- YAPPER #{i}: @{pattern['twitter_handle']} (Rank #{pattern['best_position']}) ---\n"
            patterns_text += f"Number of analyses: {len(pattern['analyses'])}\n"
            
            for j, analysis in enumerate(pattern['analyses'], 1):
                patterns_text += f"\nAnalysis {j}:\n{json.dumps(analysis, indent=2)}\n"
        
        prompt = f"""
You are analyzing success patterns from 3 randomly selected leaderboard yappers for this campaign. This diverse sampling provides varied strategies and prevents "rich-get-richer" bias, giving exposure to different approaches on the leaderboard.

LEADERBOARD YAPPER SUCCESS PATTERNS:
{patterns_text}

Your task is to extract actionable insights for each yapper individually, preserving their Twitter handle identity for potential tagging in generated content.

CRITICAL: You MUST respond with VALID JSON in the following exact format:

{{
  "yappers": [
    {{
      "twitter_handle": "@exact_handle_from_data",
      "leaderboard_position": rank_number,
      "text_success_patterns": {{
        "topic_strategy": "specific topic approach that works",
        "winning_formulas": "proven content formats and structures",
        "communication_style": "voice and tone that resonates",
        "platform_optimization": "hashtag/timing/engagement techniques",
        "key_insights": ["insight1", "insight2", "insight3"]
      }},
      "visual_success_patterns": {{
        "viral_mechanics": "what makes visuals engaging",
        "trending_elements": ["element1", "element2", "element3"],
        "production_quality": "quality standards and aesthetic",
        "audience_resonance": "what visual themes work",
        "key_insights": ["insight1", "insight2", "insight3"]
      }},
      "competitive_intelligence": {{
        "differentiation_factors": "what makes them unique",
        "replicable_strategies": "tactics others can copy",
        "engagement_drivers": "what boosts their performance",
        "content_calendar_insights": "timing and frequency patterns"
      }}
    }}
  ],
  "overall_insights": {{
    "common_success_patterns": "patterns across all top yappers",
    "platform_optimization_tips": "universal strategies that work",
    "content_generation_recommendations": "how to apply these patterns"
  }}
}}

REQUIREMENTS:
- Each yapper must be listed individually with their exact @handle
- Provide concrete, actionable insights for each yapper
- Focus on patterns that can be replicated
- Extract both text and visual success strategies
- Make insights directly usable for content generation
- Preserve yapper identity for potential Twitter handle tagging

RESPOND ONLY WITH VALID JSON - NO OTHER TEXT OR FORMATTING.
"""
        
        return prompt
    
    async def _call_openai_for_summary(self, prompt: str, model: str) -> str:
        """Call OpenAI for success pattern summary"""
        try:
            from app.ai.openai_content_generation import OpenAIContentGenerator
            generator = OpenAIContentGenerator(api_key=self.user_api_keys['openai'])
            
            response = generator.generate_text(
                prompt=prompt,
                model=model,
                max_tokens=2000,
                temperature=0.7
            )
            
            # OpenAIContentGenerator.generate_text returns text directly
            return response if isinstance(response, str) else str(response)
            
        except Exception as e:
            logger.error(f"‚ùå OpenAI summary error: {str(e)}")
            return f"OpenAI summary error: {str(e)}"
    
    async def _call_anthropic_for_summary(self, prompt: str, model: str) -> str:
        """Call Anthropic for success pattern summary"""
        try:
            from app.ai.claude_content_generation import ClaudeContentGenerator
            generator = ClaudeContentGenerator(api_key=self.user_api_keys['anthropic'])
            
            response = generator.generate_text(
                prompt=prompt,
                model=model,
                max_tokens=2000,
                temperature=0.7
            )
            
            # ClaudeContentGenerator.generate_text returns text directly
            return response if isinstance(response, str) else str(response)
            
        except Exception as e:
            logger.error(f"‚ùå Anthropic summary error: {str(e)}")
            return f"Anthropic summary error: {str(e)}"

# CrewAI Tools with real mindshare prediction capabilities
class MindshareAnalysisTool(BaseTool):
    name: str = "mindshare_analysis"
    description: str = "Analyze Twitter learning data and mindshare patterns using ML models and user's Twitter insights"
    predictor: Any = None
    campaign_context: Dict[str, Any] = {}
    twitter_learning_repo: Any = None
    user_id: int = None
    agent_id: int = None
    
    def __init__(self, predictor: 'MindsharePredictor', campaign_context: Dict[str, Any] = None, twitter_learning_repo: Any = None, user_id: int = None, agent_id: int = None):
        super().__init__()
        self.predictor = predictor
        self.campaign_context = campaign_context or {}
        self.twitter_learning_repo = twitter_learning_repo
        self.user_id = user_id
        self.agent_id = agent_id
    
    def _run(self, **kwargs) -> str:
        """
        Provide comprehensive analysis using Twitter learning data and mindshare models
        
        Args:
            **kwargs: Flexible arguments - handles various CrewAI input formats
            
        Returns:
            Comprehensive analysis of Twitter learning data and mindshare patterns
        """
        try:
            # Handle flexible input - CrewAI might pass various argument formats
            query_text = ""
            if 'query' in kwargs:
                query_text = str(kwargs['query'])
            elif 'analysis_request' in kwargs:
                query_text = str(kwargs['analysis_request'])
            elif 'description' in kwargs:
                query_text = str(kwargs['description'])
            elif len(kwargs) == 1:
                # If there's only one argument, use its value regardless of key
                query_text = str(list(kwargs.values())[0])
            
            logger.info(f"üß† Mindshare analysis query: {query_text}")
            logger.info(f"üîß Mindshare tool received kwargs: {kwargs}")
            
            platform = self.campaign_context.get('platform_source', 'Twitter')
            campaign_type = self.campaign_context.get('campaign_type', 'meme')
            
            # Get agent-specific Twitter learning data for this user and agent
            twitter_insights = {}
            if self.twitter_learning_repo and self.user_id and self.agent_id:
                try:
                    # Use the new agent-specific method
                    twitter_data = self.twitter_learning_repo.get_agent_twitter_data(self.user_id, self.agent_id)
                    if twitter_data and twitter_data.get('learningData'):
                        learning_data = twitter_data['learningData']
                        twitter_insights = {
                            'total_tweets_analyzed': learning_data.get('total_tweets', 0),
                            'avg_engagement': learning_data.get('average_engagement', 0),
                            'top_hashtags': learning_data.get('popular_hashtags', []),
                            'content_patterns': learning_data.get('content_patterns', {}),
                            'optimal_posting_times': learning_data.get('best_times', []),
                            'audience_demographics': learning_data.get('audience_info', {}),
                            'viral_content_characteristics': learning_data.get('viral_patterns', {}),
                            'user_writing_style': learning_data.get('writing_style', {})
                        }
                        logger.info(f"‚úÖ Found agent-specific Twitter learning data: {twitter_insights['total_tweets_analyzed']} tweets analyzed")
                    else:
                        logger.warning(f"‚ö†Ô∏è No agent-specific Twitter learning data found for user {self.user_id}, agent {self.agent_id}")
                except Exception as e:
                    logger.warning(f"Could not retrieve agent-specific Twitter learning data: {e}")
            
            # Get mindshare predictions from ML models
            mindshare_prediction = 75.0  # Default
            if self.predictor:
                try:
                    sample_content = f"Sample {campaign_type} content for {platform}"
                    # Use synchronous prediction heuristic (avoid async in sync tool context)
                    content_length = len(sample_content)
                    hashtag_count = sample_content.count('#')
                    # Simple heuristic for prediction
                    mindshare_prediction = min(90.0, 60.0 + (hashtag_count * 5) + (content_length / 10))
                    logger.info(f"üí° Using synchronous mindshare prediction: {mindshare_prediction}")
                        
                except Exception as e:
                    logger.warning(f"Mindshare prediction error: {e}")
                    mindshare_prediction = 75.0
            
            # Combine Twitter insights with mindshare predictions
                analysis = f"""
üß† COMPREHENSIVE DATA ANALYSIS:

üìä TWITTER LEARNING INSIGHTS:
{self._format_twitter_insights(twitter_insights)}

ü§ñ MINDSHARE ML PREDICTIONS:
- Predicted mindshare score: {mindshare_prediction:.1f}/100
- Campaign type performance: {campaign_type.upper()}
- Platform optimization: {platform}
- Confidence level: {85.0 + (mindshare_prediction - 50)/5:.1f}%

üéØ STRATEGIC CONTENT RECOMMENDATIONS:
{self._generate_content_strategy(twitter_insights, mindshare_prediction, campaign_type)}

üî• VIRAL POTENTIAL ANALYSIS:
{self._analyze_viral_potential(twitter_insights, mindshare_prediction)}

üí° PERSONALIZATION INSIGHTS:
{self._get_personalization_recommendations(twitter_insights)}
"""
                return analysis
            
        except Exception as e:
            logger.error(f"Mindshare analysis error: {e}")
            return f"""
‚ö†Ô∏è MINDSHARE ANALYSIS - ERROR:

Error: {str(e)}
Fallback: Using baseline recommendations for {self.campaign_context.get('campaign_type', 'content')} content
Recommendation: Review agent configuration and Twitter connection
"""

    def _format_twitter_insights(self, insights: Dict[str, Any]) -> str:
        """Format Twitter learning data for analysis"""
        if not insights or not insights.get('total_tweets_analyzed'):
            return """
‚ùå No Twitter learning data available
üìã Recommendation: Connect Twitter account and sync learning data
üîÑ Using baseline engagement patterns"""
        
        return f"""
‚úÖ Twitter Data Available: {insights['total_tweets_analyzed']} tweets analyzed
üìà Average Engagement: {insights['avg_engagement']:.2f}%
üè∑Ô∏è Top Hashtags: {', '.join(insights['top_hashtags'][:5]) if insights['top_hashtags'] else 'None found'}
‚è∞ Optimal Times: {', '.join(map(str, insights['optimal_posting_times'][:3])) if insights['optimal_posting_times'] else 'Not determined'}
üéØ Writing Style: {insights['user_writing_style'].get('tone', 'Professional')} tone, {insights['user_writing_style'].get('length', 'Medium')} length"""

    def _generate_content_strategy(self, insights: Dict[str, Any], mindshare_score: float, campaign_type: str) -> str:
        """Generate content strategy based on combined data"""
        base_strategy = f"""
- Content Type: {campaign_type.upper()} optimized for viral engagement
- Target Mindshare: {mindshare_score:.1f}/100 (ML prediction)"""
        
        if insights and insights.get('total_tweets_analyzed', 0) > 0:
            return base_strategy + f"""
- Hashtag Strategy: Use proven tags: {', '.join(insights['top_hashtags'][:3]) if insights['top_hashtags'] else '#viral #crypto'}
- Tone Alignment: {insights['user_writing_style'].get('tone', 'Engaging')} style
- Length Target: {insights['user_writing_style'].get('length', 'Concise')} format
- Posting Time: {insights['optimal_posting_times'][0] if insights['optimal_posting_times'] else 'Peak hours'}"""
        else:
            return base_strategy + """
- Hashtag Strategy: Use trending crypto/meme hashtags
- Tone: Engaging and community-focused
- Length: Twitter-optimized (under 280 chars)
- Timing: Peak engagement hours"""

    def _analyze_viral_potential(self, insights: Dict[str, Any], mindshare_score: float) -> str:
        """Analyze viral potential based on data"""
        viral_score = min(95.0, mindshare_score * 1.2)
        
        if insights and insights.get('viral_content_characteristics'):
            viral_patterns = insights['viral_content_characteristics']
            return f"""
- Viral Score: {viral_score:.1f}/100 (Enhanced by user's viral patterns)
- Success Factors: {', '.join(viral_patterns.get('success_factors', ['humor', 'timing', 'relevance']))}
- Engagement Multiplier: {viral_patterns.get('engagement_boost', 1.5)}x
- Community Response: {viral_patterns.get('community_response', 'Positive')}/"""
        else:
            return f"""
- Viral Score: {viral_score:.1f}/100 (ML baseline prediction)
- Success Factors: Meme format, crypto relevance, community humor
- Engagement Multiplier: 1.2x (estimated)
- Community Response: Expected positive (based on campaign type)"""

    def _get_personalization_recommendations(self, insights: Dict[str, Any]) -> str:
        """Get personalized recommendations based on user data"""
        if insights and insights.get('total_tweets_analyzed', 0) > 0:
            return f"""
- Voice: Maintain your {insights['user_writing_style'].get('tone', 'authentic')} voice
- Content Mix: Balance {insights['content_patterns'].get('humor_ratio', 70)}% humor with information
- Audience: Target your {insights['audience_demographics'].get('primary_segment', 'crypto community')}
- Interaction: {insights['audience_demographics'].get('interaction_style', 'Direct engagement')} style"""
        else:
            return """
- Voice: Authentic and community-focused
- Content Mix: 70% entertainment, 30% information
- Audience: Crypto/meme community
- Interaction: Direct and engaging communication"""

class EngagementPredictionTool(BaseTool):
    name: str = "engagement_prediction"
    description: str = "Predict engagement metrics using historical patterns"
    predictor: Any = None
    
    def __init__(self, predictor: 'MindsharePredictor'):
        super().__init__()
        self.predictor = predictor
    
    def _run(self, content_type: str) -> str:
        """Predict engagement based on content type and historical data"""
        try:
            # Base engagement predictions
            base_metrics = {
                'meme': {'likes': '850-1200', 'retweets': '120-180', 'comments': '45-70'},
                'educational': {'likes': '420-650', 'retweets': '65-95', 'comments': '25-40'},
                'promotional': {'likes': '320-480', 'retweets': '35-55', 'comments': '15-25'},
                'technical': {'likes': '280-420', 'retweets': '40-65', 'comments': '30-50'}
            }
            
            metrics = base_metrics.get(content_type, base_metrics['educational'])
            
            return f"""
üìà ENGAGEMENT PREDICTIONS:

Content Type: {content_type.title()}
Expected Performance:
- Likes: {metrics['likes']}
- Retweets: {metrics['retweets']}
- Comments: {metrics['comments']}

Confidence Level: 85%
Optimal Posting Time: Peak hours (12-2 PM, 7-9 PM UTC)
"""
        except Exception as e:
            return f"Error in engagement prediction: {str(e)}"

# LLM-based Content Extraction Tool for Content Orchestrator
class ContentExtractionInput(BaseModel):
    """Input schema for content extraction tool"""
    agent_outputs: str = Field(..., description="All previous agent outputs combined as text")
    campaign_context: str = Field(..., description="Campaign context and requirements")
    extraction_prompt: str = Field(default="", description="Optional custom extraction prompt (if empty, uses default)")

class LLMContentExtractionTool(BaseTool):
    """LLM-based tool for intelligently extracting and combining content from previous agents"""
    name: str = "content_extraction_tool"
    description: str = "Extract text content and image URLs from previous agent outputs using LLM reasoning with dynamic prompts"
    args_schema: Type[BaseModel] = ContentExtractionInput
    
    # Declare Pydantic fields properly
    user_text_provider: str = Field(default="openai")
    user_api_key: Optional[str] = Field(default=None)
    user_text_model: str = Field(default="gpt-4o")
    
    def __init__(self, user_text_provider: str = "openai", user_api_key: str = None, user_text_model: str = "gpt-4o", **kwargs):
        super().__init__(
            user_text_provider=user_text_provider,
            user_api_key=user_api_key,
            user_text_model=user_text_model,
            **kwargs
        )
        logger.info(f"üß† LLM Content Extraction Tool initialized with provider: {user_text_provider}, model: {user_text_model}")
    
    def _run(self, agent_outputs: str, campaign_context: str, extraction_prompt: str = "") -> str:
        """Use LLM to intelligently extract and combine content with dynamic prompts"""
        try:
            # Check if we have the required API key
            if not self.user_api_key:
                logger.warning(f"‚ö†Ô∏è No API key for {self.user_text_provider}, falling back to regex extraction")
                return self._fallback_regex_extraction(agent_outputs)
            
            # Initialize LLM for content extraction
            unified_generator = UnifiedContentGenerator()
            
            # Use custom prompt if provided, otherwise use default
            if extraction_prompt.strip():
                final_prompt = f"""
{extraction_prompt}

CAMPAIGN CONTEXT:
{campaign_context}

AGENT OUTPUTS TO ANALYZE:
{agent_outputs}
"""
                logger.info(f"üéØ Using custom extraction prompt for {self.user_text_provider}")
            else:
                # Default extraction prompt - designed for new JSON agent outputs
                final_prompt = f"""
You are a content extraction specialist. Your job is to extract clean, final content from AI agent JSON outputs.

CAMPAIGN CONTEXT:
{campaign_context}

AGENT OUTPUTS TO ANALYZE:
{agent_outputs}

YOUR TASK:
Extract the final tweet text, tweet thread, and image URL from these JSON agent outputs.

NEW AGENT OUTPUT FORMATS TO EXPECT:

1. TEXT CONTENT CREATOR OUTPUT (JSON):
{{
  "main_tweet": "üöÄ BOB is revolutionizing crypto gains! You can join...",
  "thread_array": ["With BOB, you get...", "Thousands of users...", "You can maximize..."],
  "hashtags_used": ["BOB", "DeFi", "Crypto"],
  "character_counts": {{"main_tweet_text": 245, "main_tweet_hashtags": 28}},
  "approach": "engaging"
}}

2. VISUAL CONTENT CREATOR OUTPUT (JSON):
{{
  "content_type": "IMAGE",
  "image_url": "https://burnie-mindshare-content-staging.s3.amazonaws.com/...",
  "video_url": null,
  "visual_concept": null,
  "provider_used": "Fal.ai",
  "model_used": "imagen4-preview",
  "dimensions": "1024x576px",
  "file_format": "JPEG"
}}

EXTRACTION RULES:
1. FIND TEXT CONTENT CREATOR JSON:
   - Look for JSON with "main_tweet" field
   - Extract the "main_tweet" value for Tweet Text
   - Extract the "thread_array" value for Tweet Thread
   - Handle both pure JSON and JSON within agent output text

2. FIND VISUAL CONTENT CREATOR JSON:
   - Look for JSON with "image_url" or "video_url" field
   - Extract the non-null URL value for Image/Video URL
   - Handle both pure JSON and JSON within agent output text

3. HANDLE LEGACY FORMATS (FALLBACK):
   - Text patterns like "üì∏ Image URL: https://..."
   - Approach-based structures with "engaging_approach"
   - Any other structured content

REQUIRED OUTPUT FORMAT (EXACT):
```
Tweet Text: [clean tweet text only - no quotes, brackets, or metadata]

Tweet Thread: [if thread available, array format: ["tweet 1", "tweet 2", "tweet 3"] - or "No thread generated"]

Image URL: [complete S3 URL with all parameters - or "No image generated"]
```

CRITICAL REQUIREMENTS:
- Return ONLY the extracted content in the exact format above
- Parse JSON fields directly when available
- Clean the tweet text of any technical artifacts
- Extract thread_array as JSON array format
- Include complete URLs with all AWS parameters
- If JSON parsing fails, use regex fallback patterns
- Do not add explanations, analysis, or commentary
- Prioritize JSON field extraction over regex patterns
"""
                logger.info(f"üß† Using default extraction prompt for {self.user_text_provider}")

            # Use user's configured text provider and API key
            try:
                # Create new event loop for async operation
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                result = loop.run_until_complete(
                    unified_generator.generate_content(
                        provider=self.user_text_provider,  # Use user's chosen provider
                        content_type="text",
                        prompt=final_prompt,
                        model=self.user_text_model,  # Use user's chosen model
                        max_tokens=500,
                        temperature=0.1,  # Low temperature for consistent extraction
                        user_api_key=self.user_api_key  # Use user's API key
                    )
                )
                
                loop.close()
                
                if result and result.success:
                    extracted_content = result.content.strip()
                    logger.info(f"üß† LLM Content Extraction ({self.user_text_provider}): {extracted_content[:100]}...")
                    return extracted_content
                else:
                    logger.warning(f"‚ö†Ô∏è LLM extraction failed: {result.error if result else 'No result'}")
                    return self._fallback_regex_extraction(agent_outputs)
                
            except Exception as async_error:
                logger.error(f"‚ùå Async LLM extraction failed: {async_error}")
                # Fallback to regex extraction if LLM fails
                return self._fallback_regex_extraction(agent_outputs)
            
        except Exception as e:
            logger.error(f"‚ùå LLM content extraction error: {e}")
            return f"Content extraction failed: {str(e)}"
    
    def _fallback_regex_extraction(self, agent_outputs: str) -> str:
        """Fallback regex-based content extraction if LLM fails"""
        try:
            logger.info("üîÑ Using fallback regex extraction method")
            
            # Extract tweet text and thread from JSON format (Text Content Creator output)
            tweet_text = "Generated content from AI agents"
            tweet_thread = None
            
            # Pattern 1: Look for new direct JSON format with main_tweet/thread_array
            import json
            try:
                # Try to find and parse JSON objects in the output
                json_objects = re.findall(r'\{[^{}]*"main_tweet"[^{}]*\}', agent_outputs, re.DOTALL)
                for json_str in json_objects:
                    try:
                        json_obj = json.loads(json_str)
                        if 'main_tweet' in json_obj:
                            tweet_text = json_obj['main_tweet']
                            logger.info(f"‚úÖ Found main_tweet in new JSON format: {tweet_text[:50]}...")
                            
                            if 'thread_array' in json_obj and json_obj['thread_array']:
                                tweet_thread = json_obj['thread_array']
                                logger.info(f"‚úÖ Found thread_array in new JSON format: {len(tweet_thread)} tweets")
                            break
                    except json.JSONDecodeError:
                        continue
            except Exception as e:
                logger.debug(f"New JSON parsing failed: {e}")
            
            # Pattern 2: Look for legacy approach-based JSON format (fallback)
            if tweet_text == "Generated content from AI agents":
                approach_patterns = ['engaging_approach', 'bold_approach', 'conservative_approach']
                for approach in approach_patterns:
                    # Look for main_tweet in this approach
                    main_tweet_match = re.search(rf'"{approach}":\s*{{[^}}]*"main_tweet":\s*"([^"]+)"', agent_outputs, re.DOTALL)
                    if main_tweet_match:
                        tweet_text = main_tweet_match.group(1)
                        logger.info(f"‚úÖ Found main_tweet in {approach}: {tweet_text[:50]}...")
                        
                        # Look for thread_array in the same approach
                        thread_match = re.search(rf'"{approach}":\s*{{[^}}]*"thread_array":\s*\[([^\]]+)\]', agent_outputs, re.DOTALL)
                        if thread_match:
                            thread_content = thread_match.group(1)
                            # Parse the array elements
                            try:
                                thread_items = json.loads(f'[{thread_content}]')
                                tweet_thread = thread_items
                                logger.info(f"‚úÖ Found thread_array in {approach}: {len(tweet_thread)} tweets")
                            except json.JSONDecodeError:
                                # Fallback: split by quotes if JSON parsing fails
                                thread_items = re.findall(r'"([^"]+)"', thread_content)
                                if thread_items:
                                    tweet_thread = thread_items
                                    logger.info(f"‚úÖ Found thread_array (regex) in {approach}: {len(tweet_thread)} tweets")
                        break
            
            # Pattern 3: Look for legacy JSON with content_variations (fallback)
            if tweet_text == "Generated content from AI agents":
                json_match = re.search(r'"content_variations":\s*\[(.*?)\]', agent_outputs, re.DOTALL)
                if json_match:
                    variations_content = json_match.group(1)
                    
                    # Try to find "Engaging" approach first
                    engaging_match = re.search(r'"approach":\s*"Engaging".*?"content":\s*"([^"]+)"', variations_content, re.DOTALL)
                    if engaging_match:
                        tweet_text = engaging_match.group(1)
                    else:
                        # Try "Bold" approach
                        bold_match = re.search(r'"approach":\s*"Bold".*?"content":\s*"([^"]+)"', variations_content, re.DOTALL)
                        if bold_match:
                            tweet_text = bold_match.group(1)
                        else:
                            # Try "Conservative" approach
                            conservative_match = re.search(r'"approach":\s*"Conservative".*?"content":\s*"([^"]+)"', variations_content, re.DOTALL)
                            if conservative_match:
                                tweet_text = conservative_match.group(1)
            
            # Pattern 4: Fallback tweet patterns if JSON extraction fails
            if tweet_text == "Generated content from AI agents":
                # Try to find "Tweet Text:" format from LLM extraction tool
                tweet_text_match = re.search(r'Tweet Text:\s*(.+?)(?=\n\nImage URL:|$)', agent_outputs, re.DOTALL | re.IGNORECASE)
                if tweet_text_match:
                    # Join lines and clean up
                    tweet_text = ' '.join(tweet_text_match.group(1).strip().split('\n')).strip()
                else:
                    # Original fallback patterns
                    tweet_patterns = [
                        r'"content":\s*"([^"]+)"',
                        r'Tweet.*?:\s*([^\n]+)',
                        r'Content.*?:\s*([^\n]+)'
                    ]
                    
                    for pattern in tweet_patterns:
                        match = re.search(pattern, agent_outputs, re.IGNORECASE)
                        if match:
                            tweet_text = match.group(1).strip()
                            break
            
            # Extract image URL from Visual Content Creator output
            image_url = None
            
            # Pattern 1: Look for new JSON format with image_url field
            try:
                json_objects = re.findall(r'\{[^{}]*"image_url"[^{}]*\}', agent_outputs, re.DOTALL)
                for json_str in json_objects:
                    try:
                        json_obj = json.loads(json_str)
                        if 'image_url' in json_obj and json_obj['image_url']:
                            image_url = json_obj['image_url']
                            logger.info(f"‚úÖ Found image_url in new JSON format: {image_url[:50]}...")
                            break
                    except json.JSONDecodeError:
                        continue
                        
                # Also check for video_url if no image_url found
                if not image_url:
                    json_objects = re.findall(r'\{[^{}]*"video_url"[^{}]*\}', agent_outputs, re.DOTALL)
                    for json_str in json_objects:
                        try:
                            json_obj = json.loads(json_str)
                            if 'video_url' in json_obj and json_obj['video_url']:
                                image_url = json_obj['video_url']
                                logger.info(f"‚úÖ Found video_url in new JSON format: {image_url[:50]}...")
                                break
                        except json.JSONDecodeError:
                            continue
            except Exception as e:
                logger.debug(f"New JSON image URL parsing failed: {e}")
            
            # Pattern 2: Fallback to legacy URL patterns
            if not image_url:
                url_patterns = [
                    # S3 URLs with all query parameters
                    r'üì∏ Image URL:\s*([^\s\[\]]+\.amazonaws\.com[^\s\[\]]*)',
                    r'Image URL:\s*([^\s\[\]]+\.amazonaws\.com[^\s\[\]]*)',
                    r'https://burnie-mindshare-content[^\s\[\]]*\.amazonaws\.com[^\s\[\]]*',
                    r'https://[^\s\[\]]+\.amazonaws\.com[^\s\[\]]*ai-generated[^\s\[\]]*',
                    # Other URL patterns
                    r'https://[^\s\[\]]+\.(?:jpg|jpeg|png|gif|webp)(?:\?[^\s\[\]]*)?',
                    r'https://oaidalleapiprodscus\.blob\.core\.windows\.net[^\s\[\]]*'
                ]
                
                for pattern in url_patterns:
                    match = re.search(pattern, agent_outputs, re.IGNORECASE)
                    if match:
                        if 'üì∏ Image URL:' in pattern or 'Image URL:' in pattern:
                            image_url = match.group(1).strip().strip('[]")')
                        else:
                            image_url = match.group(0).strip().strip('[]")')
                        logger.info(f"‚úÖ Found image URL using regex pattern: {image_url[:50]}...")
                        break
            
            # Format output
            result = f"Tweet Text: {tweet_text}\n\n"
            
            # Add tweet thread if available
            if tweet_thread and len(tweet_thread) > 0:
                import json
                result += f"Tweet Thread: {json.dumps(tweet_thread)}\n\n"
            else:
                result += "Tweet Thread: No thread generated\n\n"
            
            if image_url:
                result += f"Image URL: {image_url}"
            else:
                result += "Image URL: No image generated"
            
            logger.info(f"üîÑ Fallback extraction result: {result}")
            return result
            
        except Exception as fallback_error:
            logger.error(f"‚ùå Fallback extraction failed: {fallback_error}")
            return "Tweet Text: Content extraction failed\n\nImage URL: No content available"

# Real LLM Provider Tools with User Configuration
class OpenAIContentTool(BaseTool):
    name: str = "openai_content_generation"
    description: str = "Generate high-quality text content, images, and analyze visuals using OpenAI models ONLY (gpt-4o, gpt-image-1, dall-e-3, dall-e-2). Do NOT use for fal.ai models."
    api_key: Optional[str] = None
    model_preferences: Dict[str, Any] = {}
    generator: Any = None
    wallet_address: Optional[str] = None
    agent_id: Optional[str] = None
    
    def __init__(self, api_key: str = None, model_preferences: Dict[str, Any] = None, 
                 wallet_address: str = None, agent_id: str = None):
        super().__init__()
        self.api_key = api_key
        self.model_preferences = model_preferences or {}
        self.wallet_address = wallet_address
        self.agent_id = agent_id
        
        # Debug: Log the model preferences received by this tool
        logger.info(f"üõ†Ô∏è OpenAIContentTool initialized with model preferences: {json.dumps(self.model_preferences, indent=2)}")
        logger.info(f"üè∑Ô∏è S3 Organization: wallet_address={wallet_address}, agent_id={agent_id}")
        
        # Import OpenAI generator with user's API key
        try:
            from app.ai.openai_content_generation import OpenAIContentGenerator
            self.generator = OpenAIContentGenerator(api_key=api_key) if api_key else None
        except Exception as e:
            logger.warning(f"OpenAI generator not available: {e}")
            self.generator = None
    
    def _run(self, prompt: str) -> str:
        """
        Generate content using OpenAI models ONLY. 
        
        Args:
            prompt: The content generation prompt. Should specify content type.
                   Examples:
                   - "create image: A modern tech startup office"
                   - "generate text: Write a Twitter post about Web3"
        
        Returns:
            Generated content or error message
        """
        if not self.generator:
            return "‚ùå OpenAI API not available - please configure API key"
            
        try:
            # Parse the prompt to determine content type
            prompt_lower = prompt.lower()
            
            if "image" in prompt_lower and ("generate" in prompt_lower or "create" in prompt_lower):
                # Check if this is a fal.ai model that should be handled by FalAI tool
                preferred_model = self.model_preferences.get('image', {}).get('model', 'dall-e-3')
                
                # Debug: Log what model is being used for image generation
                logger.info(f"üé® OpenAI Image generation requested:")
                logger.info(f"   üìã Model preferences: {self.model_preferences}")
                logger.info(f"   üéØ Preferred image model: {preferred_model}")
                logger.info(f"   üìù Prompt: {prompt[:100]}...")
                
                # Check if user explicitly chose a different provider for this model
                user_provider = self.model_preferences.get('image', {}).get('provider', 'openai')
                logger.info(f"üîç OpenAI tool processing model: {preferred_model}, user's provider choice: {user_provider}")
                
                # If user chose fal.ai as provider, delegate to fal tool
                if user_provider in ['fal', 'fal.ai']:
                    logger.info(f"üîÑ User chose {user_provider} provider - delegating to fal_content_generation tool")
                    return f"‚ùå You chose '{user_provider}' as your provider for this model. Please use the fal_content_generation tool instead."
                
                # Only handle models when user explicitly chose OpenAI as provider
                if user_provider != 'openai':
                    logger.info(f"üîÑ User chose {user_provider} provider - not OpenAI")
                    return f"‚ùå You chose '{user_provider}' as your provider. Please use the appropriate tool for {user_provider}."
                
                # Map various model names to OpenAI equivalents
                openai_model_map = {
                    'gpt-image-1': 'dall-e-3',  # Map gpt-image-1 to dall-e-3 for OpenAI
                    'gpt-4o': 'gpt-4o',
                    'gpt-4o-mini': 'gpt-4o-mini', 
                    'dall-e-3': 'dall-e-3',
                    'dall-e-2': 'dall-e-2'
                }
                
                # Use OpenAI equivalent if available, otherwise default to dall-e-3
                actual_model = openai_model_map.get(preferred_model, 'dall-e-3')
                if actual_model != preferred_model:
                    logger.info(f"üîÑ Mapping {preferred_model} to OpenAI model: {actual_model}")
                
                preferred_model = actual_model
                
                # Extract brand configuration if available in prompt
                brand_config = None
                if "logo" in prompt_lower or "brand" in prompt_lower:
                    logger.info(f"üè∑Ô∏è Branding requested for image generation with {preferred_model}")
                
                # Try user's preferred OpenAI model first, then fallbacks
                fallback_models = ['dall-e-3', 'dall-e-2']  # Safe OpenAI fallbacks only
                models_to_try = [preferred_model] + [m for m in fallback_models if m != preferred_model]
                
                # Enhance the prompt with modern design aesthetics and campaign alignment
                enhanced_prompt = prompt
                if "create image" in prompt_lower:
                    # Determine Web2 vs Web3 styling based on campaign context
                    campaign_title = self.campaign_data.get('title', '').lower() if self.campaign_data else ''
                    campaign_type = self.campaign_data.get('type', '').lower() if self.campaign_data else ''
                    
                    # Detect Web3/Crypto keywords
                    web3_keywords = ['web3', 'crypto', 'blockchain', 'defi', 'nft', 'dao', 'metaverse', 'token', 'smart contract', 'ethereum', 'bitcoin', 'wallet', 'staking']
                    is_web3_campaign = any(keyword in campaign_title or keyword in campaign_type for keyword in web3_keywords)
                    
                    # Create style-specific enhancements
                    if is_web3_campaign:
                        style_enhancement = """
ADVANCED WEB3 AESTHETIC REQUIREMENTS:
- Holographic glass morphism effects with subtle transparency (15-25% opacity)
- Neon purple, cyan, and electric blue gradient overlays with glow effects
- Futuristic UI elements with rounded corners and soft shadows
- Digital particle effects and subtle hexagonal patterns in background
- Chrome/metallic text with rainbow holographic reflections
- Dark themed background (navy, deep purple, or midnight blue gradients)
- Floating glass panels with blur effects and subtle borders
- Modern sans-serif typography with tech-inspired letter spacing
- Cryptocurrency symbols or blockchain visual metaphors where appropriate
- High-tech atmosphere with clean, minimalist but rich visual depth

WEB3 CHARACTER REQUIREMENTS:
- PREFER animated/cartoon characters over real humans (Web3 community preference)
- Use imaginative hypothetical characters: cyber-punk avatars, digital beings, holographic personas
- Mix of animated characters with occasional stylized humans
- Characters should have futuristic, tech-savvy appearance
- Include NFT-style character aesthetics (unique traits, digital accessories)
- Anthropomorphic crypto mascots or blockchain-inspired creatures
- Cyberpunk-style avatars with neon accents and digital elements

CRITICAL TEXT ACCURACY REQUIREMENTS:
- ALL TEXT must use REAL ENGLISH DICTIONARY WORDS ONLY
- NO gibberish, made-up words, or nonsensical letter combinations
- Verify all text is spelled correctly and uses proper English vocabulary
- Any displayed text should be meaningful and readable
- Avoid abstract letter arrangements that don't form real words"""
                    else:
                        style_enhancement = """
MODERN GENZ AESTHETIC REQUIREMENTS:
- Soft glass morphism effects with frosted glass appearance (20-30% opacity)
- Vibrant gradient backgrounds (sunset, ocean, or aurora-inspired palettes)
- Rounded glass cards and panels with subtle drop shadows
- Contemporary flat design mixed with depth through glass effects
- Clean, modern typography with good contrast and readability
- Bright, engaging colors suitable for social media (coral, mint, lavender, gold)
- Minimalist composition with strategic negative space
- Instagram/TikTok-ready aesthetic with high visual appeal
- Subtle texture overlays for added visual interest
- Professional yet trendy atmosphere perfect for content creation

GENZ CHARACTER REQUIREMENTS:
- Balance of animated characters and stylized diverse humans
- Use creative, imaginative personas: digital influencers, content creators, entrepreneurs
- Characters with modern, trendy appearance and positive energy
- Include diverse representation and inclusive character designs
- Social media-savvy characters with contemporary styling
- Mix of realistic and stylized illustration approaches

CRITICAL TEXT ACCURACY REQUIREMENTS:
- ALL TEXT must use REAL ENGLISH DICTIONARY WORDS ONLY
- NO gibberish, made-up words, or nonsensical letter combinations
- Verify all text is spelled correctly and uses proper English vocabulary
- Any displayed text should be meaningful and readable
- Avoid abstract letter arrangements that don't form real words"""

                    enhanced_prompt = f"""{prompt}

{style_enhancement}

CRITICAL TEXT VISIBILITY REQUIREMENTS:
- Ensure ALL text is completely visible and not cut off at any edges
- Leave minimum 80px margins around all text elements  
- Position title text in center or upper-center with full visibility
- Use clear, bold typography readable on mobile devices
- Apply subtle text shadows or glow effects for better readability on glass elements
- Avoid placing important text near image boundaries
- Use 1792x1024 wide format canvas for optimal text placement
- Ensure entire text content fits within canvas dimensions
- Test text placement to prevent cropping issues
- Text should be legible against glass morphism backgrounds

GENZ ENGAGEMENT OPTIMIZATION:
- High visual impact suitable for TikTok, Instagram, and Twitter
- Color psychology aligned with target demographic preferences
- Modern aesthetic that feels current and shareable
- Professional quality that builds credibility and trust
- Visual hierarchy that guides attention to key messaging"""
                
                result = None
                last_error = None
                
                for attempt, model in enumerate(models_to_try):
                    try:
                        logger.info(f"üîÑ Attempt {attempt + 1}: Trying image generation with {model}")
                        
                        # Use unified content generator with S3 storage integration
                        from app.services.llm_content_generators import unified_generator
                        import asyncio
                        
                        # OpenAI tool only handles OpenAI provider
                        provider = "openai"
                        
                        # Call unified generator with S3 integration (use asyncio.run for sync context)
                        try:
                            # Debug: Log what we're passing to S3
                            logger.info(f"üîç DEBUG: OpenAI tool calling S3 with wallet_address: {self.wallet_address}, agent_id: {self.agent_id}")
                            
                            # Create a new event loop for the sync context
                            loop = asyncio.new_event_loop()
                            asyncio.set_event_loop(loop)
                            try:
                                # Get the user's API key for the determined provider
                                user_api_key = self.api_key  # Use the API key passed to this tool instance
                                if not user_api_key:
                                    raise ValueError(f"No API key provided for {provider} provider")
                                
                                content_result = loop.run_until_complete(unified_generator.generate_content(
                                    provider=provider,
                                    content_type="image",
                                    prompt=enhanced_prompt,  # Use enhanced prompt with text visibility requirements
                                    model=model,
                                    size='1792x1024',  # Wider format for better text visibility
                                    quality='hd',
                                    style='vivid',
                                    user_api_key=user_api_key,  # Pass user's API key
                                    wallet_address=self.wallet_address,
                                    agent_id=self.agent_id,
                                    use_s3_storage=True
                                ))
                            finally:
                                loop.close()
                        except Exception as async_error:
                            logger.error(f"‚ùå Async error: {async_error}")
                            return f"‚ùå Error: {str(async_error)}"
                        
                        # Convert result format for compatibility
                        if content_result.success:
                            result = {
                                'success': True,
                                'url': content_result.content,  # This is the final URL (S3 or original)
                                'model': content_result.metadata.get('model', model),
                                'enhanced_prompt': content_result.metadata.get('revised_prompt', prompt),
                                'size': content_result.metadata.get('size', 'N/A'),
                                'quality': content_result.metadata.get('quality', 'hd'),
                                'style': content_result.metadata.get('style', 'vivid'),
                                's3_storage': content_result.metadata.get('s3_storage')
                            }
                        else:
                            result = {
                                'success': False,
                                'error': content_result.error
                            }
                        
                        if result['success']:
                            logger.info(f"‚úÖ Image generation succeeded with {model}")
                            # Add fallback info if not the preferred model
                            if model != preferred_model:
                                result['fallback_used'] = True
                                result['original_model'] = preferred_model
                                result['fallback_model'] = model
                            break
                        else:
                            logger.warning(f"‚ö†Ô∏è Image generation failed with {model}: {result.get('error')}")
                            last_error = result.get('error')
                            
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Exception with {model}: {str(e)}")
                        last_error = str(e)
                        continue
                
                # Handle results
                if result and result['success']:
                    # Successfully generated image
                    model_display = result.get('model', models_to_try[0])
                    image_url = result.get('url', '')
                    image_base64 = result.get('image_base64', '')
                    
                    # Handle both URL and base64 responses
                    image_info = ""
                    if image_url:
                        if image_url.startswith('data:image'):
                            image_info = f"üì∏ Image Data: Base64 encoded (ready for download)\n"
                        else:
                            image_info = f"üì∏ Image URL: {image_url}\n"
                    elif image_base64:
                        image_info = f"üì∏ Image Data: Base64 encoded ({len(image_base64)} chars)\n"
                    
                    brand_info = ""
                    if result.get('brand_applied'):
                        brand_info = f"üè∑Ô∏è Brand Integration: Applied successfully\n"
                    elif result.get('brand_warning'):
                        brand_info = f"‚ö†Ô∏è Brand Warning: {result['brand_warning']}\n"
                    
                    fallback_info = ""
                    if result.get('fallback_used'):
                        fallback_info = f"üîÑ Fallback: {result['original_model']} ‚Üí {result['fallback_model']}\n"
                    
                    return f"""
üé® IMAGE GENERATED:
‚úÖ Successfully created image using {model_display.upper()}
{image_info}üí° Enhanced Prompt: {result.get('enhanced_prompt', result.get('revised_prompt', 'N/A'))}
üìê Size: {result.get('size', 'N/A')}
‚≠ê Quality: {result.get('quality', 'N/A')}
{fallback_info}{brand_info}{f"üîÑ Note: {result['note']}" if result.get('note') else ""}

TWITTER IMPLEMENTATION:
- Download and attach this image to your tweet
- Use as primary visual content
- Optimized for social media engagement
- {f"Brand elements integrated professionally" if result.get('brand_applied') else "Ready for brand overlay if needed"}
"""
                else:
                    # All models failed - return skip instruction
                    logger.error(f"‚ùå All image generation models failed. Last error: {last_error}")
                    return f"""
‚ùå IMAGE GENERATION UNAVAILABLE:
All image models failed ({', '.join(models_to_try)})
Last error: {last_error}

CONTENT SKIP INSTRUCTION:
- Skip visual content for this tweet
- Focus on text-only Twitter content
- Consider alternative content strategy
"""
            
            elif "analyze image" in prompt_lower or "describe image" in prompt_lower:
                return """
üìã IMAGE ANALYSIS TOOL READY:
To analyze an image, use: generator.analyze_image_and_generate_text(image_path, prompt)
Supports: JPEG, PNG, GIF, WebP formats
Use cases: Image descriptions, alt text, content inspiration
"""
            
            else:
                # Text content generation with fallback support
                preferred_model = self.model_preferences.get('text', {}).get('model', 'gpt-4o')
                
                # Try user's preferred model first, then fallbacks
                fallback_models = ['gpt-4o', 'gpt-4o-mini']  # Safe fallbacks for text
                models_to_try = [preferred_model] + [m for m in fallback_models if m != preferred_model]
                
                system_prompt = """You are a human Twitter content creator who writes highly engaging, story-driven content for Web3 audiences:

CONTEXT FUSION MASTERY:
- INTELLIGENTLY WEAVE all available context (Twitter data, project info, community insights) into natural storytelling
- EXTRACT actionable insights from recent tweets: launches, airdrops, partnerships, community buzz
- TRANSFORM raw data into compelling narratives that feel like insider alpha sharing
- SYNTHESIZE multiple sources to create unique perspectives that aren't just rehashing

ENGAGING STORYTELLING STYLE:
- Write like you're sharing exciting news with a friend who loves crypto
- Use storytelling techniques: set up intrigue, reveal key details, create anticipation
- Make readers feel like they're discovering something special
- Create "wow moments" and emotional hooks that make people want to learn more
- Use conversational flow that draws readers deeper into the story
- Build excitement about projects without sounding like corporate marketing

TWITTER CONTEXT INTEGRATION:
- PRIORITIZE recent Twitter activity as your primary source of current events
- Extract community sentiment, trending topics, and project momentum from tweets
- Reference specific developments naturally (don't just quote tweets verbatim)
- Build on existing community conversations and energy
- Use Twitter data to create timely, relevant content that feels current

READER ENGAGEMENT TECHNIQUES:
- Start with attention-grabbing hooks that stop scrolling
- Use curiosity gaps: hint at benefits before revealing details
- Ask rhetorical questions that get readers thinking
- Share insights as if you're an insider sharing alpha
- Create FOMO through genuine value, not artificial urgency
- End with clear value propositions that make readers want to visit the project

PROJECT REFERENCE RULES (CRITICAL):
- NEVER use "our", "we", "us" when referring to projects
- Always use third person: "they", "them", "their", "[project name]"
- You are NOT part of the project team - you're an informed observer
- Example: "They just launched..." not "We just launched..."
- Example: "Their new bridge..." not "Our new bridge..."
- Example: "BOB's latest update..." not "Our latest update..."

CHARACTER LIMITS:
- Main tweet: Maximum 240 characters (strict limit)
- Each thread tweet: Maximum 240 characters (strict limit)
- Leave room for natural hashtags and handles

CONTENT GUIDELINES:
- Sound authentic and conversational, not AI-generated
- Use emojis sparingly - only when they feel natural
- Address readers directly as "you" to create connection
- Create genuine excitement about project developments
- Focus on value and impact that will drive website visits

Create content that makes readers genuinely excited to learn more about the project and visit their website."""
                
                result_text = None
                last_error = None
                successful_model = None
                
                for attempt, model in enumerate(models_to_try):
                    try:
                        logger.info(f"üîÑ Text attempt {attempt + 1}: Trying with {model}")
                        
                        result_text = self.generator.generate_text(
                            prompt=prompt,
                            model=model,
                            max_tokens=800,  # Increased from 300 to prevent truncation
                            temperature=0.8,
                            system_prompt=system_prompt
                        )
                        
                        # Check if we got a valid response (not an error message)
                        if result_text and not result_text.startswith("Error generating text:"):
                            logger.info(f"‚úÖ Text generation succeeded with {model}")
                            successful_model = model
                            break
                        else:
                            logger.warning(f"‚ö†Ô∏è Text generation failed with {model}: {result_text}")
                            last_error = result_text
                            
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Exception with text model {model}: {str(e)}")
                        last_error = str(e)
                        continue
                
                # Handle text generation results
                if result_text and successful_model:
                    fallback_info = ""
                    if successful_model != preferred_model:
                        fallback_info = f"üîÑ Text Fallback: {preferred_model} ‚Üí {successful_model}\n"
                    
                    return f"""
üê¶ TWITTER-OPTIMIZED CONTENT:

{result_text}

‚úÖ Character Count: ~{len(result_text)} chars
üéØ Engagement Elements: ‚úì Hook ‚úì Value ‚úì CTA
üì± Mobile-friendly formatting
üî• Viral potential: HIGH
{fallback_info}ü§ñ Generated by: {successful_model.upper()}
"""
                else:
                    # All text models failed - this is critical
                    logger.error(f"‚ùå All text generation models failed. Last error: {last_error}")
                    return f"""
‚ùå TEXT GENERATION UNAVAILABLE:
All text models failed ({', '.join(models_to_try)})
Last error: {last_error}

CRITICAL ERROR: Cannot proceed without text content
"""
                
        except Exception as e:
            return f"‚ùå OpenAI content generation error: {str(e)}"

class GeminiContentTool(BaseTool):
    name: str = "gemini_content_generation"
    description: str = "Generate creative content and videos using Google Gemini and Veo models"
    api_key: Optional[str] = None
    model_preferences: Dict[str, Any] = {}
    generator: Any = None
    wallet_address: Optional[str] = None
    agent_id: Optional[str] = None
    
    def __init__(self, api_key: str = None, model_preferences: Dict[str, Any] = None,
                 wallet_address: str = None, agent_id: str = None):
        super().__init__()
        self.api_key = api_key
        self.model_preferences = model_preferences or {}
        self.wallet_address = wallet_address
        self.agent_id = agent_id
        
        # Import Gemini generator with user's API key
        try:
            from app.ai.gemini_content_generation import GeminiContentGenerator
            self.generator = GeminiContentGenerator(api_key=api_key) if api_key else None
        except Exception as e:
            logger.warning(f"Gemini generator not available: {e}")
            self.generator = None
    
    def _run(self, prompt: str) -> str:
        """Generate content using Gemini models with user's preferences"""
        if not self.generator:
            return "Gemini API not available - please configure API key"
            
        try:
            prompt_lower = prompt.lower()
            
            if "video" in prompt_lower and ("generate" in prompt_lower or "create" in prompt_lower):
                # Video generation with fallback support
                preferred_model = self.model_preferences.get('video', {}).get('model', 'veo-3')
                
                # Try user's preferred model first, then fallback (limited video model options)
                fallback_models = ['veo-3']  # Limited fallback options for video
                models_to_try = [preferred_model] + [m for m in fallback_models if m != preferred_model]
                
                result = None
                last_error = None
                successful_model = None
                
                for attempt, model in enumerate(models_to_try):
                    try:
                        logger.info(f"üîÑ Video attempt {attempt + 1}: Trying with {model}")
                        
                        result = self.generator.generate_video(
                            prompt=prompt,
                            duration=8,
                            resolution="720p"
                        )
                        
                        # Check if we got a valid response
                        if result and result.get('message') and not result.get('message').startswith('Error'):
                            logger.info(f"‚úÖ Video generation succeeded with {model}")
                            successful_model = model
                            break
                        else:
                            logger.warning(f"‚ö†Ô∏è Video generation failed with {model}: {result.get('message', 'Unknown error')}")
                            last_error = result.get('message', 'Unknown error')
                            
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Exception with video model {model}: {str(e)}")
                        last_error = str(e)
                        continue
                
                # Handle video generation results
                if result and successful_model:
                    fallback_info = ""
                    if successful_model != preferred_model:
                        fallback_info = f"üîÑ Video Fallback: {preferred_model} ‚Üí {successful_model}\n"
                    
                    return f"""
üé¨ VIDEO GENERATION:
{result['message']}
‚è±Ô∏è Duration: {result['duration']} seconds
üì∫ Resolution: {result['resolution']}
üé• Model: {successful_model.upper()} (High-fidelity with native audio)
{fallback_info}
TWITTER IMPLEMENTATION:
- Perfect for Twitter video posts (max 2:20)
- Native audio enhances engagement
- Optimized for mobile viewing
- Use compelling thumbnail frame

{result.get('response_text', '')}
"""
                else:
                    # Video generation failed - return skip instruction
                    logger.error(f"‚ùå Video generation models failed. Last error: {last_error}")
                    return f"""
‚ùå VIDEO GENERATION UNAVAILABLE:
Video models failed ({', '.join(models_to_try)})
Last error: {last_error}

CONTENT SKIP INSTRUCTION:
- Skip video content for this tweet
- Focus on text and image content
- Consider static visual alternatives
"""
            
            if "image" in prompt_lower and ("generate" in prompt_lower or "create" in prompt_lower):
                # Enhanced prompt with modern aesthetics and campaign alignment
                campaign_title = self.campaign_data.get('title', '').lower() if self.campaign_data else ''
                campaign_type = self.campaign_data.get('type', '').lower() if self.campaign_data else ''
                
                # Detect Web3/Crypto campaign context
                web3_keywords = ['web3', 'crypto', 'blockchain', 'defi', 'nft', 'dao', 'metaverse', 'token', 'smart contract', 'ethereum', 'bitcoin', 'wallet', 'staking']
                is_web3_campaign = any(keyword in campaign_title or keyword in campaign_type for keyword in web3_keywords)
                
                # Campaign-specific styling
                if is_web3_campaign:
                    aesthetic_style = """
ADVANCED WEB3 VISUAL AESTHETIC:
- Premium glass morphism with holographic effects and 15-25% transparency
- Neon gradients: electric blue, cyber purple, mint green with glow effects  
- Futuristic UI design with rounded glass panels and soft depth shadows
- Digital particle systems and subtle hexagonal background patterns
- Metallic chrome text with rainbow holographic reflections and tech spacing
- Dark gradient themes: navy to deep purple or midnight blue atmospheric depth
- Floating translucent panels with gaussian blur and subtle neon borders
- Cryptocurrency and blockchain visual metaphors integrated naturally
- High-tech minimalism with rich visual depth and professional finish

WEB3 CHARACTER REQUIREMENTS:
- PREFER animated/cartoon characters over real humans (Web3 community preference)
- Use imaginative hypothetical characters: cyber-punk avatars, digital beings, holographic personas
- Mix of animated characters with occasional stylized humans
- Characters should have futuristic, tech-savvy appearance
- Include NFT-style character aesthetics (unique traits, digital accessories)
- Anthropomorphic crypto mascots or blockchain-inspired creatures
- Cyberpunk-style avatars with neon accents and digital elements

CRITICAL TEXT ACCURACY REQUIREMENTS:
- ALL TEXT must use REAL ENGLISH DICTIONARY WORDS ONLY
- NO gibberish, made-up words, or nonsensical letter combinations
- Verify all text is spelled correctly and uses proper English vocabulary
- Any displayed text should be meaningful and readable
- Avoid abstract letter arrangements that don't form real words"""
                else:
                    aesthetic_style = """
MODERN GENZ SOCIAL AESTHETIC:
- Sophisticated glass morphism with frosted appearance and 20-30% opacity
- Vibrant social gradients: sunset coral, ocean turquoise, aurora pastels
- Contemporary rounded glass cards with strategic drop shadows and depth
- Clean flat design elevated with layered glass effects and visual hierarchy
- Fresh color palettes: coral pink, mint green, lavender purple, champagne gold
- Instagram/TikTok optimized with high engagement visual appeal
- Minimalist composition with purposeful negative space and breathing room
- Subtle texture overlays for enhanced visual interest and depth
- Professional content creator aesthetic that builds authority and trust

GENZ CHARACTER REQUIREMENTS:
- Balance of animated characters and stylized diverse humans
- Use creative, imaginative personas: digital influencers, content creators, entrepreneurs
- Characters with modern, trendy appearance and positive energy
- Include diverse representation and inclusive character designs
- Social media-savvy characters with contemporary styling
- Mix of realistic and stylized illustration approaches

CRITICAL TEXT ACCURACY REQUIREMENTS:
- ALL TEXT must use REAL ENGLISH DICTIONARY WORDS ONLY
- NO gibberish, made-up words, or nonsensical letter combinations
- Verify all text is spelled correctly and uses proper English vocabulary
- Any displayed text should be meaningful and readable
- Avoid abstract letter arrangements that don't form real words"""

                enhanced_prompt = f"""{prompt}

{aesthetic_style}

CRITICAL TEXT VISIBILITY REQUIREMENTS:
- Ensure ALL text is completely visible and not cut off at any edges
- Leave minimum 80px margins around all text elements  
- Position title text in center or upper-center with full visibility
- Use clear, bold typography readable on mobile devices
- Apply strategic text shadows or glow effects for glass background readability
- Avoid placing important text near image boundaries
- Use 1792x1024 wide format canvas for optimal text placement
- Ensure entire text content fits within canvas dimensions
- Test text placement to prevent cropping issues
- Maintain excellent text contrast against glass morphism elements

PLATFORM OPTIMIZATION:
- Twitter/X ready with high mobile readability
- TikTok/Instagram Stories compatible aesthetic
- LinkedIn professional yet engaging appearance
- Viral potential through modern design trends
- GenZ demographic appeal with contemporary visual language"""
                
                # Generate image concepts
                result = self.generator.generate_image(
                    prompt=enhanced_prompt,
                    style="vibrant, social media optimized",
                    quality="high"
                )
                
                return f"""
üñºÔ∏è IMAGE CONCEPT GENERATION:
{result['message']}

CREATIVE DIRECTION:
{result.get('response_text', '')}

TWITTER OPTIMIZATION:
- Design for 16:9 or 1:1 aspect ratio
- High contrast for mobile screens
- Bold, readable text overlays
- Brand-consistent color palette
ü§ñ Generated by: Gemini
"""
            
            else:
                # Generate creative text content
                result = self.generator.generate_text(
                    prompt=f"Create engaging Twitter content: {prompt}",
                    max_tokens=800,  # Increased from 280 to prevent truncation
                    temperature=0.9
                )
                
            return f"""
‚ú® CREATIVE TWITTER CONTENT:

{result}

üé® Style: Creative & engaging
üß† Generated by: Gemini 2.0 Flash
üöÄ Optimized for virality
üí¨ Perfect for community engagement
"""
                
        except Exception as e:
            return f"‚ùå Gemini content generation error: {str(e)}"

class ClaudeContentTool(BaseTool):
    name: str = "claude_content_generation"
    description: str = "Generate strategic, well-reasoned content using Claude's advanced reasoning capabilities"
    api_key: Optional[str] = None
    model_preferences: Dict[str, Any] = {}
    generator: Any = None
    wallet_address: Optional[str] = None
    agent_id: Optional[str] = None
    
    def __init__(self, api_key: str = None, model_preferences: Dict[str, Any] = None,
                 wallet_address: str = None, agent_id: str = None):
        super().__init__()
        self.api_key = api_key
        self.model_preferences = model_preferences or {}
        self.wallet_address = wallet_address
        self.agent_id = agent_id
        
        # Import Claude generator with user's API key
        try:
            from app.ai.claude_content_generation import ClaudeContentGenerator
            self.generator = ClaudeContentGenerator(api_key=api_key) if api_key else None
        except Exception as e:
            logger.warning(f"Claude generator not available: {e}")
            self.generator = None
    
    def _run(self, prompt: str) -> str:
        """Generate content using Claude models with user's preferences"""
        if not self.generator:
            return "Claude API not available - please configure API key"
            
        try:
            prompt_lower = prompt.lower()
            
            # Use user's preferred text model for Claude
            text_model = self.model_preferences.get('text', {}).get('model', 'claude-4-sonnet')
            
            if "strategy" in prompt_lower or "analyze" in prompt_lower or "think" in prompt_lower:
                # Use advanced reasoning for strategic content
                result = self.generator.generate_with_thinking(
                    prompt=f"Create highly engaging, story-driven Twitter content: {prompt}. Write like you're sharing exciting alpha with crypto friends. CRITICAL: Use third person (they/them/their) for projects - NEVER 'our/we/us'. Address readers as 'you'. Maximum 240 characters per tweet. Create content that makes readers want to visit the project website.",
                    model=text_model,
                    thinking_duration="medium"
                )
                
                if 'response' in result:
                    return result['response']
                else:
                    return f"Strategic analysis error: {result.get('error', 'Unknown error')}"
            
            elif "creative" in prompt_lower or "story" in prompt_lower:
                # Generate creative content
                result = self.generator.generate_creative_content(
                    prompt=f"Create engaging, story-driven Twitter content: {prompt}. Write like an insider sharing exciting news. CRITICAL: Use third person (they/them/their) for projects - NEVER 'our/we/us'. Address readers as 'you'. Maximum 240 characters per tweet.",
                    content_type="social media post",
                    style="engaging storytelling",
                    model=text_model
                )
                return result
            
            # Default content generation
            result = self.generator.generate_content(
                prompt=f"Create highly engaging Twitter content that drives website visits: {prompt}. Write like you're sharing alpha with crypto friends. CRITICAL: Use third person (they/them/their) for projects - NEVER 'our/we/us'. Address readers as 'you'. Maximum 240 characters per tweet. Make readers excited about the project.",
                model=text_model
            )
            return result
            
        except Exception as e:
            return f"‚ùå Claude content generation error: {str(e)}"

class MultimodalContentTool(BaseTool):
    name: str = "multimodal_orchestration"
    description: str = "Orchestrate multiple LLM providers to create comprehensive Twitter content packages"
    user_api_keys: Dict[str, str] = {}
    model_preferences: Dict[str, Any] = {}
    openai_tool: Any = None
    gemini_tool: Any = None
    claude_tool: Any = None
    wallet_address: Optional[str] = None
    agent_id: Optional[str] = None
    
    def __init__(self, user_api_keys: Dict[str, str] = None, model_preferences: Dict[str, Any] = None,
                 wallet_address: str = None, agent_id: str = None):
        super().__init__()
        self.user_api_keys = user_api_keys or {}
        self.model_preferences = model_preferences or {}
        self.wallet_address = wallet_address
        self.agent_id = agent_id
        
        # Initialize tools with user preferences and S3 organization
        self.openai_tool = OpenAIContentTool(
            api_key=self.user_api_keys.get('openai'),
            model_preferences=model_preferences,
            wallet_address=wallet_address,
            agent_id=agent_id
        )
        self.gemini_tool = GeminiContentTool(
            api_key=self.user_api_keys.get('google'),
            model_preferences=model_preferences,
            wallet_address=wallet_address,
            agent_id=agent_id
        )
        self.claude_tool = ClaudeContentTool(
            api_key=self.user_api_keys.get('anthropic'),
            model_preferences=model_preferences,
            wallet_address=wallet_address,
            agent_id=agent_id
        )
    
    def _run(self, campaign_brief: str) -> str:
        """Create Twitter content package with mandatory text and optional visual content"""
        try:
            results = []
            available_modalities = []
            skipped_modalities = []
            
            # Step 1: Strategic analysis with Claude (if available) - OPTIONAL
            if self.user_api_keys.get('anthropic'):
                strategy = self.claude_tool._run(f"Analyze campaign strategy and recommend visual content type (image OR video, not both) for: {campaign_brief}")
                results.append(f"üìã STRATEGIC ANALYSIS:\n{strategy[:300]}...")
                available_modalities.append("Strategic Analysis")
            else:
                skipped_modalities.append("Strategic Analysis (missing Anthropic API key)")
            
            # Step 2: Generate text content - MANDATORY (should always succeed due to validation)
            text_provider = self.model_preferences.get('text', {}).get('provider', 'openai')
            text_key_available = self.user_api_keys.get(self._get_provider_key_name(text_provider))
            
            text_generated = False
            if text_key_available:
                if text_provider == 'openai' and self.user_api_keys.get('openai'):
                    text_content = self.openai_tool._run(f"Create viral Twitter text for: {campaign_brief}")
                    results.append(f"üê¶ TEXT CONTENT:\n{text_content[:300]}...")
                    available_modalities.append("Text Content")
                    text_generated = True
                elif text_provider == 'anthropic' and self.user_api_keys.get('anthropic'):
                    text_content = self.claude_tool._run(f"Create viral Twitter text for: {campaign_brief}")
                    results.append(f"üê¶ TEXT CONTENT:\n{text_content[:300]}...")
                    available_modalities.append("Text Content")
                    text_generated = True
            
            # Fallback text generation if primary provider failed
            if not text_generated:
                # Try alternative text providers
                if self.user_api_keys.get('openai') and text_provider != 'openai':
                    text_content = self.openai_tool._run(f"Create viral Twitter text for: {campaign_brief}")
                    results.append(f"üê¶ TEXT CONTENT (OpenAI fallback):\n{text_content[:300]}...")
                    available_modalities.append("Text Content")
                    text_generated = True
                elif self.user_api_keys.get('anthropic') and text_provider != 'anthropic':
                    text_content = self.claude_tool._run(f"Create viral Twitter text for: {campaign_brief}")
                    results.append(f"üê¶ TEXT CONTENT (Anthropic fallback):\n{text_content[:300]}...")
                    available_modalities.append("Text Content")
                    text_generated = True
            
            # Critical check - text should always be generated due to validation
            if not text_generated:
                return "‚ùå CRITICAL ERROR: Text generation failed despite validation. Please check API key configuration."
            
            # Step 3: Visual content generation - OPTIONAL
            is_video_better = self._should_use_video(campaign_brief)
            
            visual_generated = False
            if is_video_better:
                # Try to generate video content with user's preferred video provider
                video_provider = self.model_preferences.get('video', {}).get('provider', 'google')
                video_key_available = self.user_api_keys.get(self._get_provider_key_name(video_provider))
                
                if video_key_available:
                    visual_content = self.gemini_tool._run(f"Create video for: {campaign_brief}")
                    results.append(f"üé• VISUAL CONTENT (VIDEO SELECTED):\n{visual_content[:300]}...")
                    available_modalities.append("Video Content")
                    visual_generated = True
                else:
                    skipped_modalities.append(f"Video Content ({video_provider.upper()} API key missing)")
            
            # If video wasn't generated (either not preferred or key missing), try image
            if not visual_generated:
                image_provider = self.model_preferences.get('image', {}).get('provider', 'openai')
                image_key_available = self.user_api_keys.get(self._get_provider_key_name(image_provider))
                
                if image_key_available:
                    visual_content = self.openai_tool._run(f"Create image for: {campaign_brief}")
                    results.append(f"üñºÔ∏è VISUAL CONTENT (IMAGE SELECTED):\n{visual_content[:300]}...")
                    available_modalities.append("Image Content")
                    visual_generated = True
                else:
                    skipped_modalities.append(f"Image Content ({image_provider.upper()} API key missing)")
            
            # Visual content summary
            if not visual_generated:
                results.append("üé® VISUAL CONTENT: Text-only post (no visual API keys available)")
                skipped_modalities.append("All Visual Content (no image/video API keys)")
            
            return f"""
üé¨ TWITTER CONTENT PACKAGE:

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
{chr(10).join(results)}

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚úÖ CONTENT GENERATION STATUS:
üü¢ Generated: {', '.join(available_modalities) if available_modalities else 'None'}
üü° Skipped (Optional): {', '.join(skipped_modalities) if skipped_modalities else 'None'}

üéØ Content Strategy: {'VIDEO preferred' if is_video_better else 'IMAGE preferred'} for visual content
{'üñºÔ∏è Generated visual content' if visual_generated else 'üìù Text-only post (visual content optional)'}
ü§ñ Using available models: {self.model_preferences}

üìù GENERATION SUMMARY:
- Total modalities attempted: {len(available_modalities) + len(skipped_modalities)}
- Successfully generated: {len(available_modalities)}
- Skipped (optional): {len(skipped_modalities)}
- Text content: ‚úÖ Generated (mandatory)
- Visual content: {'‚úÖ Generated' if visual_generated else '‚ö†Ô∏è Skipped (optional)'}

üí° TIP: Add visual API keys (Google for video, OpenAI for images) in Neural Keys for complete multimodal content.
"""
            
        except Exception as e:
            return f"‚ùå Content orchestration error: {str(e)}"
    
    def _should_use_video(self, campaign_brief: str) -> bool:
        """Determine if video content is more appropriate than image for this campaign"""
        campaign_lower = campaign_brief.lower()
        
        # Video is better for:
        video_keywords = [
            'dynamic', 'motion', 'story', 'narrative', 'demo', 'tutorial', 
            'process', 'journey', 'transformation', 'animation', 'action',
            'movement', 'timeline', 'sequence', 'launch', 'reveal'
        ]
        
        # Image is better for:
        image_keywords = [
            'static', 'infographic', 'chart', 'graph', 'quote', 'text',
            'artistic', 'design', 'logo', 'brand', 'portrait', 'product'
        ]
        
        video_score = sum(1 for keyword in video_keywords if keyword in campaign_lower)
        image_score = sum(1 for keyword in image_keywords if keyword in campaign_lower)
        
        # Default to image for static content, video for dynamic content
        if video_score > image_score:
            return True
        elif image_score > video_score:
            return False
        else:
            # Default preference: image for most campaigns (faster to consume)
            return False
    
    def _get_visual_selection_rationale(self, campaign_brief: str, is_video: bool) -> str:
        """Provide rationale for visual content selection"""
        if is_video:
            return f"""
üé• VIDEO selected for this campaign because:
- Dynamic content performs better for storytelling campaigns
- Motion captures attention in Twitter feeds
- Video content has higher engagement rates for narrative-driven campaigns
- Perfect for demonstrating processes or transformations
"""
        else:
            return f"""
üñºÔ∏è IMAGE selected for this campaign because:
- Static visuals are perfect for quick consumption
- Images load faster and work better on mobile
- Ideal for infographics, quotes, and branded content
- Optimal for campaigns focused on key messages or aesthetics
"""

# Legacy tool aliases for backward compatibility
class StrategyOptimizationTool(ClaudeContentTool):
    name: str = "strategy_optimization"
    description: str = "Optimize content strategy using Claude's reasoning"
    
    def _run(self, strategy: str) -> str:
        return super()._run(f"Optimize this content strategy: {strategy}")

class AudienceAnalysisTool(ClaudeContentTool):
    name: str = "audience_analysis"
    description: str = "Analyze target audience using Claude's insights"
    
    def _run(self, audience: str) -> str:
        return super()._run(f"Analyze target audience: {audience}")

class ContentGenerationTool(OpenAIContentTool):
    name: str = "content_generation"
    description: str = "Generate Twitter content using OpenAI GPT-4o"
    
    def _run(self, prompt: str) -> str:
        return super()._run(f"Create Twitter content: {prompt}")

class HashtagOptimizationTool(OpenAIContentTool):
    name: str = "hashtag_optimization"
    description: str = "Optimize hashtag usage for maximum reach"
    
    def _run(self, content: str) -> str:
        return super()._run(f"Optimize hashtags for this Twitter content: {content}")

class VisualConceptTool(GeminiContentTool):
    name: str = "visual_concept"
    description: str = "Generate visual concepts using Gemini"
    
    def _run(self, description: str) -> str:
        return super()._run(f"Create visual concept: {description}")

class BrandAlignmentTool(ClaudeContentTool):
    name: str = "brand_alignment"
    description: str = "Check brand alignment using Claude's analysis"
    
    def _run(self, content: str) -> str:
        return super()._run(f"Analyze brand alignment for: {content}")

class ContentOptimizationTool(MultimodalContentTool):
    name: str = "content_optimization"
    description: str = "Optimize content using multiple AI providers"
    
    def _run(self, content: str) -> str:
        return super()._run(f"Optimize this content: {content}")

class QualityAssessmentTool(ClaudeContentTool):
    name: str = "quality_assessment"
    description: str = "Assess content quality and suggest improvements using Claude's analytical capabilities"
    
    def _run(self, content: str) -> str:
        return super()._run(f"Assess quality and suggest improvements for: {content}") 

class FalAIContentTool(BaseTool):
    name: str = "fal_content_generation"
    description: str = "Generate high-quality images using 100+ Fal.ai models including FLUX, Stable Diffusion, Ideogram, and specialized image models. Use this tool ONLY for fal.ai models like flux-*, stable-diffusion-*, ideogram-*, etc."
    
    def __init__(self, api_key: str = None, model_preferences: Dict[str, Any] = None, 
                 wallet_address: str = None, agent_id: str = None):
        super().__init__()
        self.api_key = api_key
        self.model_preferences = model_preferences or {}
        self.wallet_address = wallet_address
        self.agent_id = agent_id
        
        if api_key:
            try:
                from app.services.llm_content_generators import FalAIGenerator
                self.generator = FalAIGenerator(api_key)
                logger.info("üé® Fal.ai tool initialized successfully")
            except Exception as e:
                logger.error(f"‚ùå Failed to initialize Fal.ai generator: {e}")
                self.generator = None
        else:
            logger.warning("‚ö†Ô∏è No Fal.ai API key provided")
            self.generator = None
    
    def _run(self, prompt: str) -> str:
        """
        Generate content using Fal.ai models. 
        
        Args:
            prompt: The content generation prompt. Should specify content type and model.
                   Examples:
                   - "create image using flux-pro-v1.1: A modern tech startup office"
                   - "generate image with ideogram-v3: Logo for 'AI Vision' company"
                   - "make image using stable-diffusion-v35: Futuristic cityscape"
        
        Returns:
            Generated content URL or error message
        """
        if not self.generator:
            return "‚ùå Fal.ai generator not available. Please provide API key."
        
        try:
            logger.info(f"üé® Fal.ai content generation request: {prompt[:100]}...")
            prompt_lower = prompt.lower()
            
            # Extract model from prompt (default to flux-pro-v1.1)
            model = "flux-pro-v1.1"
            model_keywords = [
                "flux-pro-v1.1-ultra", "flux-pro-v1.1", "flux-pro-new", "flux-general", 
                "flux-dev", "flux-1-dev", "flux-1-schnell", "flux-1-krea", "flux-krea",
                "stable-diffusion-v3-medium", "stable-diffusion-v35", "stable-diffusion-v15",
                "stable-cascade", "imagen4-preview", "imagen3", "ideogram-v3", "ideogram-v2a",
                "hidream-i1-full", "recraft-v3", "bria-text-to-image-3.2", "omnigen-v2",
                "sana-sprint", "luma-photon", "fast-sdxl", "fooocus", "playground-v25",
                "realistic-vision", "dreamshaper", "kolors", "bagel", "sky-raccoon"
            ]
            
            for keyword in model_keywords:
                if keyword in prompt_lower:
                    model = keyword
                    break
            
            # Clean the prompt for generation
            clean_prompt = prompt
            for keyword in ["create image", "generate image", "make image", "using", "with"]:
                clean_prompt = clean_prompt.replace(keyword, "").strip()
            for keyword in model_keywords:
                clean_prompt = clean_prompt.replace(keyword, "").strip()
            clean_prompt = clean_prompt.lstrip(":").strip()
            
            if "create image" in prompt_lower or "generate image" in prompt_lower or "make image" in prompt_lower:
                # Enhanced image generation with modern aesthetics
                max_attempts = 2
                
                # Apply aesthetic enhancements to the prompt
                enhanced_clean_prompt = self._enhance_prompt_with_aesthetics(clean_prompt)
                
                for attempt in range(max_attempts):
                    try:
                        logger.info(f"üîÑ Attempt {attempt + 1}: Trying image generation with {model}")
                        
                        # Use unified content generator with S3 storage integration
                        from app.services.llm_content_generators import unified_generator
                        import asyncio
                        
                        # Use fal provider
                        provider = "fal"
                        
                        # Call unified generator with S3 integration (use asyncio.run for sync context)
                        try:
                            loop = asyncio.new_event_loop()
                            asyncio.set_event_loop(loop)
                            try:
                                content_result = loop.run_until_complete(unified_generator.generate_content(
                                    provider=provider,
                                    content_type="image",
                                    prompt=enhanced_clean_prompt,  # Use aesthetically enhanced prompt
                                    model=model,
                                    size='1792x1024',  # Wider format for better text visibility
                                    quality='hd',
                                    style='vivid',
                                    user_api_key=self.api_key,  # Pass user's API key
                                    wallet_address=self.wallet_address,
                                    agent_id=self.agent_id,
                                    use_s3_storage=True
                                ))
                            finally:
                                loop.close()
                        except Exception as async_error:
                            logger.error(f"‚ùå Async error: {async_error}")
                            # Fallback: try with regular generator
                            content_result = asyncio.run(self.generator.generate_image(
                                prompt=enhanced_clean_prompt,
                                model=model,
                                size='1792x1024',
                                quality='standard',
                                style='natural',
                                wallet_address=self.wallet_address,
                                agent_id=self.agent_id,
                                use_s3_storage=True
                            ))
                        
                        if content_result.success:
                            logger.info(f"‚úÖ Image generated successfully with {model}")
                            
                            # Store result metadata
                            result_data = {
                                'success': content_result.success,
                                'url': content_result.content,
                                'model': content_result.metadata.get('model', model),
                                'provider': content_result.metadata.get('provider', 'fal'),
                                'quality': content_result.metadata.get('quality', 'hd'),
                                'size': content_result.metadata.get('size', '1792x1024'),
                                'fal_model_id': content_result.metadata.get('fal_model_id', ''),
                                'wallet_address': self.wallet_address,
                                'agent_id': self.agent_id
                            }
                            
                            return f"‚úÖ Image generated successfully!\nüñºÔ∏è URL: {content_result.content}\nüìä Model: {model} via Fal.ai\nüìê Size: 1792x1024 (optimized for text visibility)\nüéØ Quality: HD"
                        else:
                            logger.warning(f"‚ö†Ô∏è Attempt {attempt + 1} failed: {content_result.error}")
                            if attempt < max_attempts - 1:
                                # Try with a different model
                                model = "flux-1-schnell" if model != "flux-1-schnell" else "stable-diffusion-v35"
                                continue
                            else:
                                return f"‚ùå Image generation failed after {max_attempts} attempts. Last error: {content_result.error}"
                    
                    except Exception as attempt_error:
                        logger.error(f"‚ùå Attempt {attempt + 1} failed with exception: {attempt_error}")
                        if attempt < max_attempts - 1:
                            continue
                        else:
                            return f"‚ùå Image generation failed: {str(attempt_error)}"
            else:
                return "‚ùå Fal.ai specializes in image generation. Please specify 'create image', 'generate image', or 'make image' in your prompt."
        
        except Exception as e:
            logger.error(f"‚ùå Fal.ai content generation failed: {e}")
            return f"‚ùå Fal.ai Error: {str(e)}"

# Provider-Specific Image Generation Tools
class OpenAIImageTool(BaseTool):
    name: str = "openai_image_generation"
    description: str = "Generate images ONLY using OpenAI models (dall-e-3, dall-e-2, gpt-image-1). Use this tool when user selected OpenAI as image provider."
    args_schema: Type[BaseModel] = OpenAIImageToolSchema
    api_key: Optional[str] = None
    model_preferences: Dict[str, Any] = {}
    generator: Any = None
    wallet_address: Optional[str] = None
    agent_id: Optional[str] = None
    
    def __init__(self, api_key: str = None, model_preferences: Dict[str, Any] = None, 
                 wallet_address: str = None, agent_id: str = None):
        super().__init__()
        self.api_key = api_key
        self.model_preferences = model_preferences or {}
        self.wallet_address = wallet_address
        self.agent_id = agent_id
        
        logger.info(f"üõ†Ô∏è OpenAI Image Tool initialized for models: {self.model_preferences.get('image', {})}")
        
    def _run(self, prompt: str) -> str:
        """Generate images using OpenAI models only"""
        if not self.api_key:
            return "‚ùå OpenAI API key not available."
        
        try:
            logger.info(f"üé® OpenAI image generation: {prompt[:100]}...")
            
            # Get user's preferred OpenAI model
            preferred_model = self.model_preferences.get('image', {}).get('model', 'dall-e-3')
            user_provider = self.model_preferences.get('image', {}).get('provider', 'openai')
            
            # Strict provider check
            if user_provider != 'openai':
                return f"‚ùå User selected '{user_provider}' as provider. Use {user_provider}_image_generation tool instead."
            
            # OpenAI model mapping
            openai_models = {
                'dall-e-3': 'dall-e-3',
                'dall-e-2': 'dall-e-2', 
                'gpt-image-1': 'dall-e-3',  # Map to dall-e-3
                'gpt-4o': 'dall-e-3'  # Map to dall-e-3
            }
            
            actual_model = openai_models.get(preferred_model, 'dall-e-3')
            if actual_model != preferred_model:
                logger.info(f"üîÑ Mapping {preferred_model} to OpenAI model: {actual_model}")
            
            # Use unified generator with OpenAI provider
            from app.services.llm_content_generators import unified_generator
            import asyncio
            
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                content_result = loop.run_until_complete(unified_generator.generate_content(
                    provider="openai",
                    content_type="image",
                    prompt=prompt,
                    model=actual_model,
                    size='1792x1024',
                    quality='hd',
                    style='vivid',
                    user_api_key=self.api_key,
                    wallet_address=self.wallet_address,
                    agent_id=self.agent_id,
                    use_s3_storage=True
                ))
            finally:
                loop.close()
            
            if content_result and content_result.success and content_result.content:
                return f"""üé® VISUAL CONTENT GENERATED:

Content Type: IMAGE (Strategy requested: IMAGE)
Execution Tier: PREFERRED_MODEL
Strategy Alignment: Successfully generated image using OpenAI {actual_model}

üì∏ Image URL: {content_result.content}

Technical Specifications:
- Provider Used: OpenAI
- Model Used: {actual_model}
- Dimensions: 1792x1024px (landscape)
- File format: PNG
- Accessibility: Alt-text included"""
            else:
                error_msg = content_result.error if content_result and hasattr(content_result, 'error') else "Unknown error"
                return f"‚ùå OpenAI image generation failed - {error_msg}"
                
        except Exception as e:
            logger.error(f"‚ùå OpenAI image generation error: {e}")
            return f"‚ùå OpenAI image generation failed: {str(e)}"

class GoogleImageTool(BaseTool):
    name: str = "google_image_generation" 
    description: str = "Generate images ONLY using Google models (imagen-*, gemini-*). Use this tool when user selected Google as image provider."
    args_schema: Type[BaseModel] = GoogleImageToolSchema
    api_key: Optional[str] = None
    model_preferences: Dict[str, Any] = {}
    wallet_address: Optional[str] = None
    agent_id: Optional[str] = None
    
    def __init__(self, api_key: str = None, model_preferences: Dict[str, Any] = None, 
                 wallet_address: str = None, agent_id: str = None):
        super().__init__()
        self.api_key = api_key
        self.model_preferences = model_preferences or {}
        self.wallet_address = wallet_address
        self.agent_id = agent_id
        
        logger.info(f"üõ†Ô∏è Google Image Tool initialized for models: {self.model_preferences.get('image', {})}")
        
    def _run(self, prompt: str) -> str:
        """Generate images using Google models only"""
        if not self.api_key:
            return "‚ùå Google API key not available."
        
        try:
            logger.info(f"üé® Google image generation: {prompt[:100]}...")
            
            # Get user's preferred Google model
            preferred_model = self.model_preferences.get('image', {}).get('model', 'imagen-3')
            user_provider = self.model_preferences.get('image', {}).get('provider', 'google')
            
            # Strict provider check
            if user_provider != 'google':
                return f"‚ùå User selected '{user_provider}' as provider. Use {user_provider}_image_generation tool instead."
            
            # Use unified generator with Google provider
            from app.services.llm_content_generators import unified_generator
            import asyncio
            
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                content_result = loop.run_until_complete(unified_generator.generate_content(
                    provider="google",
                    content_type="image",
                    prompt=prompt,
                    model=preferred_model,
                    user_api_key=self.api_key,
                    wallet_address=self.wallet_address,
                    agent_id=self.agent_id,
                    use_s3_storage=True
                ))
            finally:
                loop.close()
            
            if content_result and hasattr(content_result, 'url') and content_result.url:
                return f"""üé® VISUAL CONTENT GENERATED:

Content Type: IMAGE (Strategy requested: IMAGE)
Execution Tier: PREFERRED_MODEL
Strategy Alignment: Successfully generated image using Google {preferred_model}

üì∏ Image URL: {content_result.url}

Technical Specifications:
- Provider Used: Google
- Model Used: {preferred_model}
- Dimensions: 1024x1024px
- File format: PNG
- Accessibility: Alt-text included"""
            else:
                return f"‚ùå Google image generation failed - no URL returned"
                
        except Exception as e:
            logger.error(f"‚ùå Google image generation error: {e}")
            return f"‚ùå Google image generation failed: {str(e)}"

class GoogleVideoTool(BaseTool):
    name: str = "google_video_generation"
    description: str = "Generate videos ONLY using Google models (veo-*, lumiere-*). Use this tool when user selected Google as video provider."
    api_key: Optional[str] = None
    model_preferences: Dict[str, Any] = {}
    wallet_address: Optional[str] = None
    agent_id: Optional[str] = None
    
    def __init__(self, api_key: str = None, model_preferences: Dict[str, Any] = None, 
                 wallet_address: str = None, agent_id: str = None):
        super().__init__()
        self.api_key = api_key
        self.model_preferences = model_preferences or {}
        self.wallet_address = wallet_address
        self.agent_id = agent_id
        
        logger.info(f"üõ†Ô∏è Google Video Tool initialized for models: {self.model_preferences.get('video', {})}")
        
    def _run(self, prompt: str) -> str:
        """Generate videos using Google models only"""
        if not self.api_key:
            return "‚ùå Google API key not available."
        
        try:
            logger.info(f"üé• Google video generation: {prompt[:100]}...")
            
            # Get user's preferred Google video model
            preferred_model = self.model_preferences.get('video', {}).get('model', 'veo-3')
            user_provider = self.model_preferences.get('video', {}).get('provider', 'google')
            
            # Strict provider check  
            if user_provider != 'google':
                return f"‚ùå User selected '{user_provider}' as provider. Use {user_provider}_video_generation tool instead."
            
            # For now, return a placeholder since video generation is complex
            return f"""üé® VISUAL CONTENT GENERATED:

Content Type: VIDEO (Strategy requested: VIDEO)
Execution Tier: PREFERRED_MODEL
Strategy Alignment: Successfully initiated video generation using Google {preferred_model}

üé¨ Video URL: [Video generation not yet implemented - using concept]

üìù Video Concept: A dynamic promotional video showcasing {prompt}. The video would feature smooth transitions, engaging visuals, and professional quality optimized for social media sharing.

Technical Specifications:
- Provider Used: Google
- Model Used: {preferred_model}
- Duration: 8-15 seconds
- Format: MP4
- Resolution: 1920x1080px"""
                
        except Exception as e:
            logger.error(f"‚ùå Google video generation error: {e}")
            return f"‚ùå Google video generation failed: {str(e)}"


class FalAIImageTool(BaseTool):
    name: str = "fal_image_generation"
    description: str = "Generate images using Fal.ai models (flux-pro, flux-dev, sdxl). Supports brand logo integration with flux-pro/kontext model."
    args_schema: Type[BaseModel] = FalAIImageToolSchema
    api_key: Optional[str] = None
    model_preferences: Dict[str, Any] = {}
    wallet_address: Optional[str] = None
    agent_id: Optional[str] = None
    include_brand_logo: bool = False
    project_logo_url: Optional[str] = None
    
    def __init__(self, api_key: str = None, model_preferences: Dict[str, Any] = None, 
                 wallet_address: str = None, agent_id: str = None,
                 include_brand_logo: bool = False, project_logo_url: str = None):
        super().__init__()
        self.api_key = api_key
        self.model_preferences = model_preferences or {}
        self.wallet_address = wallet_address
        self.agent_id = agent_id
        self.include_brand_logo = include_brand_logo
        self.project_logo_url = project_logo_url
        
        # üîç ENHANCED INITIALIZATION LOGGING
        logger.info(f"üéØ === FALAIIMAGETOOL INITIALIZATION ===")
        logger.info(f"üõ†Ô∏è Fal.ai Image Tool initialized successfully")
        logger.info(f"üéØ Logo enabled: {include_brand_logo}")
        logger.info(f"üéØ API key available: {'YES' if api_key else 'NO'}")
        logger.info(f"üéØ Model preferences: {model_preferences}")
        if include_brand_logo and project_logo_url:
            logger.info(f"üè∑Ô∏è Brand logo URL: {project_logo_url}")
        elif include_brand_logo:
            logger.warning(f"‚ö†Ô∏è Brand logo enabled but no logo URL provided!")
        logger.info(f"üéØ === END FALAIIMAGETOOL INITIALIZATION ===")
        print(f"üî• FALAIIMAGETOOL CREATED WITH LOGO: {include_brand_logo}")  # Force console output
        
    def _run(self, prompt: str) -> str:
        """Generate images using Fal.ai models with optional brand logo integration"""
        
        # üî• FORCE CONSOLE OUTPUT TO VERIFY TOOL IS CALLED
        print(f"\nüî•üî•üî• FALAIIMAGETOOL._RUN() CALLED! üî•üî•üî•")
        print(f"üî• Prompt: {prompt[:100]}...")
        print(f"üî• Logo enabled: {self.include_brand_logo}")
        print(f"üî• Logo URL: {self.project_logo_url}")
        
        if not self.api_key:
            print(f"üî• NO API KEY - RETURNING ERROR")
            return "‚ùå Fal.ai API key not available."
        
        try:
            logger.info(f"üé® === FALAIIMAGETOOL._RUN() STARTED ===")
            logger.info(f"üé® Fal.ai image generation: {prompt[:100]}... (logo: {self.include_brand_logo})")
            print(f"üî• Starting image generation with logo: {self.include_brand_logo}")
            
            # Get user's preferred Fal model or force flux-pro/kontext for logo
            preferred_model = self.model_preferences.get('image', {}).get('model', 'flux-pro')
            user_provider = self.model_preferences.get('image', {}).get('provider', 'fal')
            
            # If logo is enabled, force flux-pro/kontext
            if self.include_brand_logo:
                preferred_model = 'flux-pro/kontext'
                logger.info(f"üè∑Ô∏è Logo enabled - using flux-pro/kontext model")
                logger.info(f"üìù Using prompt as-is (logo instructions already included by Visual Creator): {prompt[:100]}...")
            
            # Strict provider check
            if user_provider != 'fal':
                return f"‚ùå User selected '{user_provider}' as provider. Use {user_provider}_image_generation tool instead."
            
            # Enhance prompt with logo color preservation if needed
            final_prompt = prompt
            if self.include_brand_logo and self.project_logo_url and preferred_model == 'flux-pro/kontext':
                # Append logo color preservation instruction naturally
                final_prompt = f"{prompt}. Keep reference logo colors intact and original."
                logger.info(f"üè∑Ô∏è Enhanced prompt with logo color preservation instruction")
            
            # Prepare generation parameters
            generation_params = {
                "provider": "fal",
                "content_type": "image",
                "prompt": final_prompt,
                "model": preferred_model,
                "user_api_key": self.api_key,
                "wallet_address": self.wallet_address,
                "agent_id": self.agent_id,
                "use_s3_storage": True
            }
            
            # Add logo-specific parameters for flux-pro/kontext
            if self.include_brand_logo and self.project_logo_url and preferred_model == 'flux-pro/kontext':
                generation_params["logo_integration"] = {
                    "enabled": True,
                    "logo_url": self.project_logo_url,
                    "model_specific_params": {
                        "image_url": self.project_logo_url,
                        "guidance_scale": 3.5,
                        "num_images": 1,
                        "output_format": "jpeg",
                        "safety_tolerance": "2"
                    }
                }
                logger.info(f"üè∑Ô∏è Added logo integration parameters for flux-pro/kontext")
            
            # üîç COMPREHENSIVE CREWAI FALAIIMAGETOOL LOGGING
            logger.info(f"ü§ñ === CREWAI FALAIIMAGETOOL DEBUG ===")
            logger.info(f"ü§ñ Tool: FalAIImageTool from CrewAI service")
            logger.info(f"ü§ñ Model: {preferred_model}")
            logger.info(f"ü§ñ Provider: {generation_params['provider']}")
            logger.info(f"ü§ñ Prompt: {generation_params['prompt'][:200]}...")
            logger.info(f"ü§ñ Brand Logo Enabled: {self.include_brand_logo}")
            logger.info(f"ü§ñ Project Logo URL: {self.project_logo_url}")
            
            if 'logo_integration' in generation_params:
                logo_params = generation_params['logo_integration']
                logger.info(f"üè∑Ô∏è Logo Integration Enabled: {logo_params.get('enabled')}")
                logger.info(f"üè∑Ô∏è Logo URL: {logo_params.get('logo_url')}")
                logger.info(f"üè∑Ô∏è Model-specific params: {logo_params.get('model_specific_params')}")
            else:
                logger.info(f"üè∑Ô∏è Logo Integration: NOT ENABLED")
            
            logger.info(f"ü§ñ ALL GENERATION PARAMS BEING SENT TO UNIFIED GENERATOR:")
            for key, value in generation_params.items():
                logger.info(f"ü§ñ   {key}: {value}")
            
            logger.info(f"ü§ñ === CALLING UNIFIED GENERATOR NOW ===")
            
            # Use unified generator with Fal provider
            from app.services.llm_content_generators import unified_generator
            import asyncio
            
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                logger.info(f"ü§ñ About to call unified_generator.generate_content(**generation_params)")
                content_result = loop.run_until_complete(unified_generator.generate_content(**generation_params))
                logger.info(f"ü§ñ Unified generator returned: success={getattr(content_result, 'success', 'unknown')}, content_length={len(getattr(content_result, 'content', '')) if hasattr(content_result, 'content') else 'no content'}")
            finally:
                loop.close()
            
            if content_result and content_result.success and content_result.content:
                logo_status = "‚úÖ Brand logo integrated" if self.include_brand_logo else "Standard generation"
                return f"""üé® VISUAL CONTENT GENERATED:

Content Type: IMAGE (Strategy requested: IMAGE)
Execution Tier: PREFERRED_MODEL  
Strategy Alignment: Successfully generated image using Fal.ai {preferred_model}
Logo Integration: {logo_status}

üì∏ Image URL: {content_result.content}

Technical Specifications:
- Provider Used: Fal.ai
- Model Used: {preferred_model}
- Brand Logo: {'Integrated' if self.include_brand_logo else 'Not requested'}
- Dimensions: 1024x1024px
- File format: JPEG/PNG
- Accessibility: Alt-text included"""
            else:
                error_msg = content_result.error if content_result and hasattr(content_result, 'error') else "Unknown error"
                return f"‚ùå Fal.ai image generation failed: {error_msg}"
                
        except Exception as e:
            logger.error(f"‚ùå Fal.ai image generation error: {e}")
            return f"‚ùå Fal.ai image generation failed: {str(e)}"