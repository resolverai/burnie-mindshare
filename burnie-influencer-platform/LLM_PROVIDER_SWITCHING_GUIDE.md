# ğŸ”Œ LLM Provider Switching Guide

This system is designed to be **easily pluggable** - you can switch between OpenAI, Anthropic, and other LLM providers at any time without code changes.

## ğŸš€ Quick Switch Methods

### Method 1: Environment Variables (Persistent)
```bash
# In python-ai-backend/.env
DEFAULT_LLM_PROVIDER=openai          # Primary provider
FALLBACK_LLM_PROVIDER=anthropic      # Backup provider

# To switch to Anthropic as primary:
DEFAULT_LLM_PROVIDER=anthropic
FALLBACK_LLM_PROVIDER=openai
```

### Method 2: Admin Dashboard (Runtime)
1. Go to **Admin Snapshots** page
2. Use the **LLM Provider Manager** component
3. Select providers from dropdowns
4. Click **Update Configuration**
5. Test providers to ensure they work

### Method 3: API Endpoints (Programmatic)
```bash
# Get current configuration
curl GET /api/llm-providers/current

# Switch providers
curl -X POST /api/llm-providers/configure \
  -H "Content-Type: application/json" \
  -d '{
    "primary_provider": "openai",
    "fallback_provider": "anthropic"
  }'

# Test a provider
curl -X POST /api/llm-providers/test \
  -H "Content-Type: application/json" \
  -d '{
    "provider": "openai",
    "test_prompt": "Hello, test message"
  }'
```

## ğŸ¯ Current Status: OpenAI Primary

**Current Configuration:**
- âœ… **Primary**: OpenAI GPT-4o (fast, cost-effective)
- âœ… **Fallback**: Anthropic Claude 3.5 Sonnet (high accuracy)
- âœ… **Auto-fallback**: If OpenAI fails, automatically uses Anthropic

## ğŸ“Š Provider Comparison

| Provider | Speed | Cost | Accuracy | Best For |
|----------|-------|------|----------|----------|
| **OpenAI** | âš¡âš¡âš¡ | ğŸ’°ğŸ’° | â­â­â­ | General tasks, speed |
| **Anthropic** | âš¡âš¡ | ğŸ’°ğŸ’°ğŸ’° | â­â­â­â­ | Structured data, accuracy |
| **Google** | âš¡âš¡ | ğŸ’° | â­â­ | Cost optimization |

## ğŸ› ï¸ System Architecture

```
Snapshot Upload
     â†“
CookieFunProcessor
     â†“
MultiProviderLLMService
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Primary Providerâ”‚ â†’  â”‚ Fallback Providerâ”‚
â”‚   (OpenAI)      â”‚    â”‚   (Anthropic)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ How Switching Works

### 1. **LLMProviderFactory**
- Creates provider instances dynamically
- Supports: `openai`, `anthropic`, `google`
- Extensible for new providers

### 2. **MultiProviderLLMService**
- Handles primary/fallback logic
- Automatic retry with fallback
- Consistent interface for all providers

### 3. **Settings-Based Configuration**
- Environment variables control defaults
- Runtime configuration via API
- Admin dashboard for easy switching

## ğŸ“ Configuration Examples

### Cost-Optimized Setup
```env
DEFAULT_LLM_PROVIDER=openai
FALLBACK_LLM_PROVIDER=anthropic
```

### Accuracy-Optimized Setup
```env
DEFAULT_LLM_PROVIDER=anthropic
FALLBACK_LLM_PROVIDER=openai
```

### Testing Setup
```env
DEFAULT_LLM_PROVIDER=openai
FALLBACK_LLM_PROVIDER=openai
```

## ğŸš¨ Important Notes

1. **API Keys Required**: Ensure you have valid API keys for providers you want to use
2. **Runtime vs Persistent**: Dashboard changes are runtime-only; env vars persist across restarts
3. **Health Monitoring**: Use the dashboard to monitor provider health and response times
4. **Automatic Fallback**: System automatically switches to fallback if primary fails
5. **No Downtime**: Provider switching happens immediately without service restart

## ğŸ§ª Testing Providers

### Before Switching
Always test providers before making them primary:

```bash
# Test OpenAI
curl -X POST /api/llm-providers/test -d '{"provider": "openai"}'

# Test Anthropic  
curl -X POST /api/llm-providers/test -d '{"provider": "anthropic"}'
```

### Health Monitoring
```bash
# Check all provider health
curl GET /api/llm-providers/health

# Get recommendations
curl GET /api/llm-providers/recommendations
```

## ğŸ›ï¸ Admin Dashboard Features

The **LLM Provider Manager** component provides:

- âœ… **Real-time Health Status** - See provider response times and health
- âœ… **One-Click Testing** - Test any provider instantly
- âœ… **Easy Configuration** - Switch providers with dropdowns
- âœ… **Visual Indicators** - Health icons and response time metrics
- âœ… **Provider Recommendations** - Optimal configurations for different use cases

## ğŸ”® Adding New Providers

To add a new LLM provider:

1. **Create Provider Class** in `app/services/llm_providers.py`:
```python
class NewProvider(LLMProvider):
    async def analyze_image_with_text(self, ...):
        # Implementation
    
    async def analyze_multiple_images_with_text(self, ...):
        # Implementation
```

2. **Register in Factory**:
```python
_providers = {
    "openai": OpenAIProvider,
    "anthropic": AnthropicProvider,
    "newprovider": NewProvider  # Add here
}
```

3. **Update Settings** with API key configuration

4. **Test and Deploy** - Provider is immediately available

The system is designed for maximum flexibility and ease of switching! ğŸš€
