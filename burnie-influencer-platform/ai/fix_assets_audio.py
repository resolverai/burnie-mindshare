#!/usr/bin/env python3
"""
Fix Audio & Regenerate Video from Assets

This script supports assets generated by BOTH:
- political_video_generator.py (image-based political videos with effects)
- ai_avatar_video_generator.py (OmniHuman-based avatar videos)

This script can:
1. Fix audio noise/artifacts in existing video assets
2. Regenerate final video from raw assets (videos, voiceovers, music)
3. Apply captions to the final video
4. List available assets and verify regeneration capability

Usage:
    # List available assets and check what's available
    python fix_assets_audio.py --assets-folder output/video_assets --list-assets
    
    # Just re-stitch original clips with proper audio handling
    python fix_assets_audio.py --assets-folder output/video_assets --restitch-only
    
    # Regenerate from raw assets (works for both political and avatar videos)
    python fix_assets_audio.py --assets-folder output/video_assets --from-raw
    
    # Regenerate with captions
    python fix_assets_audio.py --assets-folder output/video_assets --from-raw --captions karaoke_red

Assets Structure:
    raw_assets/
    ‚îú‚îÄ‚îÄ master_metadata.json    # Generation params, clip info (identifies generator)
    ‚îú‚îÄ‚îÄ video_plan.json         # Grok-generated video plan
    ‚îú‚îÄ‚îÄ input_context.txt       # Original script text
    ‚îú‚îÄ‚îÄ transcriptions.json     # Word timestamps for captions (if captions were used)
    ‚îú‚îÄ‚îÄ effect_analysis.json    # Applied effects (political_video_generator only)
    ‚îú‚îÄ‚îÄ videos/                 # Raw video clips (SILENT_IMAGE, B_ROLL, AI_VIDEO)
    ‚îÇ   ‚îî‚îÄ‚îÄ clip_*_raw.mp4
    ‚îú‚îÄ‚îÄ images/                 # Generated images (starting frames for B_ROLL, influencer clips)
    ‚îÇ   ‚îî‚îÄ‚îÄ clip_*.png
    ‚îú‚îÄ‚îÄ voiceovers/             # Voiceover audio files
    ‚îÇ   ‚îî‚îÄ‚îÄ voiceover_clip_*.mp3
    ‚îú‚îÄ‚îÄ music/                  # Background music files (first one loops throughout)
    ‚îÇ   ‚îî‚îÄ‚îÄ music_Music_A.mp3   # Uses only first music group, loops for entire video
    ‚îî‚îÄ‚îÄ research_clips/         # Research clips to insert after specific clips
        ‚îú‚îÄ‚îÄ research_after_clip_{n}.mp4       # Research video
        ‚îú‚îÄ‚îÄ research_vo_after_clip_{n}.mp3    # Research voiceover
        ‚îî‚îÄ‚îÄ research_after_clip_{n}_info.json # Research metadata

Clip Types Supported:
    - SILENT_IMAGE: Static image with text overlay (Clip 0 only)
    - B_ROLL: Dynamic AI-generated video clips from images (single or video groups)
    - AI_VIDEO: Influencer clips with OmniHuman lip-sync
    - Research clips: Inserted after specified clips with unique numbers (1000+n)
"""

import argparse
import os
import json
import glob
import shutil
from typing import List, Dict, Optional, Tuple
from moviepy.editor import (
    VideoFileClip, AudioFileClip, 
    concatenate_videoclips, concatenate_audioclips,
    CompositeAudioClip
)

# Constants
OUTPUT_SIZE = (1080, 1920)  # 9:16 vertical
FPS = 30


def apply_speed_and_music(video_path: str, output_path: str, speed: float = 1.0, 
                          music_path: Optional[str] = None, music_volume: float = 0.07,
                          clip_0_duration: float = 0.0) -> Optional[str]:
    """
    Apply speed change to video and then add background music.
    
    This function:
    1. Speeds up the video (visuals + any embedded audio) by the given factor
    2. Adds background music at normal speed to the sped-up video
    
    Args:
        video_path: Path to input video
        output_path: Path for output video
        speed: Speed multiplier (e.g., 1.1 for 10% faster)
        music_path: Optional path to background music
        music_volume: Volume for background music (default 0.07 = 7%)
        clip_0_duration: Duration of clip 0 (music starts AFTER this, scaled by speed)
    
    Returns:
        Path to output video or None on failure
    """
    if speed == 1.0 and not music_path:
        # No changes needed
        shutil.copy(video_path, output_path)
        return output_path
    
    try:
        print(f"\n{'='*60}")
        print(f"üöÄ APPLYING SPEED AND MUSIC")
        print(f"{'='*60}")
        
        video = VideoFileClip(video_path)
        original_duration = video.duration
        print(f"  Original duration: {original_duration:.2f}s")
        
        # Apply speed change if needed
        if speed != 1.0:
            print(f"  Applying speed: {speed}x")
            # speedx changes video speed (>1 = faster, <1 = slower)
            # This also speeds up any embedded audio proportionally
            video = video.speedx(speed)
            new_duration = video.duration
            print(f"  New duration: {new_duration:.2f}s ({original_duration/new_duration:.2f}x faster)")
        else:
            new_duration = original_duration
        
        # Calculate music start time (after clip 0, scaled by speed)
        # Clip 0 is SILENT_IMAGE, music should only start from Clip 1
        music_start_time = clip_0_duration / speed if speed != 1.0 else clip_0_duration
        print(f"  Music start time: {music_start_time:.2f}s (clip 0 duration: {clip_0_duration:.2f}s / speed: {speed}x)")
        
        # CRITICAL: When speed is applied, the audio can have artifacts at the end
        # We need to properly handle the sped-up audio BEFORE adding music
        END_BUFFER = 0.2  # 200ms buffer at end to prevent jitter
        audio_end_time = new_duration - END_BUFFER
        
        # First, handle the existing (sped-up) audio from the video
        if video.audio is not None:
            print(f"  Processing sped-up voiceover audio...")
            sped_audio = video.audio
            
            # Trim sped-up audio to prevent overflow and add buffer
            if sped_audio.duration > audio_end_time:
                sped_audio = sped_audio.subclip(0, audio_end_time)
                print(f"  Trimmed sped-up audio to {audio_end_time:.2f}s (added {END_BUFFER*1000:.0f}ms end buffer)")
            
            # Apply fade to sped-up audio to prevent artifacts at boundaries
            audio_fade = min(0.1, sped_audio.duration * 0.02)
            sped_audio = sped_audio.audio_fadeout(audio_fade)
        else:
            sped_audio = None
        
        # Add background music if provided
        if music_path and os.path.exists(music_path):
            print(f"  Adding background music: {os.path.basename(music_path)}")
            music = AudioFileClip(music_path)
            
            # Apply fade to music
            music_fade = min(0.05, music.duration * 0.02)
            music = music.audio_fadein(music_fade).audio_fadeout(music_fade)
            
            # Calculate how much music we need (from music_start_time to audio_end_time)
            music_duration_needed = audio_end_time - music_start_time
            
            # Loop music if needed
            if music.duration < music_duration_needed:
                loops_needed = int(music_duration_needed / music.duration) + 1
                music_parts = [music] * loops_needed
                music = concatenate_audioclips(music_parts)
                print(f"  Looped music {loops_needed}x to cover video")
            
            # Trim to needed duration
            music = music.subclip(0, max(0.1, music_duration_needed))
            
            # Apply final fade
            final_fade = min(0.1, music.duration * 0.02)
            music = music.audio_fadein(final_fade).audio_fadeout(final_fade)
            
            # CRITICAL: Start music AFTER clip 0 (not from beginning!)
            music = music.set_start(music_start_time)
            print(f"  üéµ Music will start at {music_start_time:.2f}s (skipping Clip 0)")
            
            # Set volume
            music = music.volumex(music_volume)
            
            # Combine with existing sped-up audio
            if sped_audio is not None:
                final_audio = CompositeAudioClip([sped_audio, music])
            else:
                final_audio = music
        else:
            final_audio = sped_audio
        
        # Set the properly processed audio on the video
        if final_audio is not None:
            # Final trim to ensure audio doesn't exceed video duration minus buffer
            if hasattr(final_audio, 'duration') and final_audio.duration > audio_end_time:
                final_audio = final_audio.subclip(0, audio_end_time)
            
            # Apply final fadeout to combined audio
            final_audio_fade = min(0.15, final_audio.duration * 0.02)
            final_audio = final_audio.audio_fadeout(final_audio_fade)
            
            video = video.set_audio(final_audio)
            print(f"  ‚úÖ Final audio duration: {final_audio.duration:.2f}s (video: {new_duration:.2f}s, buffer: {END_BUFFER*1000:.0f}ms)")
        
        # CRITICAL: Add fade to black at the END of the video to prevent noise/jitter
        FADE_OUT_DURATION = 0.3  # 300ms fade to black
        print(f"  üé¨ Adding {FADE_OUT_DURATION}s fade to black at end of video")
        video = video.fadeout(FADE_OUT_DURATION)
        
        # Write output
        print(f"  Writing output: {output_path}")
        video.write_videofile(
            output_path,
            fps=FPS,
            codec='libx264',
            audio_codec='aac',
            preset='medium',
            bitrate='8000k'
        )
        
        video.close()
        print(f"  ‚úÖ Speed and music applied successfully")
        return output_path
        
    except Exception as e:
        print(f"  ‚ùå Failed to apply speed/music: {e}")
        import traceback
        traceback.print_exc()
        return None


def load_master_metadata(assets_folder: str) -> Optional[Dict]:
    """Load master metadata from assets folder."""
    metadata_path = os.path.join(assets_folder, "raw_assets", "master_metadata.json")
    if os.path.exists(metadata_path):
        with open(metadata_path, 'r') as f:
            return json.load(f)
    return None


def detect_generator_type(assets_folder: str) -> str:
    """
    Detect which script generated the assets.
    
    Returns:
        - "ai_avatar_video_generator" for OmniHuman-based avatar videos
        - "political_video_generator" for image-based political videos
        - "unknown" if cannot be determined
    """
    metadata = load_master_metadata(assets_folder)
    if metadata:
        # Check explicit generator field (newer format)
        if 'generator' in metadata:
            return metadata['generator']
        
        # Infer from generation_params
        params = metadata.get('generation_params', {})
        
        # Avatar videos have split_proportion and reference_image
        if 'split_proportion' in params or 'reference_image' in params:
            return "ai_avatar_video_generator"
        
        # Political videos have influencer_mode, ai_video_model
        if 'influencer_mode' in params or 'ai_video_model' in params:
            return "political_video_generator"
        
        # Check if all clips have embedded voiceovers (avatar style)
        clips = metadata.get('clips', [])
        if clips and all(c.get('voiceover_embedded', False) for c in clips):
            return "ai_avatar_video_generator"
    
    # Fallback: check for characteristic files
    raw_assets_dir = os.path.join(assets_folder, "raw_assets")
    
    # Avatar videos have images/clip_*_image.png
    images_dir = os.path.join(raw_assets_dir, "images")
    if os.path.exists(images_dir):
        image_files = glob.glob(os.path.join(images_dir, "clip_*_image.png"))
        if image_files:
            return "ai_avatar_video_generator"
        
        # Political videos have images/clip_*.png or images/clip_*_start.png
        political_images = glob.glob(os.path.join(images_dir, "clip_*.png"))
        if political_images:
            return "political_video_generator"
    
    return "unknown"


def fix_clip_audio(clip_path: str, output_path: str, music_path: Optional[str] = None, 
                   music_start: float = 0, music_volume: float = 0.07) -> Optional[str]:
    """
    Fix audio in a single clip by:
    1. Extracting video without audio
    2. Extracting audio and applying proper fades
    3. Trimming audio to exact video duration
    4. Recombining with optional background music
    """
    print(f"  Fixing: {os.path.basename(clip_path)}")
    
    try:
        video = VideoFileClip(clip_path)
        video_duration = video.duration
        
        print(f"    Video duration: {video_duration:.2f}s")
        
        audio_clips = []
        
        if video.audio is not None:
            original_audio = video.audio
            
            if original_audio.duration > video_duration:
                original_audio = original_audio.subclip(0, video_duration)
                print(f"    Trimmed audio from {video.audio.duration:.2f}s to {video_duration:.2f}s")
            
            fade_duration = min(0.03, original_audio.duration * 0.05)
            original_audio = original_audio.audio_fadein(fade_duration).audio_fadeout(fade_duration)
            
            audio_clips.append(original_audio)
            print(f"    Applied fade ({fade_duration*1000:.1f}ms) to audio")
        else:
            print(f"    No audio in clip")
        
        if music_path and os.path.exists(music_path):
            music = AudioFileClip(music_path)
            
            music_fade = min(0.05, music.duration * 0.02)
            music = music.audio_fadein(music_fade).audio_fadeout(music_fade)
            
            if music_start + video_duration > music.duration:
                loops_needed = int((music_start + video_duration) / music.duration) + 1
                music_parts = [music] * loops_needed
                music = concatenate_audioclips(music_parts)
            
            music = music.subclip(music_start % music.duration, 
                                  min((music_start % music.duration) + video_duration, music.duration))
            
            if music.duration < video_duration:
                loops = int(video_duration / music.duration) + 1
                music_parts = [music] * loops
                music = concatenate_audioclips(music_parts)
            music = music.subclip(0, video_duration)
            
            clip_music_fade = min(0.03, music.duration * 0.05)
            music = music.audio_fadein(clip_music_fade).audio_fadeout(clip_music_fade)
            music = music.volumex(music_volume)
            
            audio_clips.append(music)
            print(f"    Added background music (volume: {music_volume})")
        
        video_no_audio = video.set_audio(None)
        
        if audio_clips:
            trimmed_clips = []
            for ac in audio_clips:
                if ac.duration > video_duration:
                    ac = ac.subclip(0, video_duration)
                trimmed_clips.append(ac)
            
            if len(trimmed_clips) > 1:
                final_audio = CompositeAudioClip(trimmed_clips)
            else:
                final_audio = trimmed_clips[0]
            
            # CRITICAL: Add buffer at the END to prevent jitter/noise
            END_BUFFER = 0.15  # 150ms buffer at end
            if final_audio.duration > video_duration - END_BUFFER:
                final_audio = final_audio.subclip(0, video_duration - END_BUFFER)
            
            # Apply final fade out at the very end
            final_fade_duration = min(0.1, final_audio.duration * 0.02)
            final_audio = final_audio.audio_fadeout(final_fade_duration)
            
            video_fixed = video_no_audio.set_audio(final_audio)
        else:
            video_fixed = video_no_audio
        
        video_fixed.write_videofile(
            output_path,
            fps=FPS,
            codec='libx264',
            audio_codec='aac',
            verbose=False,
            logger=None
        )
        
        video.close()
        video_fixed.close()
        
        print(f"    ‚úÖ Fixed clip saved")
        return output_path
        
    except Exception as e:
        print(f"    ‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        return None


def stitch_clips_with_separate_audio(
    video_paths: List[str],
    clip_numbers: List[int],  # Clip numbers corresponding to each path
    voiceover_paths: Dict[int, str],
    embedded_audio_clips: List[int],
    music_path: Optional[str],
    output_path: str,
    music_volume: float = 0.07,
    clip0_voiceover: Optional[str] = None
) -> Optional[str]:
    """
    Stitch video clips with separately managed audio.
    
    This is the key function for proper audio handling:
    - Strips audio from all video clips
    - Adds voiceover/embedded audio with proper timing
    - Adds background music
    - Uses CompositeAudioClip with set_start/set_end for precise boundaries
    - Uses clip_numbers to look up voiceovers (important for research clip insertion)
    
    Args:
        clip0_voiceover: Optional path to voiceover audio for Clip 0 (normally silent opening hook)
    """
    print(f"\n{'='*60}")
    print(f"üé¨ STITCHING WITH SEPARATE AUDIO HANDLING")
    print(f"{'='*60}")
    print(f"  Video clips: {len(video_paths)}")
    print(f"  Clip numbers: {clip_numbers}")
    print(f"  Voiceover clips: {len(voiceover_paths)}")
    print(f"  Embedded audio clips: {len(embedded_audio_clips)}")
    if clip0_voiceover:
        print(f"  üé§ Clip 0 voiceover: {os.path.basename(clip0_voiceover)}")
    
    try:
        video_clips = []
        audio_clips = []
        current_time = 0
        clip_durations = {}
        clip_start_times = {}
        
        # Build a mapping from clip_number to list index
        clip_num_to_index = {clip_numbers[i]: i for i in range(len(clip_numbers))}
        
        # Load all video clips and calculate timing
        for i, video_path in enumerate(video_paths):
            if not video_path or not os.path.exists(video_path):
                continue
            
            # Get the actual clip number for this position
            clip_num = clip_numbers[i] if i < len(clip_numbers) else i
            is_research_clip = clip_num >= 1000  # Research clips have numbers >= 1000
            is_silent_image_clip = (clip_num == 0)  # Clip 0 is always SILENT_IMAGE - no audio
            
            clip = VideoFileClip(video_path)
            clip_duration = clip.duration
            clip_durations[clip_num] = clip_duration
            clip_start_times[i] = current_time
            
            if clip.size != OUTPUT_SIZE:
                clip = clip.resize(OUTPUT_SIZE)
            
            # Clip 0 handling - normally silent, but can have custom voiceover
            if is_silent_image_clip:
                if clip0_voiceover and os.path.exists(clip0_voiceover):
                    # Custom voiceover for Clip 0
                    print(f"    Clip {i} #{clip_num}: Adding custom voiceover to opening hook")
                    voiceover = AudioFileClip(clip0_voiceover)
                    
                    # Trim voiceover to clip duration with buffer
                    AUDIO_BUFFER = 0.06
                    VOICEOVER_END_GAP = 0.15
                    target_duration = min(voiceover.duration, clip_duration) - AUDIO_BUFFER - VOICEOVER_END_GAP
                    target_duration = max(target_duration, 0.1)
                    
                    if voiceover.duration > target_duration:
                        voiceover = voiceover.subclip(0, target_duration)
                    
                    actual_vo_duration = voiceover.duration
                    
                    # Apply fade
                    fade_duration = min(0.05, voiceover.duration * 0.05)
                    voiceover = voiceover.audio_fadein(fade_duration).audio_fadeout(fade_duration)
                    
                    # Set timing
                    clip_end_time = current_time + actual_vo_duration
                    voiceover = voiceover.set_start(current_time).set_end(clip_end_time)
                    
                    audio_clips.append(voiceover)
                    print(f"    Clip {i} #{clip_num}: üé§ Custom voiceover added ({actual_vo_duration:.2f}s)")
                else:
                    print(f"    Clip {i} #{clip_num}: SILENT_IMAGE (no audio)")
                
                video_clips.append(clip.set_audio(None))
                current_time += clip_duration
                continue
            
            # Extract audio if this is an embedded audio clip
            if clip_num in embedded_audio_clips and clip.audio is not None:
                clip_audio = clip.audio
                
                # CRITICAL: Always trim embedded audio to ensure clean boundaries
                # Trim to slightly less than video duration (60ms buffer) to prevent
                # sample alignment issues at clip boundaries
                # PLUS add 150ms gap at END of voiceover for breathing room before next voiceover
                AUDIO_BUFFER = 0.06  # 60ms buffer to prevent boundary artifacts
                VOICEOVER_END_GAP = 0.15  # 150ms gap between voiceovers for natural pacing
                target_duration = min(clip_audio.duration, clip_duration) - AUDIO_BUFFER - VOICEOVER_END_GAP
                target_duration = max(target_duration, 0.1)  # Minimum 100ms
                
                if clip_audio.duration > target_duration:
                    clip_audio = clip_audio.subclip(0, target_duration)
                
                actual_audio_duration = clip_audio.duration
                
                # Apply fade in/out to prevent clicks/pops at boundaries
                fade_duration = min(0.05, clip_audio.duration * 0.05)  # Slightly longer fade
                clip_audio = clip_audio.audio_fadein(fade_duration).audio_fadeout(fade_duration)
                
                # Use actual audio duration for end time
                clip_end_time = current_time + actual_audio_duration
                clip_audio = clip_audio.set_start(current_time).set_end(clip_end_time)
                
                audio_clips.append(clip_audio)
                clip_label = f"(research after {clip_num - 1000})" if is_research_clip else ""
                print(f"    Clip {i} #{clip_num} {clip_label}: extracted embedded audio ({current_time:.2f}s - {clip_end_time:.2f}s)")
            
            # Add voiceover if available (for non-embedded clips)
            elif clip_num in voiceover_paths and voiceover_paths[clip_num]:
                vo_path = voiceover_paths[clip_num]
                if os.path.exists(vo_path):
                    voiceover = AudioFileClip(vo_path)
                    
                    # CRITICAL: Trim voiceover to ensure clean boundaries
                    # Use 60ms buffer to prevent sample alignment issues at clip boundaries
                    # PLUS add 150ms gap at END of voiceover for breathing room before next voiceover
                    AUDIO_BUFFER = 0.06  # 60ms buffer
                    VOICEOVER_END_GAP = 0.15  # 150ms gap between voiceovers for natural pacing
                    target_duration = min(voiceover.duration, clip_duration) - AUDIO_BUFFER - VOICEOVER_END_GAP
                    target_duration = max(target_duration, 0.1)  # Minimum 100ms
                    
                    if voiceover.duration > target_duration:
                        voiceover = voiceover.subclip(0, target_duration)
                    
                    actual_vo_duration = voiceover.duration
                    
                    # Apply fade in/out - slightly longer fade for cleaner transitions
                    fade_duration = min(0.05, voiceover.duration * 0.05)
                    voiceover = voiceover.audio_fadein(fade_duration).audio_fadeout(fade_duration)
                    
                    # Use actual voiceover duration for end time
                    clip_end_time = current_time + actual_vo_duration
                    voiceover = voiceover.set_start(current_time).set_end(clip_end_time)
                    
                    audio_clips.append(voiceover)
                    clip_label = f"(research after {clip_num - 1000})" if is_research_clip else ""
                    print(f"    Clip {i} #{clip_num} {clip_label}: added voiceover ({current_time:.2f}s - {clip_end_time:.2f}s)")
            
            # Strip audio from video and add to list
            video_clips.append(clip.set_audio(None))
            clip_label = f"(research after {clip_num - 1000})" if is_research_clip else ""
            print(f"    Clip {i} #{clip_num} {clip_label}: {clip_duration:.2f}s (video only)")
            
            current_time += clip_duration
        
        if not video_clips:
            print("  ‚ùå No video clips to stitch")
            return None
        
        # Concatenate videos
        print(f"\n  Concatenating {len(video_clips)} video clips...")
        final_video = concatenate_videoclips(video_clips, method="compose")
        total_duration = final_video.duration
        print(f"  Combined video duration: {total_duration:.2f}s")
        
        # Add background music (starts from Clip 1, skipping Clip 0 which is SILENT_IMAGE)
        if music_path and os.path.exists(music_path):
            print(f"  Adding background music...")
            music = AudioFileClip(music_path)
            
            # CRITICAL: Music starts from Clip 1 (skip Clip 0 which is SILENT_IMAGE)
            clip_0_duration = clip_durations.get(0, 4.0)  # Get Clip 0 duration
            music_start_time = clip_0_duration
            music_duration_needed = total_duration - music_start_time
            
            print(f"     Music starts at: {music_start_time:.1f}s (after Clip 0)")
            print(f"     Music duration needed: {music_duration_needed:.1f}s")
            
            music_fade = min(0.05, music.duration * 0.02)
            music = music.audio_fadein(music_fade).audio_fadeout(music_fade)
            
            if music.duration < music_duration_needed:
                loops_needed = int(music_duration_needed / music.duration) + 1
                music_parts = [music] * loops_needed
                music = concatenate_audioclips(music_parts)
                print(f"     Looped music {loops_needed}x")
            
            music = music.subclip(0, music_duration_needed)
            
            final_music_fade = min(0.1, music.duration * 0.01)
            music = music.audio_fadein(final_music_fade).audio_fadeout(final_music_fade)
            
            # Start music at Clip 1 (after Clip 0)
            music = music.set_start(music_start_time)
            music = music.volumex(music_volume)
            
            audio_clips.append(music)
            print(f"  Added music: {music.duration:.2f}s (starts at {music_start_time:.1f}s, skips Clip 0)")
        
        # Combine all audio
        if audio_clips:
            print(f"  Combining {len(audio_clips)} audio tracks...")
            
            # Final trim to ensure no overflow
            trimmed_audio = []
            for ac in audio_clips:
                if hasattr(ac, 'end') and ac.end and ac.end > total_duration:
                    ac = ac.set_end(total_duration)
                trimmed_audio.append(ac)
            
            final_audio = CompositeAudioClip(trimmed_audio)
            
            # CRITICAL: Add buffer at the END of the final video to prevent jitter/noise
            END_BUFFER = 0.15  # 150ms buffer at end of video
            if final_audio.duration > total_duration - END_BUFFER:
                final_audio = final_audio.subclip(0, total_duration - END_BUFFER)
                print(f"  üîá Added {int(END_BUFFER*1000)}ms end buffer to prevent audio jitter")
            
            # Apply final fade out at the very end
            final_fade_duration = min(0.1, final_audio.duration * 0.02)
            final_audio = final_audio.audio_fadeout(final_fade_duration)
            
            final_video = final_video.set_audio(final_audio)
            print(f"  Combined audio duration: {final_audio.duration:.2f}s")
        
        # CRITICAL: Add fade to black at the END of the video to prevent noise/jitter
        # This is especially important when the last clip is an AI Influencer clip
        FADE_OUT_DURATION = 0.3  # 300ms fade to black
        print(f"  üé¨ Adding {FADE_OUT_DURATION}s fade to black at end of video")
        final_video = final_video.fadeout(FADE_OUT_DURATION)
        
        # Write final video
        print(f"\n  Writing final video: {output_path}")
        final_video.write_videofile(
            output_path,
            fps=FPS,
            codec='libx264',
            audio_codec='aac',
            preset='medium',
            bitrate='8000k'
        )
        
        # Cleanup
        for clip in video_clips:
            clip.close()
        
        print(f"\n  ‚úÖ Final video created: {output_path}")
        return output_path
        
    except Exception as e:
        print(f"  ‚ùå Stitching failed: {e}")
        import traceback
        traceback.print_exc()
        return None


def load_transcriptions(assets_folder: str) -> Dict[int, Dict]:
    """Load saved transcription data (word timestamps for captions)."""
    transcription_path = os.path.join(assets_folder, "raw_assets", "transcriptions.json")
    if os.path.exists(transcription_path):
        with open(transcription_path, 'r') as f:
            data = json.load(f)
            # Convert string keys back to int
            return {int(k): v for k, v in data.items()}
    return {}


def load_video_plan(assets_folder: str) -> Optional[Dict]:
    """Load the original Grok video plan."""
    plan_path = os.path.join(assets_folder, "raw_assets", "video_plan.json")
    if os.path.exists(plan_path):
        with open(plan_path, 'r') as f:
            return json.load(f)
    return None


def load_effect_analysis(assets_folder: str) -> Dict[int, Dict]:
    """Load effect analysis results (applied effects per clip)."""
    effect_path = os.path.join(assets_folder, "raw_assets", "effect_analysis.json")
    if os.path.exists(effect_path):
        with open(effect_path, 'r') as f:
            data = json.load(f)
            return {int(k): v for k, v in data.items()}
    return {}


def load_research_clips(assets_folder: str) -> List[Dict]:
    """Load research clips from raw_assets/research_clips/ directory."""
    research_clips = []
    research_dir = os.path.join(assets_folder, "raw_assets", "research_clips")
    
    if not os.path.exists(research_dir):
        return []
    
    # Find all research clip info files
    info_files = glob.glob(os.path.join(research_dir, "research_after_clip_*_info.json"))
    
    for info_file in sorted(info_files):
        try:
            with open(info_file, 'r') as f:
                info = json.load(f)
            
            insert_after = info.get('insert_after_clip')
            if insert_after is None:
                continue
            
            # Find corresponding video and voiceover
            video_path = os.path.join(research_dir, f"research_after_clip_{insert_after}.mp4")
            vo_path = os.path.join(research_dir, f"research_vo_after_clip_{insert_after}.mp3")
            
            if os.path.exists(video_path):
                research_clips.append({
                    'insert_after_clip': insert_after,
                    'video_path': video_path,
                    'voiceover_path': vo_path if os.path.exists(vo_path) else None,
                    'duration': info.get('duration', 2.0),
                    'claim': info.get('claim', ''),
                    'voiceover_text': info.get('voiceover_text', '')
                })
        except Exception as e:
            print(f"  ‚ö†Ô∏è Error loading research clip info: {e}")
            continue
    
    return research_clips


def regenerate_from_raw(assets_folder: str, output_path: Optional[str] = None,
                        captions: Optional[str] = None, language_code: str = "en",
                        custom_music_path: Optional[str] = None, speed: float = 1.0,
                        use_saved_transcriptions: bool = True,
                        clip0_voiceover: Optional[str] = None,
                        include_music: bool = True) -> Optional[str]:
    """
    Regenerate final video from raw assets.
    
    Supports assets from both:
    - political_video_generator.py (image-based with effects, B_ROLL, research clips)
    - ai_avatar_video_generator.py (OmniHuman avatar videos)
    
    Args:
        custom_music_path: Optional path to custom background music file (overrides raw_assets music)
        speed: Speed multiplier for final video (e.g., 1.1 for 10% faster). 
               If speed != 1.0, video is first stitched without music, then sped up, then music is added.
        clip0_voiceover: Optional path to voiceover audio for Clip 0 (normally silent opening hook)
        include_music: If False, no background music will be added to the final video
    
    Uses:
    - raw_assets/videos/clip_*_raw.mp4 (raw video clips including B_ROLL)
    - raw_assets/images/clip_*.png (raw generated images)
    - raw_assets/voiceovers/voiceover_clip_*.mp3 (voiceover files)
    - raw_assets/music/music_*.mp3 (background music - uses first one, loops throughout)
    - raw_assets/research_clips/ (research clips to insert after specific clips)
    - raw_assets/master_metadata.json (clip information)
    - raw_assets/video_plan.json (Grok's video plan)
    - raw_assets/effect_analysis.json (effects per clip - political only)
    - raw_assets/transcriptions.json (word timestamps for captions)
    - raw_assets/input_context.txt (original input text)
    """
    print(f"\n{'='*60}")
    print(f"üîÑ REGENERATING FROM RAW ASSETS")
    print(f"{'='*60}")
    print(f"  Assets folder: {assets_folder}")
    
    raw_assets_dir = os.path.join(assets_folder, "raw_assets")
    if not os.path.exists(raw_assets_dir):
        print(f"  ‚ùå Raw assets folder not found: {raw_assets_dir}")
        return None
    
    # Detect generator type
    generator_type = detect_generator_type(assets_folder)
    generator_display = {
        "ai_avatar_video_generator": "AI Avatar (OmniHuman)",
        "political_video_generator": "Political Video (Image-based with B_ROLL)",
        "unknown": "Unknown"
    }.get(generator_type, "Unknown")
    print(f"  üé¨ Generator: {generator_display}")
    
    # Load master metadata
    metadata = load_master_metadata(assets_folder)
    if not metadata:
        print(f"  ‚ö†Ô∏è No master_metadata.json found, using file discovery")
    else:
        print(f"  ‚úÖ Loaded master metadata")
        print(f"     Clip count: {metadata.get('clip_count', 'unknown')}")
        print(f"     Total duration: {metadata.get('total_duration', 'unknown')}s")
        params = metadata.get('generation_params', {})
        print(f"     Language: {params.get('language_code', 'unknown')}")
        print(f"     Captions: {params.get('captions', 'none')}")
    
    # Load additional saved data
    video_plan = load_video_plan(assets_folder)
    if video_plan:
        print(f"  ‚úÖ Loaded video plan ({len(video_plan.get('clips', []))} clips)")
    
    effect_analysis = load_effect_analysis(assets_folder)
    if effect_analysis:
        print(f"  ‚úÖ Loaded effect analysis ({len(effect_analysis)} clips)")
    
    transcriptions = {}
    if use_saved_transcriptions:
        transcriptions = load_transcriptions(assets_folder)
        if transcriptions:
            print(f"  ‚úÖ Loaded transcriptions ({len(transcriptions)} clips)")
    
    # Find raw video clips (check multiple possible locations)
    # 1. First try new structure: raw_assets/videos/
    raw_videos_dir = os.path.join(raw_assets_dir, "videos")
    if not os.path.exists(raw_videos_dir):
        # 2. Fallback: check for clip_*_raw.mp4 directly in raw_assets
        raw_videos_dir = raw_assets_dir
    
    video_files = sorted(glob.glob(os.path.join(raw_videos_dir, "clip_*_raw.mp4")))
    if not video_files:
        print(f"  ‚ùå No raw video clips found in {raw_videos_dir}")
        print(f"     Try --restitch-only to use clip_*/clip_*_complete.mp4 files instead")
        return None
    
    print(f"  Found {len(video_files)} raw video clips")
    
    # Build video paths and clip numbers lists (parallel lists)
    video_paths = []
    clip_numbers = []
    
    for vf in sorted(video_files, key=lambda x: int(os.path.basename(x).split("_")[1])):
        # Extract clip number from filename (clip_0_raw.mp4 -> 0)
        basename = os.path.basename(vf)
        clip_num = int(basename.split("_")[1])
        video_paths.append(vf)
        clip_numbers.append(clip_num)
    
    # Find voiceover files (check new structure first)
    voiceover_paths = {}
    voiceovers_dir = os.path.join(raw_assets_dir, "voiceovers")
    if os.path.exists(voiceovers_dir):
        for vo_file in glob.glob(os.path.join(voiceovers_dir, "voiceover_clip_*.mp3")):
            basename = os.path.basename(vo_file)
            clip_num = int(basename.replace("voiceover_clip_", "").replace(".mp3", ""))
            voiceover_paths[clip_num] = vo_file
    else:
        # Fallback: check directly in raw_assets
        for vo_file in glob.glob(os.path.join(raw_assets_dir, "voiceover_clip_*.mp3")):
            basename = os.path.basename(vo_file)
            clip_num = int(basename.replace("voiceover_clip_", "").replace(".mp3", ""))
            voiceover_paths[clip_num] = vo_file
    print(f"  Found {len(voiceover_paths)} voiceover files")
    
    # Determine which clips have embedded audio (from metadata or generator type)
    embedded_audio_clips = []
    
    # For avatar videos, ALL clips have embedded audio (OmniHuman generates lip-synced videos)
    if generator_type == "ai_avatar_video_generator":
        # All clips have embedded audio in avatar videos
        embedded_audio_clips = list(clip_numbers)
        print(f"  Clips with embedded audio: ALL ({len(embedded_audio_clips)} clips - avatar video)")
    elif metadata and 'voiceover_files' in metadata:
        # For political videos, check metadata for which clips have embedded audio
        for clip_num_str, vo_info in metadata['voiceover_files'].items():
            if vo_info.get('embedded', False):
                embedded_audio_clips.append(int(clip_num_str))
        print(f"  Clips with embedded audio: {embedded_audio_clips}")
    else:
        print(f"  Clips with embedded audio: unknown (using file discovery)")
    
    # Load research clips
    research_clips = load_research_clips(assets_folder)
    if research_clips:
        print(f"  Found {len(research_clips)} research clips to insert")
        
        # Sort by insert_after_clip in reverse order (to maintain correct positions when inserting)
        research_clips.sort(key=lambda x: x['insert_after_clip'], reverse=True)
        
        # Insert research clips at their correct positions
        for research_clip in research_clips:
            insert_after_clip_num = research_clip['insert_after_clip']
            
            # Find the index of the clip we want to insert after
            try:
                idx_of_target = clip_numbers.index(insert_after_clip_num)
                insert_idx = idx_of_target + 1
            except ValueError:
                print(f"  ‚ö†Ô∏è Clip {insert_after_clip_num} not found, skipping research clip")
                continue
            
            # Create unique clip number for research clip (1000 + insert_after)
            research_clip_num = 1000 + insert_after_clip_num
            
            # Insert video path and clip number
            video_paths.insert(insert_idx, research_clip['video_path'])
            clip_numbers.insert(insert_idx, research_clip_num)
            
            # Add voiceover if available
            if research_clip['voiceover_path']:
                voiceover_paths[research_clip_num] = research_clip['voiceover_path']
            
            print(f"  üìç Inserted research clip after Clip {insert_after_clip_num} (at index {insert_idx})")
    
    # Find music file - use custom music if provided, otherwise use from raw_assets
    # Skip music entirely if include_music=False
    if not include_music:
        music_path = None
        print(f"  üîá No background music (--no-music flag)")
    elif custom_music_path and os.path.exists(custom_music_path):
        music_path = custom_music_path
        print(f"  üéµ Using CUSTOM music: {os.path.basename(music_path)} (will loop throughout)")
    else:
        # Find music from raw_assets (check new structure first - use first one and loop)
        music_dir = os.path.join(raw_assets_dir, "music")
        if os.path.exists(music_dir):
            music_files_list = sorted(glob.glob(os.path.join(music_dir, "music_*.mp3")))
        else:
            music_files_list = sorted(glob.glob(os.path.join(raw_assets_dir, "music_*.mp3")))
        music_path = music_files_list[0] if music_files_list else None
        if music_path:
            # Check if it's custom or generated music
            music_type = "generated"
            if metadata and 'music_files' in metadata:
                for group_name, music_info in metadata['music_files'].items():
                    if music_info.get('is_custom', False):
                        music_type = "custom"
                        orig_path = music_info.get('original_path', '')
                        if orig_path:
                            print(f"  Background music: {os.path.basename(music_path)} ({music_type} - from {os.path.basename(orig_path)}, will loop)")
                        else:
                            print(f"  Background music: {os.path.basename(music_path)} ({music_type}, will loop)")
                        break
                else:
                    print(f"  Background music: {os.path.basename(music_path)} ({music_type} via ElevenLabs, will loop)")
            else:
                print(f"  Background music: {os.path.basename(music_path)} (will loop throughout)")
    
    # Determine output path
    if not output_path:
        folder_name = os.path.basename(assets_folder.rstrip("/").rstrip("_assets"))
        output_path = os.path.join(os.path.dirname(assets_folder), f"{folder_name}_regenerated.mp4")
    
    # Get clip 0's duration for music timing (music starts AFTER clip 0)
    clip_0_duration = 0.0
    if video_paths and clip_numbers and clip_numbers[0] == 0:
        try:
            temp_clip = VideoFileClip(video_paths[0])
            clip_0_duration = temp_clip.duration
            temp_clip.close()
            print(f"  üìè Clip 0 duration: {clip_0_duration:.2f}s (music will start after this)")
        except Exception as e:
            print(f"  ‚ö†Ô∏è Could not get clip 0 duration: {e}, using default 0")
            clip_0_duration = 0.0
    
    # If speed != 1.0, stitch WITHOUT music first, then apply speed, then add music
    if speed != 1.0:
        print(f"\n  üöÄ Speed mode: {speed}x - will stitch without music, then speed up, then add music")
        
        # Step 1: Stitch without music
        temp_no_music_path = output_path.replace(".mp4", "_temp_no_music.mp4")
        result = stitch_clips_with_separate_audio(
            video_paths=video_paths,
            clip_numbers=clip_numbers,
            voiceover_paths=voiceover_paths,
            embedded_audio_clips=embedded_audio_clips,
            music_path=None,  # No music in first pass
            output_path=temp_no_music_path,
            music_volume=0.07,
            clip0_voiceover=clip0_voiceover
        )
        
        if result:
            # Step 2 & 3: Apply speed and add music
            final_result = apply_speed_and_music(
                video_path=temp_no_music_path,
                output_path=output_path,
                speed=speed,
                music_path=music_path,
                music_volume=0.07,
                clip_0_duration=clip_0_duration  # Pass clip 0 duration for music timing
            )
            
            # Clean up temp file
            if os.path.exists(temp_no_music_path):
                os.remove(temp_no_music_path)
            
            result = final_result
    else:
        # Normal flow: stitch with music
        result = stitch_clips_with_separate_audio(
            video_paths=video_paths,
            clip_numbers=clip_numbers,
            voiceover_paths=voiceover_paths,
            embedded_audio_clips=embedded_audio_clips,
            music_path=music_path,
            output_path=output_path,
            music_volume=0.07,
            clip0_voiceover=clip0_voiceover
        )
    
    # Apply captions if requested
    if result and captions:
        print(f"\n{'='*60}")
        print(f"üìù APPLYING CAPTIONS: {captions}")
        print(f"{'='*60}")
        try:
            from video_captions import VideoCaptionStyler, find_combination
            
            combo = find_combination(captions)
            if combo:
                print(f"  Found caption style: {combo['style']} with effect: {combo['effect']}")
                captioned_path = output_path.replace(".mp4", "_captioned.mp4")
                
                print(f"  Input video: {result}")
                print(f"  Output video: {captioned_path}")
                
                styler = VideoCaptionStyler(result, captioned_path)
                print(f"  Transcribing audio (language: {language_code})...")
                styler.transcribe_audio(language=language_code)
                
                # Calculate caption start time (skip Clip 0)
                # If speed was applied, clip_0_duration is scaled by speed
                caption_start_time = clip_0_duration / speed if speed != 1.0 else clip_0_duration
                
                max_words = 4 if combo['effect'] == 'karaoke' else 2
                print(f"  Generating captions (max_words: {max_words}, style: {combo['style']}, effect: {combo['effect']})...")
                print(f"  üé¨ Captions will start at {caption_start_time:.2f}s (after Clip 0)")
                styler.auto_generate_captions(
                    max_words_per_caption=max_words,
                    style_preset=combo['style'],
                    word_effect=combo['effect'],
                    caption_start_time=caption_start_time
                )
                
                print(f"  Rendering captioned video...")
                styler.render(quality="high")
                
                if os.path.exists(captioned_path):
                    # Replace original with captioned version
                    os.remove(result)
                    os.rename(captioned_path, result)
                    print(f"  ‚úÖ Captions applied successfully!")
                    print(f"  Output: {result}")
                else:
                    print(f"  ‚ùå Captioned file was not created: {captioned_path}")
            else:
                print(f"  ‚ùå Unknown caption style: {captions}")
                print(f"     Valid styles include: karaoke_red, karaoke_blue, boxed_white, etc.")
        except ImportError as e:
            print(f"  ‚ùå Failed to import video_captions module: {e}")
        except Exception as e:
            print(f"  ‚ùå Failed to apply captions: {e}")
            import traceback
            traceback.print_exc()
    
    return result


def restitch_only(assets_folder: str, output_path: Optional[str] = None,
                  custom_music_path: Optional[str] = None, speed: float = 1.0,
                  clip0_voiceover: Optional[str] = None,
                  include_music: bool = True) -> Optional[str]:
    """
    Re-stitch original complete clips without individual fixing.
    Uses clip_*/clip_*_complete.mp4 files.
    
    Args:
        custom_music_path: Optional path to custom background music file (overrides existing music)
        speed: Speed multiplier for final video (e.g., 1.1 for 10% faster)
        clip0_voiceover: Optional path to voiceover audio for Clip 0 (normally silent opening hook)
        include_music: If False, no background music will be added to the final video
    """
    print(f"\n{'='*60}")
    print(f"üîó RE-STITCHING COMPLETE CLIPS")
    print(f"{'='*60}")
    print(f"  Assets folder: {assets_folder}")
    
    if not os.path.exists(assets_folder):
        print(f"  ‚ùå Assets folder not found: {assets_folder}")
        return None
    
    # Find all clip folders
    clip_folders = sorted(glob.glob(os.path.join(assets_folder, "clip_*")))
    if not clip_folders:
        print(f"  ‚ùå No clip folders found in {assets_folder}")
        return None
    
    print(f"  Found {len(clip_folders)} clip folders")
    
    # Load metadata to identify embedded audio clips
    metadata = load_master_metadata(assets_folder)
    embedded_audio_clips = []
    if metadata and 'voiceover_files' in metadata:
        for clip_num_str, vo_info in metadata['voiceover_files'].items():
            if vo_info.get('embedded', False):
                embedded_audio_clips.append(int(clip_num_str))
    
    # Collect clips with parallel clip_numbers tracking
    video_paths = []
    clip_numbers = []
    voiceover_paths = {}
    
    for clip_folder in sorted(clip_folders, key=lambda x: int(os.path.basename(x).split("_")[1])):
        clip_name = os.path.basename(clip_folder)
        clip_num = int(clip_name.split("_")[1])
        
        clip_path = os.path.join(clip_folder, f"{clip_name}_complete.mp4")
        if os.path.exists(clip_path):
            video_paths.append(clip_path)
            clip_numbers.append(clip_num)
    
    # Find voiceover files
    raw_assets_dir = os.path.join(assets_folder, "raw_assets")
    if os.path.exists(raw_assets_dir):
        voiceovers_dir = os.path.join(raw_assets_dir, "voiceovers")
        search_dir = voiceovers_dir if os.path.exists(voiceovers_dir) else raw_assets_dir
        for vo_file in glob.glob(os.path.join(search_dir, "voiceover_clip_*.mp3")):
            basename = os.path.basename(vo_file)
            clip_num = int(basename.replace("voiceover_clip_", "").replace(".mp3", ""))
            voiceover_paths[clip_num] = vo_file
    
    # Find music - use custom music if provided
    # Skip music entirely if include_music=False
    music_path = None
    if not include_music:
        print(f"  üîá No background music (--no-music flag)")
    elif custom_music_path and os.path.exists(custom_music_path):
        music_path = custom_music_path
        print(f"  üéµ Using CUSTOM music: {os.path.basename(music_path)}")
    elif os.path.exists(raw_assets_dir):
        music_dir = os.path.join(raw_assets_dir, "music")
        search_dir = music_dir if os.path.exists(music_dir) else raw_assets_dir
        music_files = sorted(glob.glob(os.path.join(search_dir, "music_*.mp3")))
        music_path = music_files[0] if music_files else None
    
    if not output_path:
        folder_name = os.path.basename(assets_folder.rstrip("/").rstrip("_assets"))
        output_path = os.path.join(os.path.dirname(assets_folder), f"{folder_name}_restitched.mp4")
    
    # Note: For restitching complete clips, we DON'T use voiceover_paths
    # because the audio is already in the clips
    # We just need proper stitching with set_start/set_end
    # EXCEPT: If custom music is provided, we strip audio and add new music
    
    # Get clip 0's duration for music timing (music starts AFTER clip 0)
    clip_0_duration = 0.0
    if video_paths and clip_numbers and clip_numbers[0] == 0:
        try:
            temp_clip = VideoFileClip(video_paths[0])
            clip_0_duration = temp_clip.duration
            temp_clip.close()
            print(f"  üìè Clip 0 duration: {clip_0_duration:.2f}s (music will start after this)")
        except Exception as e:
            print(f"  ‚ö†Ô∏è Could not get clip 0 duration: {e}, using default 0")
            clip_0_duration = 0.0
    
    # Handle speed change
    if speed != 1.0:
        print(f"\n  üöÄ Speed mode: {speed}x - will stitch without music, then speed up, then add music")
        
        # Stitch without music first
        temp_no_music_path = output_path.replace(".mp4", "_temp_no_music.mp4")
        result = stitch_clips_with_separate_audio(
            video_paths=video_paths,
            clip_numbers=clip_numbers,
            voiceover_paths={},
            embedded_audio_clips=clip_numbers,
            music_path=None,  # No music in first pass
            output_path=temp_no_music_path,
            clip0_voiceover=clip0_voiceover
        )
        
        if result:
            # Apply speed and add music
            final_result = apply_speed_and_music(
                video_path=temp_no_music_path,
                output_path=output_path,
                speed=speed,
                music_path=music_path,  # Use custom or found music
                music_volume=0.07,
                clip_0_duration=clip_0_duration  # Pass clip 0 duration for music timing
            )
            
            # Clean up temp file
            if os.path.exists(temp_no_music_path):
                os.remove(temp_no_music_path)
            
            return final_result
        return None
    elif custom_music_path:
        # With custom music: strip existing audio, add new music
        print(f"  üîÑ Will replace existing music with custom music")
        return stitch_clips_with_separate_audio(
            video_paths=video_paths,
            clip_numbers=clip_numbers,
            voiceover_paths={},  # Complete clips already have voiceover embedded
            embedded_audio_clips=clip_numbers,  # Extract voiceover from clips
            music_path=music_path,  # Add custom music
            output_path=output_path,
            clip0_voiceover=clip0_voiceover
        )
    else:
        # Without custom music: keep existing audio as-is
        return stitch_clips_with_separate_audio(
            video_paths=video_paths,
            clip_numbers=clip_numbers,
            voiceover_paths={},  # Complete clips already have audio
            embedded_audio_clips=clip_numbers,  # Treat all as embedded (use clip numbers, not range)
            music_path=None,  # Complete clips already have music
            output_path=output_path,
            clip0_voiceover=clip0_voiceover
        )


def fix_assets(assets_folder: str, output_path: Optional[str] = None, 
               include_music: bool = True, custom_music_path: Optional[str] = None,
               speed: float = 1.0, restitch_only_mode: bool = False,
               from_raw: bool = False, captions: Optional[str] = None,
               language_code: str = "en",
               clip0_voiceover: Optional[str] = None) -> Optional[str]:
    """
    Main entry point for asset fixing/regeneration.
    
    Args:
        custom_music_path: Optional path to custom background music file (overrides raw_assets music)
        speed: Speed multiplier for final video (e.g., 1.1 for 10% faster)
        clip0_voiceover: Optional path to voiceover audio for Clip 0 (normally silent opening hook)
    """
    if from_raw:
        return regenerate_from_raw(assets_folder, output_path, captions, language_code, custom_music_path, speed, clip0_voiceover=clip0_voiceover, include_music=include_music)
    
    if restitch_only_mode:
        return restitch_only(assets_folder, output_path, custom_music_path, speed, clip0_voiceover=clip0_voiceover, include_music=include_music)
    
    # Original fix mode - fix individual clips then stitch
    print(f"\n{'='*60}")
    print(f"üîß FIXING ASSETS AUDIO")
    print(f"{'='*60}")
    print(f"  Assets folder: {assets_folder}")
    
    if not os.path.exists(assets_folder):
        print(f"  ‚ùå Assets folder not found: {assets_folder}")
        return None
    
    clip_folders = sorted(glob.glob(os.path.join(assets_folder, "clip_*")))
    if not clip_folders:
        print(f"  ‚ùå No clip folders found in {assets_folder}")
        return None
    
    print(f"  Found {len(clip_folders)} clip folders")
    
    raw_assets_dir = os.path.join(assets_folder, "raw_assets")
    music_path = None
    if include_music and os.path.exists(raw_assets_dir):
        music_files = sorted(glob.glob(os.path.join(raw_assets_dir, "music_*.mp3")))
        if music_files:
            music_path = music_files[0]
            print(f"  Background music: {os.path.basename(music_path)}")
    
    fixed_folder = os.path.join(assets_folder, "fixed")
    os.makedirs(fixed_folder, exist_ok=True)
    print(f"  Fixed clips will be saved to: {fixed_folder}")
    
    print(f"\n{'='*60}")
    print(f"üì¶ FIXING INDIVIDUAL CLIPS")
    print(f"{'='*60}")
    
    fixed_clips = []
    music_position = 0
    
    for clip_folder in clip_folders:
        clip_name = os.path.basename(clip_folder)
        clip_num = int(clip_name.split("_")[1])
        
        clip_path = os.path.join(clip_folder, f"{clip_name}_complete.mp4")
        if not os.path.exists(clip_path):
            print(f"  ‚ö†Ô∏è Clip not found: {clip_path}")
            continue
        
        fixed_path = os.path.join(fixed_folder, f"{clip_name}_fixed.mp4")
        
        try:
            temp_clip = VideoFileClip(clip_path)
            clip_duration = temp_clip.duration
            temp_clip.close()
        except:
            clip_duration = 4
        
        result = fix_clip_audio(
            clip_path=clip_path,
            output_path=fixed_path,
            music_path=music_path,
            music_start=music_position,
            music_volume=0.07
        )
        
        if result:
            fixed_clips.append((clip_num, result))
            music_position += clip_duration
    
    if not fixed_clips:
        print(f"\n  ‚ùå No clips were fixed successfully")
        return None
    
    fixed_clips.sort(key=lambda x: x[0])
    fixed_clip_paths = [path for _, path in fixed_clips]
    fixed_clip_numbers = [clip_num for clip_num, _ in fixed_clips]
    
    print(f"\n  ‚úÖ Fixed {len(fixed_clips)} clips")
    
    if not output_path:
        folder_name = os.path.basename(assets_folder.rstrip("/").rstrip("_assets"))
        output_path = os.path.join(os.path.dirname(assets_folder), f"{folder_name}_fixed.mp4")
    
    # Use the proper stitching function
    return stitch_clips_with_separate_audio(
        video_paths=fixed_clip_paths,
        clip_numbers=fixed_clip_numbers,
        voiceover_paths={},
        embedded_audio_clips=fixed_clip_numbers,  # Use clip numbers, not range
        music_path=None,  # Already added to individual clips
        output_path=output_path
    )


def main():
    parser = argparse.ArgumentParser(
        description="Fix audio noise in video assets and regenerate final video",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    # Just re-stitch complete clips with proper audio handling
    python fix_assets_audio.py --assets-folder output/royjewels10_assets --restitch-only
    
    # Re-stitch with CUSTOM background music
    python fix_assets_audio.py --assets-folder output/royjewels10_assets --from-raw --music ~/Music/my_background.mp3
    
    # Speed up video by 10% (1.1x) - speeds up visuals + voiceover, then adds music
    python fix_assets_audio.py --assets-folder output/royjewels10_assets --from-raw --speed 1.1
    
    # Speed up AND use custom music
    python fix_assets_audio.py --assets-folder output/royjewels10_assets --from-raw --speed 1.15 --music ~/Music/upbeat.mp3
    
    # Regenerate from raw assets (videos, voiceovers, music)
    python fix_assets_audio.py --assets-folder output/royjewels10_assets --from-raw
    
    # Regenerate with captions
    python fix_assets_audio.py --assets-folder output/royjewels10_assets --from-raw --captions karaoke_red
    
    # Fix individual clips then stitch
    python fix_assets_audio.py --assets-folder output/royjewels10_assets
    
    # Custom output path
    python fix_assets_audio.py --assets-folder output/royjewels10_assets --output my_video.mp4
        """
    )
    
    parser.add_argument(
        "--assets-folder", "-a",
        required=True,
        help="Path to assets folder (e.g., output/royjewels10_assets)"
    )
    
    parser.add_argument(
        "--output", "-o",
        default=None,
        help="Output path for final video (default: auto-generated)"
    )
    
    parser.add_argument(
        "--no-music",
        action="store_true",
        help="Don't include background music in fixed clips"
    )
    
    parser.add_argument(
        "--music", "-m",
        default=None,
        help="Path to custom background music file (overrides music from raw_assets)"
    )
    
    parser.add_argument(
        "--clip0-voiceover",
        default=None,
        help="Path to voiceover audio file to apply on Clip 0 (normally silent). This adds narration to the opening hook image."
    )
    
    parser.add_argument(
        "--speed", "-s",
        type=float,
        default=1.0,
        help="Speed multiplier for the final video (e.g., 1.1 for 10%% faster, 1.2 for 20%% faster). Speeds up visuals and voiceover together, then applies background music at normal speed."
    )
    
    parser.add_argument(
        "--restitch-only", "-r",
        action="store_true",
        help="Skip individual clip fixing, just re-stitch complete clips with proper audio handling"
    )
    
    parser.add_argument(
        "--from-raw",
        action="store_true",
        help="Regenerate from raw assets (videos folder) instead of complete clips"
    )
    
    parser.add_argument(
        "--captions", "-c",
        default=None,
        help="Caption style to apply (e.g., karaoke_red, boxed_purple)"
    )
    
    parser.add_argument(
        "--language", "-l",
        default="en",
        help="Language code for caption transcription (default: en)"
    )
    
    parser.add_argument(
        "--list-assets",
        action="store_true",
        help="List available assets in the folder and exit"
    )
    
    args = parser.parse_args()
    
    # List assets mode
    if args.list_assets:
        print(f"\n{'='*60}")
        print(f"üìÇ AVAILABLE ASSETS")
        print(f"{'='*60}")
        print(f"  Assets folder: {args.assets_folder}")
        
        # Detect generator type
        generator_type = detect_generator_type(args.assets_folder)
        generator_display = {
            "ai_avatar_video_generator": "AI Avatar Video Generator (OmniHuman)",
            "political_video_generator": "Political Video Generator (Image-based)",
            "unknown": "Unknown Generator"
        }.get(generator_type, "Unknown")
        print(f"\n  üé¨ Generator: {generator_display}")
        
        raw_assets_dir = os.path.join(args.assets_folder, "raw_assets")
        
        # Check master metadata
        metadata = load_master_metadata(args.assets_folder)
        if metadata:
            print(f"\n  üìã Master Metadata:")
            params = metadata.get('generation_params', {})
            print(f"     - Language: {params.get('language_code', 'unknown')} ({params.get('language_name', '')})")
            print(f"     - Clip count: {metadata.get('clip_count', 'unknown')}")
            print(f"     - Total duration: {metadata.get('total_duration', 'unknown')}s")
            print(f"     - Captions: {params.get('captions', 'none')}")
            
            # Show generator-specific params
            if generator_type == "ai_avatar_video_generator":
                print(f"     - Voice ID: {params.get('voice_id', 'unknown')[:20]}...")
                print(f"     - Split proportion: {params.get('split_proportion', 0) * 100:.0f}%")
                print(f"     - Reference image: {'Yes' if params.get('reference_image') else 'No'}")
            else:
                print(f"     - Influencer mode: {params.get('influencer_mode', False)}")
                print(f"     - AI video model: {params.get('ai_video_model', 'none')}")
        
        # Check video plan
        video_plan = load_video_plan(args.assets_folder)
        if video_plan:
            print(f"\n  üìù Video Plan: {len(video_plan.get('clips', []))} clips defined")
        
        # Check effect analysis
        effects = load_effect_analysis(args.assets_folder)
        if effects:
            print(f"\n  üé® Effect Analysis: {len(effects)} clips with effects")
        
        # Check transcriptions
        transcriptions = load_transcriptions(args.assets_folder)
        if transcriptions:
            print(f"\n  üí¨ Transcriptions: {len(transcriptions)} clips with word timestamps")
        
        # Check raw assets
        if os.path.exists(raw_assets_dir):
            print(f"\n  üìÅ Raw Assets:")
            
            # Videos
            videos_dir = os.path.join(raw_assets_dir, "videos")
            if os.path.exists(videos_dir):
                videos = glob.glob(os.path.join(videos_dir, "clip_*_raw.mp4"))
                print(f"     - Videos: {len(videos)} raw clips")
            
            # Images
            images_dir = os.path.join(raw_assets_dir, "images")
            if os.path.exists(images_dir):
                images = glob.glob(os.path.join(images_dir, "*.png"))
                print(f"     - Images: {len(images)} raw images")
            
            # Voiceovers
            voiceovers_dir = os.path.join(raw_assets_dir, "voiceovers")
            if os.path.exists(voiceovers_dir):
                voiceovers = glob.glob(os.path.join(voiceovers_dir, "voiceover_clip_*.mp3"))
                print(f"     - Voiceovers: {len(voiceovers)} audio files")
            
            # Music
            music_dir = os.path.join(raw_assets_dir, "music")
            if os.path.exists(music_dir):
                music = glob.glob(os.path.join(music_dir, "music_*.mp3"))
                # Check if music is custom or generated
                music_type = "generated"
                if metadata and 'music_files' in metadata:
                    for group_name, music_info in metadata['music_files'].items():
                        if music_info.get('is_custom', False):
                            music_type = "custom"
                            orig_path = music_info.get('original_path', 'unknown')
                            print(f"     - Music: {len(music)} files ({music_type} - original: {os.path.basename(orig_path) if orig_path else 'unknown'})")
                            break
                    else:
                        print(f"     - Music: {len(music)} files ({music_type} via ElevenLabs)")
                else:
                    print(f"     - Music: {len(music)} music files")
            
            # Input context
            context_path = os.path.join(raw_assets_dir, "input_context.txt")
            if os.path.exists(context_path):
                with open(context_path, 'r') as f:
                    content = f.read()
                print(f"     - Input context: {len(content)} characters")
            
            # Research clips
            research_dir = os.path.join(raw_assets_dir, "research_clips")
            if os.path.exists(research_dir):
                research_videos = glob.glob(os.path.join(research_dir, "research_after_clip_*.mp4"))
                research_voiceovers = glob.glob(os.path.join(research_dir, "research_vo_after_clip_*.mp3"))
                print(f"     - Research clips: {len(research_videos)} videos, {len(research_voiceovers)} voiceovers")
        
        # Check complete clips
        clip_folders = glob.glob(os.path.join(args.assets_folder, "clip_*"))
        if clip_folders:
            print(f"\n  üé¨ Complete Clips: {len(clip_folders)} processed clips")
        
        # Determine if assets are sufficient for regeneration
        has_videos = os.path.exists(os.path.join(raw_assets_dir, "videos")) and glob.glob(os.path.join(raw_assets_dir, "videos", "*.mp4"))
        has_metadata = metadata is not None
        has_video_plan = video_plan is not None
        
        sufficient = has_videos and has_metadata
        
        print(f"\n  ‚úÖ Assets sufficient for regeneration: {'YES' if sufficient else 'PARTIAL'}")
        if not sufficient:
            missing = []
            if not has_videos:
                missing.append("raw video clips")
            if not has_metadata:
                missing.append("master metadata")
            print(f"     Missing: {', '.join(missing)}")
        
        print(f"\n  üí° To regenerate video:")
        print(f"     python fix_assets_audio.py --assets-folder {args.assets_folder} --from-raw")
        exit(0)
    
    # Handle custom music path
    custom_music = args.music
    if custom_music:
        if os.path.exists(custom_music):
            print(f"üéµ Using custom music: {custom_music}")
        else:
            print(f"‚ö†Ô∏è Custom music file not found: {custom_music}")
            custom_music = None
    
    # Handle speed parameter
    speed = args.speed
    if speed != 1.0:
        print(f"üöÄ Speed: {speed}x (will speed up visuals + voiceover, then apply music)")
    
    result = fix_assets(
        assets_folder=args.assets_folder,
        output_path=args.output,
        include_music=not args.no_music,
        custom_music_path=custom_music,
        speed=speed,
        restitch_only_mode=args.restitch_only,
        from_raw=args.from_raw,
        captions=args.captions,
        language_code=args.language,
        clip0_voiceover=args.clip0_voiceover
    )
    
    if result:
        print(f"\n{'='*60}")
        print(f"üéâ SUCCESS!")
        print(f"{'='*60}")
        print(f"  Final video: {result}")
        
        try:
            video_info = VideoFileClip(result)
            print(f"  Duration: {video_info.duration:.1f}s")
            print(f"  Resolution: {video_info.size[0]}x{video_info.size[1]}")
            video_info.close()
        except:
            pass
    else:
        print(f"\n{'='*60}")
        print(f"‚ùå FAILED")
        print(f"{'='*60}")
        exit(1)


if __name__ == "__main__":
    main()
